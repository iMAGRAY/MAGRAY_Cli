# Zeroâ€‘toâ€‘One CLI Agent Architecture â€” **Rust Edition** (.v2)

**Author:** generated by AI for Magray  
**Status:** Draft â€” Greenfield, **pureâ€‘Rust** stack  
**Last Update:** 2025-07-29

---

## 0. Core Principles

| Pillar | Implication |
|--------|-------------|
| **Single static binary** | deliver via `cargo install ourcli`; no Python/conda. |
| **Safety & Speed** | leverage Rust's `async` + zeroâ€‘cost abstractions; memoryâ€‘safe by default. |
| **Localâ€‘first** | works completely offline; optional remote toggle via feature flags. |
| **Extensible** | WASI plugins compiled from any language; manifestâ€‘driven tool discovery. |
| **Transparent AI** | logs, traces and memory promotion rules visible to the user. |

---

## 1. Crate Topology (Cargo Workspace)

```text
workspace/
â”œâ”€ crates/
â”‚  â”œâ”€ cli            # main binary (clap)
â”‚  â”œâ”€ core           # planner, executor, event bus
â”‚  â”œâ”€ memory         # LanceDB wrapper + promotion
â”‚  â”œâ”€ ai             # embedding, rerank, llm clients
â”‚  â”œâ”€ tools          # common Tool traits + wasm host
â”‚  â””â”€ scheduler      # cron jobs / maintenance
â””â”€ plugins/          # *.wasm thirdâ€‘party tools
```

Each crate is `no_std`â€‘friendly where possible; shared utils under `crates/common`.

---

## 2. System Overview

```mermaid
flowchart TD
    subgraph CLI
        CLI[[ourcli]] --> Router
    end

    subgraph Core
        Router --> Planner
        Planner --> Executor
        Executor -->|events| EventBus
        Executor --> MemSvc
        Executor --> ToolReg
        Executor --> PromptBldr
    end

    subgraph AI
        PromptBldr --> EmbedSvc
        EmbedSvc --> MemSvc
        MemSvc --> RerankSvc
        PromptBldr --> RerankSvc
        RerankSvc --> LLMsvc
    end

    Scheduler --> MemSvc
    Scheduler --> ToolReg
    EventBus --> Observability
```

All links are **`async`/await** powered by **Tokio** runtime; EventBus is `tokio::sync::broadcast`.

---

## 3. Memory Service (LanceDB + Rust)

| Table | Purpose | Retention | Index | Weight |
|-------|---------|-----------|-------|--------|
| `interact` (L1) | session chat & tool logs | â‰¤ 24 h | HNSW | 1.2 |
| `insights` (L2) | distilled decisions | â‰¤ 90 d | IVFâ€‘PQ | 1.0 |
| `assets` (L3) | docs / code chunks | longâ€‘term | IVFâ€‘PQ segmented | 0.8 |

Implemented using **`lancedb` crate** â€” zeroâ€‘copy Arrow columns, embedded storage.

### Rust schema

```rust
#[derive(ArrowSchema)]
struct Record {
    #[id]
    id: uuid::Uuid,
    #[text]
    text: String,
    #[vector(dim = 384)]
    embedding: Vec<f32>,
    layer: Layer,
    kind: String,
    tags: Vec<String>,
    project: String,
    session: String,
    ts: chrono::DateTime<chrono::Utc>,
}
```

### Retrieval

```rust
let hits = memsvc
    .search("how to fix linkage error")
    .with_layers(&[Layer::Interact, Layer::Insights, Layer::Assets])
    .with_project("proj42")
    .top_k(200)        // ANN via HNSW/IVF
    .rerank(32)        // Onâ€‘device crossâ€‘encoder
    .await?;
```

---

## 4. AI Stack (Rustâ€‘only)

| Function | Crate | Notes |
|----------|-------|-------|
| **Embeddings** | `onnxruntime` via Qwen3-Embedding-0.6B-ONNX | BGE models replaced with Qwen3 |
| **Crossâ€‘Encoder Rerank** | `onnxruntime` (Qwen3-Reranker-0.6B-ONNX) | Runs ~2 ms / pair on laptop |
| **LLM Client** | `llm` or `ggml-rs` (local GGUF) + optional `openai-rs` behind feature flag | swap models via `--model` CLI |
| **Scheduler** | `tokio_cron_scheduler` | cronâ€‘style tasks |
| **Observability** | `tracing` + `tracing_subscriber` + `opentelemetry-otlp` exporter |

Embeddings and rerankers are loaded once into `Arc<Mutex<Model>>` and shared across tasks.

---

## 5. Tool Plugins

* **WASM/WASI** sandbox via `wasmtime` crate.  
* Plugins declare JSON manifest with `spec` and required caps.  
* Host->Guest communication over stdin/stdout JSONâ€‘RPC (serde).

```jsonc
// hello_wasm/manifest.json
{
  "name": "hello",
  "description": "Greets the world",
  "inputs": [{"name": "name", "type": "string"}],
  "outputs": [{"name": "greeting", "type": "string"}]
}
```

Compile with `cargo build --target wasm32-wasi --release`.

---

## 6. Config & Runtime Flags

```toml
[paths]
db = "~/.ourcli/lancedb"

[ai]
embed_model = "Qwen3-Embedding-0.6B-ONNX"
rerank_model = "Qwen3-Reranker-0.6B-ONNX"
llm_model = "llama2-chat.gguf"
max_ctx_tokens = 8192

[scheduler]
promote_cron = "0 */6 * * * *"   # every 6h
vacuum_cron  = "0 0 */1 * * *"   # daily
```

Environment flags:

* `OURCLI_NET=1` â†’ enable network tools & remote OpenAI.
* `RUST_LOG=info` â†’ enable tracing.

---

## 7. Promotion & Decay Logic

```rust
if layer == Layer::Interact && age > 24h && rec.tags.contains("decision") {
    memsvc.promote(&rec.id, Layer::Insights).await?;
}
if layer == Layer::Insights && last_used > 90d {
    memsvc.demote_summary(&rec.id, Layer::Assets).await?;
}
```

Scheduler wires these into cron.

---

## 8. Cargo Features Matrix

| Feature | Default? | Enables |
|---------|----------|---------|
| `remote-openai` | off | `openai-rs`, network tools |
| `gpu` | off | `wgpu` acceleration for ONNXRuntime |
| `tui` | off | `ratatui` Kanban board |

---

## 9. MVP Roadmap (Rust tasks)

1. **Workspace scaffolding** (`cargo new --lib`)  
2. CLI â†’ `clap` derive + commands.  
3. Memory crate wrapping LanceDB (CRUD + ANN).  
4. SBERT embeddings & cache (`sled`).  
5. Onnx reranker integration.  
6. Static Planner & Executor (topological).  
7. Wasmtime host + sample plugin.  
8. Tracing & JSON event log.  
9. Cron Scheduler jobs.  
10. Release binary via GitHub Actions & `cross`.

---

## 10. Key Traits (Rust API)

```rust
#[async_trait::async_trait]
pub trait Memory {
    async fn search(&self, q: &str, k: usize) -> anyhow::Result<Vec<Record>>;
    async fn insert(&self, rec: Record) -> anyhow::Result<()>;
}

#[async_trait::async_trait]
pub trait Tool {
    fn spec(&self) -> ToolSpec;
    async fn invoke(&self, input: serde_json::Value) -> anyhow::Result<serde_json::Value>;
}
```

---

## 11. Result

A **100 % Rust** AI CLI with:

* < 50 ms hybrid retrieval  
* Secure WASI tool sandbox  
* Zero external deps â€” ship one binary, run anywhere.

_`cargo run -- ask "design cache layer"`_ and enjoy the speed! ðŸš€