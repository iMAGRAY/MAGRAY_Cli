# Проектное видение: MAGRAY CLI

## Цель проекта
Создать локального CLI‑помощника для программистов, который:
- управляет задачами и автоматизирует рутинные действия в проекте;
- использует LLM (через публичные API или локальные модели) только для рассуждений и генерации, оставляя данные на машине пользователя;
- предоставляет гибкую систему инструментов (file/git/shell/плагины), «умную» память и оркестрацию действий без жёстко зашитых сценариев.

## Принципы
- **Local‑first и приватность**: никакой удалённой инфраструктуры или внешних серверов. Все данные, индексы и кэши находятся локально у пользователя. Разрешены только сетевые обращения к LLM API-провайдерам при явной настройке.
- **Модульность и расширяемость**: инструменты и подсистемы подключаются как плагины/адаптеры, конфигурируются через TOML/ENV, не требуют форка проекта.
- **Гибкость вместо жёстких «магических» флоу**: планирование и исполнение задач — через оркестратор, который опирается на память и инструменты, а не на фиксированные пайплайны.
- **Надёжность и воспроизводимость**: локальные журналы, детерминированные шаги, возможность повторного запуска/резюме.

## Ключевые компоненты
- **Оркестратор**
  - Центральный «мозг»: принимает цель, строит план (Plan‑Act‑Reflect), выбирает инструменты, контролирует шаги, анализирует результаты.
  - Политики: лимиты шагов, безопасный режим, стратегия повторных попыток.
  - Событийная шина: события шага, статусы, артефакты, логи — для UI/CLI вывода и диагностики.

- **Todo/DAG‑движок**
  - Локальный планировщик задач (DAG), состояния: Pending/Running/Blocked/Done/Failed.
  - Перезапуск после падения, журналирование (локально), дедлайны/приоритеты.
  - Примитивы: задача‑команда, задача‑инструмент, задача‑скрипт, задача‑шаблон.

- **Система инструментов (Tools)**
  - Базовые адаптеры: file (read/write/list), git, shell.
  - Расширения пользователем: плагины (dinamic/static), декларативные инструменты.
  - Контроль разрешений (capabilities): доступ к файлам/сетям, лимиты времени.

- **Память (Memory)**
  - Контекстная память проекта и сессий: заметки, факты, ключевые фрагменты кода.
  - Векторный поиск для семантического извлечения; реранкинг для точности.
  - По умолчанию: **qwen3 0.6b** для эмбеддинга и реранкинга.
  - Опциональная персистентность (встроенная БД) и индексация (ANN/HNSW) — локально.

- **LLM‑слой**
  - Провайдеры: OpenAI, Anthropic, Groq, а также локальные (Ollama, LM Studio).
  - Единый интерфейс, конфигурация через `.env`/TOML, таймауты и ретраи.
  - Никаких внешних сервисов: только вызовы к LLM API при необходимости.

- **MCP (Model Context Protocol) — поддержка серверов**
  - Интеграция внешних инструментов через MCP‑серверы (stdio/websocket) без передачи приватных данных в сторонние сервисы.
  - Унифицированные адаптеры: объявление инструментов, контекста, доступов.

## Технологии
- Язык/Runtime: **Rust**, `tokio`, `clap`, `tracing`, `serde`.
- LLM: абстракции провайдеров, `reqwest` для API, локальные мосты (Ollama/LM Studio).
- Память/индексация: qwen3 0.6b (эмбеддинг/реранкинг), локальные индексы (опционально HNSW), кэширование.
- Хранилище (локально): встраиваемая БД (SQLite/sled — по выбранной сборочной фиче), файлы пользователя.
- Безопасность: capability‑гейтинг инструментов, явные подтверждения, режим «только чтение».

## Нефункциональные требования
- Кросс‑платформенность: Linux/macOS/Windows.
- Прозрачность: логи, детальная диагностика, понятные сообщения об ошибках.
- Производительность: кэш ответов, пакетная обработка, минимизация I/O.

## Дорожная карта (high‑level)
1. Базовый CLI и инструменты (file/git/shell), конфиг, LLM‑провайдеры.
2. Память: локальная база, qwen3 0.6b эмбеддинг/реранкинг, поиск.
3. Оркестратор: планирование задач, контроль шагов, ретраи и отчёты.
4. Todo/DAG‑исполнитель: статусы, возобновление, приоритеты, дедлайны.
5. MCP интеграция: клиент/сервер, адаптация сторонних инструментов.
6. Локальный OS‑ассистент: управление приложениями, окнами, файлами, сценариями (с подтверждениями).

## Ограничения и поток данных
- Все данные/кэши/индексы — **локально**. Никаких внешних сервисов/БД/кластеров.
- Единственные исходящие запросы — к LLM API, если пользователь включил провайдера.
- MCP‑серверы/клиенты — локальные процессы/каналы; сетевые порты — по явной настройке пользователя.

## Что это даст пользователю?
- Автоматизация рутинных задач в проекте и ОС, сохранение контекста и знаний.
- Прозрачный и расширяемый инструмент без «чёрных ящиков» и внешних сервисов.
- Гибкая архитектура для экспериментов с моделями и инструментами — всё локально.