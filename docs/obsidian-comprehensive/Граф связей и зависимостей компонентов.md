# Граф связей и зависимостей компонентов

#architecture #dependencies #graph #relations #obsidian

> **🔗 Полная карта взаимосвязей компонентов MAGRAY CLI**  
> Визуализация всех связей, зависимостей и потоков данных между компонентами системы.

## 🎯 Обзор архитектуры связей

### 📊 Статистика связей

| Тип связи | Количество | Критичность | Статус |
|-----------|------------|-------------|--------|
| **Direct Dependencies** | 47 связей | Высокая | ✅ Mapped |
| **Data Flow** | 23 потока | Критическая | ✅ Verified |
| **Event Triggers** | 15 событий | Средняя | ✅ Documented |
| **Health Checks** | 12 проверок | Высокая | ✅ Active |

## 🏗️ Главная архитектурная диаграмма

```mermaid
graph TB
    subgraph "🖥️ Frontend Layer"
        CLI[CLI Crate<br/>🎯 Entry Point]
        Progress[Adaptive Progress<br/>🎨 UI Feedback]
        Health[Health Checks<br/>🏥 System Status]
    end
    
    subgraph "🤖 Orchestration Layer"
        Agent[Unified Agent<br/>🎭 Core Orchestrator]
        Router[Smart Router<br/>🔀 Task Routing]
        Planner[Action Planner<br/>📋 Task Planning]
    end
    
    subgraph "🧠 Core Services"
        Memory[Memory Service<br/>💾 Vector Storage]
        AI[AI Service<br/>🚀 ONNX Models]
        LLM[LLM Client<br/>🤖 Multi-Provider]
        Tools[Tool Registry<br/>🛠️ Safe Execution]
    end
    
    subgraph "🔧 Infrastructure"
        Common[Common Utils<br/>⚙️ Foundation]
        Database[Database Manager<br/>🗄️ Sled Backend]
        Cache[Cache System<br/>⚡ LRU + Persistence]
        Notifications[Alert System<br/>📢 Production Alerts]
    end
    
    subgraph "🎮 Hardware Layer"
        GPU[GPU Manager<br/>⚡ CUDA Acceleration]
        MemPool[Memory Pool<br/>💾 VRAM Management]
        Fallback[Fallback Manager<br/>🔄 CPU Fallback]
    end
    
    %% Main flow connections
    CLI --> Agent
    Agent --> Router
    Router --> Memory
    Router --> AI
    Router --> LLM
    Router --> Tools
    
    %% Core service interconnections
    Memory --> AI
    Memory --> Database
    Memory --> Cache
    AI --> GPU
    AI --> MemPool
    GPU --> Fallback
    
    %% Infrastructure connections
    Memory --> Common
    AI --> Common
    LLM --> Common
    Tools --> Common
    Database --> Common
    Cache --> Common
    
    %% Monitoring connections
    CLI --> Health
    Memory --> Notifications
    AI --> Notifications
    GPU --> Notifications
    
    %% UI feedback
    CLI --> Progress
    Memory --> Progress
    AI --> Progress
    
    classDef frontend fill:#e1f5fe
    classDef orchestration fill:#f3e5f5
    classDef services fill:#e8f5e8
    classDef infrastructure fill:#fff3e0
    classDef hardware fill:#ffebee
    
    class CLI,Progress,Health frontend
    class Agent,Router,Planner orchestration
    class Memory,AI,LLM,Tools services
    class Common,Database,Cache,Notifications infrastructure
    class GPU,MemPool,Fallback hardware
```

## 🧠 Memory System - Внутренние связи

### 🏛️ Трёхслойная архитектура связей

```mermaid
graph TB
    subgraph "Data Flow Pipeline"
        Input[📝 Input Data] --> Embed[🔄 Embedding Service]
        Embed --> VectorStore[📊 Vector Store]
        VectorStore --> HNSW[🔍 HNSW Index]
        HNSW --> LayerRouter[🎯 Layer Router]
    end
    
    subgraph "Layer 1: Interact (24h TTL)"
        I_DB[(Interact DB)]
        I_Index[Interact HNSW]
        I_Cache[Interact Cache]
    end
    
    subgraph "Layer 2: Insights (90d TTL)"  
        In_DB[(Insights DB)]
        In_Index[Insights HNSW]
        In_Cache[Insights Cache]
    end
    
    subgraph "Layer 3: Assets (∞ TTL)"
        A_DB[(Assets DB)]
        A_Index[Assets HNSW]  
        A_Cache[Assets Cache]
    end
    
    subgraph "Promotion System"
        MLEngine[🤖 ML Promotion Engine]
        TimeTracker[⏰ Time Tracker]
        AccessTracker[📊 Access Tracker]
        Scheduler[⚡ Promotion Scheduler]
    end
    
    subgraph "Search & Retrieval"
        SearchAPI[🔍 Search API]
        Reranker[📈 BGE Reranker]
        Results[📋 Result Processor]
    end
    
    %% Data flow to layers
    LayerRouter --> I_DB
    LayerRouter --> In_DB  
    LayerRouter --> A_DB
    
    I_DB --> I_Index
    In_DB --> In_Index
    A_DB --> A_Index
    
    I_Index --> I_Cache
    In_Index --> In_Cache
    A_Index --> A_Cache
    
    %% Promotion flows
    I_DB --> MLEngine
    In_DB --> MLEngine
    TimeTracker --> MLEngine
    AccessTracker --> MLEngine
    MLEngine --> Scheduler
    
    Scheduler --> In_DB
    Scheduler --> A_DB
    
    %% Search flows
    SearchAPI --> I_Index
    SearchAPI --> In_Index
    SearchAPI --> A_Index
    
    I_Index --> Reranker
    In_Index --> Reranker
    A_Index --> Reranker
    
    Reranker --> Results
    
    classDef layer1 fill:#e3f2fd
    classDef layer2 fill:#f1f8e9  
    classDef layer3 fill:#fff8e1
    classDef promotion fill:#fce4ec
    classDef search fill:#f3e5f5
    
    class I_DB,I_Index,I_Cache layer1
    class In_DB,In_Index,In_Cache layer2
    class A_DB,A_Index,A_Cache layer3
    class MLEngine,TimeTracker,AccessTracker,Scheduler promotion
    class SearchAPI,Reranker,Results search
```

### 🔗 Memory Component Dependencies

| Component | Зависит от | Использует | Статус связи |
|-----------|------------|------------|--------------|
| **Vector Store** | [[Database Manager]], [[Cache System]] | Sled DB, LRU Cache | ✅ Active |
| **HNSW Index** | [[Vector Store]], hnsw_rs | Raw vectors | ✅ Strong |
| **ML Promotion** | [[Vector Store]], [[Time Tracker]] | Access patterns | ✅ Active |
| **Search API** | [[HNSW Index]], [[BGE Reranker]] | Vector similarity | ✅ Strong |
| **Cache System** | [[Database Manager]] | Persistence layer | ✅ Active |

## 🤖 AI System - Модельные связи

### 🚀 ONNX Pipeline Architecture

```mermaid
graph TB
    subgraph "Model Registry & Loading"
        Registry[📋 Model Registry<br/>Centralized Metadata]
        Downloader[⬇️ Model Downloader<br/>Auto-fetch Models]
        Loader[📦 Model Loader<br/>ONNX Loading]
    end
    
    subgraph "Embedding Pipeline"
        TokenizerService[🔤 Tokenizer Service<br/>Text → Tokens]
        QwenCPU[🖥️ Qwen3 CPU<br/>CPU Inference]
        QwenGPU[🎮 Qwen3 GPU<br/>GPU Inference]
        DeviceSelector[🎯 Auto Device Selector<br/>Intelligent Routing]
    end
    
    subgraph "GPU Management"
        GPUDetector[🔍 GPU Detector<br/>Hardware Detection]
        MemoryPool[💾 GPU Memory Pool<br/>VRAM Management]
        PipelineManager[⚡ Pipeline Manager<br/>Batch Processing]
        FallbackManager[🔄 Fallback Manager<br/>CPU Fallback]
        TensorRTCache[⚡ TensorRT Cache<br/>Optimized Models]
    end
    
    subgraph "Reranking System"
        BGEReranker[📊 BGE Reranker v2-m3<br/>Semantic Reranking]
        OptimizedReranker[⚡ Optimized Reranker<br/>Fast Inference]
    end
    
    %% Registry connections
    Registry --> Downloader
    Downloader --> Loader
    Loader --> QwenCPU
    Loader --> QwenGPU
    
    %% Embedding pipeline
    TokenizerService --> QwenCPU
    TokenizerService --> QwenGPU
    DeviceSelector --> QwenCPU
    DeviceSelector --> QwenGPU
    
    %% GPU management
    GPUDetector --> DeviceSelector
    GPUDetector --> MemoryPool
    MemoryPool --> PipelineManager
    PipelineManager --> QwenGPU
    FallbackManager --> QwenCPU
    QwenGPU --> FallbackManager
    TensorRTCache --> QwenGPU
    
    %% Reranking connections
    QwenCPU --> BGEReranker
    QwenGPU --> BGEReranker
    BGEReranker --> OptimizedReranker
    
    classDef registry fill:#e8f5e8
    classDef embedding fill:#e1f5fe
    classDef gpu fill:#ffebee
    classDef reranking fill:#f3e5f5
    
    class Registry,Downloader,Loader registry
    class TokenizerService,QwenCPU,QwenGPU,DeviceSelector embedding
    class GPUDetector,MemoryPool,PipelineManager,FallbackManager,TensorRTCache gpu
    class BGEReranker,OptimizedReranker reranking
```

### 🎮 GPU Dependency Chain

```mermaid
graph LR
    subgraph "Detection Phase"
        A[GPU Detector] --> B[Hardware Info]
        B --> C[Capability Check]
    end
    
    subgraph "Initialization Phase"
        C --> D[Memory Pool Init]
        D --> E[Pipeline Setup]
        E --> F[TensorRT Cache]
    end
    
    subgraph "Runtime Phase"
        F --> G[Batch Processor]
        G --> H[Fallback Check]
        H --> I[CPU Fallback]
        H --> J[GPU Execution]
    end
    
    subgraph "Monitoring Phase"
        J --> K[Performance Monitor]
        I --> K
        K --> L[Health Updates]
    end
    
    classDef detection fill:#e3f2fd
    classDef init fill:#f1f8e9
    classDef runtime fill:#fff8e1
    classDef monitoring fill:#fce4ec
    
    class A,B,C detection
    class D,E,F init
    class G,H,I,J runtime
    class K,L monitoring
```

## 🖥️ CLI System - Command Flow

### 🎯 Command Processing Pipeline

```mermaid
graph TB
    subgraph "Input Layer"
        UserInput[👤 User Input] --> Parser[📋 Clap Parser]
        Parser --> CommandRouter[🔀 Command Router]
    end
    
    subgraph "Command Handlers"
        ChatCmd[💬 Chat Command]
        SmartCmd[🧠 Smart Command]
        ToolCmd[🛠️ Tool Command]
        StatusCmd[📊 Status Command]
        HealthCmd[🏥 Health Command]
        GPUCmd[🎮 GPU Command]
        MemoryCmd[💾 Memory Command]
        ModelsCmd[📦 Models Command]
    end
    
    subgraph "Agent Layer"
        UnifiedAgent[🎭 Unified Agent<br/>Core Orchestrator]
        ActionPlanner[📋 Action Planner]
        IntentAnalyzer[🔍 Intent Analyzer]
        ParameterExtractor[⚙️ Parameter Extractor]
        ToolSelector[🎯 Tool Selector]
    end
    
    subgraph "Execution Layer"
        MemoryService[🧠 Memory Operations]
        AIService[🤖 AI Operations]
        LLMService[💭 LLM Operations]
        ToolExecution[⚡ Tool Execution]
        SystemOps[🔧 System Operations]
    end
    
    subgraph "Response Layer"
        ProgressBar[📊 Progress Indicators]
        ResultFormatter[✨ Result Formatting]
        ErrorHandler[❌ Error Handling]
    end
    
    %% Input processing
    CommandRouter --> ChatCmd
    CommandRouter --> SmartCmd
    CommandRouter --> ToolCmd
    CommandRouter --> StatusCmd
    CommandRouter --> HealthCmd
    CommandRouter --> GPUCmd
    CommandRouter --> MemoryCmd
    CommandRouter --> ModelsCmd
    
    %% Agent integration
    ChatCmd --> UnifiedAgent
    SmartCmd --> UnifiedAgent
    ToolCmd --> UnifiedAgent
    
    %% Agent internal flow
    UnifiedAgent --> ActionPlanner
    ActionPlanner --> IntentAnalyzer
    IntentAnalyzer --> ParameterExtractor
    ParameterExtractor --> ToolSelector
    
    %% Execution routing
    ToolSelector --> MemoryService
    ToolSelector --> AIService
    ToolSelector --> LLMService
    ToolSelector --> ToolExecution
    
    StatusCmd --> SystemOps
    HealthCmd --> SystemOps
    GPUCmd --> SystemOps
    MemoryCmd --> MemoryService
    ModelsCmd --> AIService
    
    %% Response handling
    MemoryService --> ProgressBar
    AIService --> ProgressBar
    LLMService --> ProgressBar
    ToolExecution --> ProgressBar
    SystemOps --> ProgressBar
    
    ProgressBar --> ResultFormatter
    ResultFormatter --> ErrorHandler
    
    classDef input fill:#e3f2fd
    classDef commands fill:#f1f8e9
    classDef agent fill:#fff8e1
    classDef execution fill:#fce4ec
    classDef response fill:#f3e5f5
    
    class UserInput,Parser,CommandRouter input
    class ChatCmd,SmartCmd,ToolCmd,StatusCmd,HealthCmd,GPUCmd,MemoryCmd,ModelsCmd commands
    class UnifiedAgent,ActionPlanner,IntentAnalyzer,ParameterExtractor,ToolSelector agent
    class MemoryService,AIService,LLMService,ToolExecution,SystemOps execution
    class ProgressBar,ResultFormatter,ErrorHandler response
```

## 🔄 Data Flow Analysis

### 📊 Main Data Flows

```mermaid
sequenceDiagram
    participant U as User
    participant C as CLI
    participant A as Agent
    participant M as Memory
    participant AI as AI Service
    participant GPU as GPU Manager
    
    U->>C: magray smart "analyze code"
    C->>A: Parse and route command
    A->>A: Analyze intent & plan actions
    A->>M: Search for relevant context
    M->>AI: Request embeddings
    AI->>GPU: Check GPU availability
    GPU-->>AI: GPU ready / fallback to CPU
    AI-->>M: Return embeddings
    M-->>A: Return search results
    A->>AI: Generate response with context
    AI-->>A: Return enhanced response
    A-->>C: Formatted response
    C-->>U: Display result with progress
    
    Note over M: Background: ML promotion runs
    M->>M: Promote important data to Insights
    
    Note over AI: Background: Cache management
    AI->>AI: Cache embeddings for reuse
```

### 🔗 Component Interaction Matrix

| Component | Memory | AI | LLM | Tools | Router | CLI | Common |
|-----------|--------|----|----|-------|--------|-----|--------|
| **Memory** | - | ✅ Strong | ❌ None | ❌ None | ✅ Medium | ✅ Direct | ✅ Foundation |
| **AI** | ✅ Strong | - | ❌ None | ❌ None | ✅ Medium | ✅ Direct | ✅ Foundation |
| **LLM** | ❌ None | ❌ None | - | ❌ None | ✅ Strong | ✅ Direct | ✅ Foundation |
| **Tools** | ❌ None | ❌ None | ❌ None | - | ✅ Strong | ✅ Direct | ✅ Foundation |
| **Router** | ✅ Medium | ✅ Medium | ✅ Strong | ✅ Strong | - | ✅ Direct | ✅ Foundation |
| **CLI** | ✅ Direct | ✅ Direct | ✅ Direct | ✅ Direct | ✅ Direct | - | ✅ Foundation |

**Legend:**
- ✅ **Strong**: Tight coupling, direct API calls
- ✅ **Medium**: Moderate coupling, occasional interaction
- ✅ **Direct**: Command-level integration
- ✅ **Foundation**: Infrastructure dependency
- ❌ **None**: No direct interaction

## 🏥 Health Monitoring Network

### 📊 Health Check Flow

```mermaid
graph TB
    subgraph "Health Collectors"
        VectorHealth[📊 Vector Store Health]
        CacheHealth[⚡ Cache Health] 
        GPUHealth[🎮 GPU Health]
        AIHealth[🤖 AI Model Health]
        DatabaseHealth[🗄️ Database Health]
    end
    
    subgraph "Health Aggregation"
        HealthMonitor[🏥 Health Monitor<br/>Central Collector]
        MetricsCollector[📈 Metrics Collector<br/>Time Series Data]
        AlertManager[🚨 Alert Manager<br/>Threshold Monitoring]
    end
    
    subgraph "Notification System"
        Notifications[📢 Notification System<br/>Alert Distribution]
        StatusDisplay[📊 Status Display<br/>CLI Output]
        HealthEndpoint[🌐 Health Endpoint<br/>HTTP Check]
    end
    
    %% Collection flows
    VectorHealth --> HealthMonitor
    CacheHealth --> HealthMonitor
    GPUHealth --> HealthMonitor
    AIHealth --> HealthMonitor
    DatabaseHealth --> HealthMonitor
    
    %% Aggregation flows
    HealthMonitor --> MetricsCollector
    HealthMonitor --> AlertManager
    MetricsCollector --> AlertManager
    
    %% Notification flows
    AlertManager --> Notifications
    HealthMonitor --> StatusDisplay
    HealthMonitor --> HealthEndpoint
    
    classDef collectors fill:#e8f5e8
    classDef aggregation fill:#e1f5fe
    classDef notifications fill:#fff3e0
    
    class VectorHealth,CacheHealth,GPUHealth,AIHealth,DatabaseHealth collectors
    class HealthMonitor,MetricsCollector,AlertManager aggregation
    class Notifications,StatusDisplay,HealthEndpoint notifications
```

### 🎯 Health Check Dependencies

| Health Component | Monitors | Dependencies | Update Frequency |
|------------------|----------|--------------|------------------|
| **Vector Store Health** | HNSW performance, search latency | Vector Index, Database | 30s |
| **GPU Health** | VRAM usage, temperature, errors | GPU Detector, Memory Pool | 15s |
| **Cache Health** | Hit rate, memory usage, evictions | LRU Cache, Database | 60s |
| **AI Model Health** | Inference time, error rate, throughput | ONNX Runtime, GPU | 30s |
| **Database Health** | Connection, disk space, query time | Sled DB | 60s |

## 🛠️ Development & Build Dependencies

### 📦 Build Dependency Graph

```mermaid
graph TB
    subgraph "External Dependencies"
        Tokio[tokio - Async Runtime]
        Sled[sled - Database]
        ONNX[ort - ONNX Runtime]
        HNSW[hnsw_rs - Vector Index]
        Clap[clap - CLI Parsing]
        Anyhow[anyhow - Error Handling]
    end
    
    subgraph "Workspace Crates"
        Common[common - Foundation]
        Memory[memory - Vector Storage]
        AI[ai - ONNX Models]
        LLM[llm - Multi-provider]
        Tools[tools - Safe Execution]
        Router[router - Smart Routing]
        Todo[todo - Task System]
        CLI[cli - User Interface]
    end
    
    %% External dependencies
    Memory --> Sled
    Memory --> HNSW
    AI --> ONNX
    CLI --> Clap
    
    %% Workspace dependencies
    Memory --> Common
    AI --> Common
    LLM --> Common
    Tools --> Common
    Router --> Common
    Todo --> Common
    CLI --> Common
    
    CLI --> Memory
    CLI --> AI
    CLI --> LLM
    CLI --> Tools
    CLI --> Router
    CLI --> Todo
    
    Router --> Memory
    Router --> LLM
    Router --> Tools
    
    Memory --> AI
    
    %% Async runtime
    Memory --> Tokio
    AI --> Tokio
    LLM --> Tokio
    Tools --> Tokio
    Router --> Tokio
    CLI --> Tokio
    
    %% Error handling
    Memory --> Anyhow
    AI --> Anyhow
    LLM --> Anyhow
    Tools --> Anyhow
    Router --> Anyhow
    CLI --> Anyhow
    Common --> Anyhow
    
    classDef external fill:#ffebee
    classDef workspace fill:#e8f5e8
    
    class Tokio,Sled,ONNX,HNSW,Clap,Anyhow external
    class Common,Memory,AI,LLM,Tools,Router,Todo,CLI workspace
```

## 🔍 Critical Path Analysis

### ⚡ Performance Critical Paths

**Path 1: Search Query Processing**
```
User Input → CLI → Agent → Memory → HNSW Index → Results
Latency: <5ms target, <1ms goal
```

**Path 2: Embedding Generation**  
```
Text Input → AI → GPU/CPU → ONNX Model → Vector → Cache
Latency: <50ms CPU, <15ms GPU
```

**Path 3: Memory Promotion**
```
Background → ML Engine → Time Analysis → Layer Transfer → Index Update
Frequency: Every 10 minutes
```

### 🚨 Failure Points & Fallbacks

| Critical Component | Failure Mode | Fallback Strategy | Recovery Time |
|-------------------|--------------|-------------------|---------------|
| **GPU Processing** | VRAM exhaustion | CPU fallback | <100ms |
| **Vector Index** | Index corruption | Rebuild from DB | 1-5 minutes |
| **Database** | Connection loss | Retry with backoff | <30s |
| **Cache System** | Memory pressure | LRU eviction | Immediate |
| **ONNX Runtime** | Model load fail | Alternative model | <10s |

## 📊 Component Status Dashboard

### 🎯 Ready for Production

| Component | Status | Test Coverage | Documentation | Production Score |
|-----------|--------|---------------|---------------|------------------|
| **[[HNSW Vector Index]]** | ✅ Ready | 90% | 85% | 95% |
| **[[GPU Batch Processor]]** | ✅ Ready | 80% | 80% | 90% |
| **[[ML Promotion Engine]]** | ✅ Ready | 85% | 75% | 85% |
| **[[Adaptive Progress]]** | ✅ Ready | 95% | 90% | 95% |
| **[[Health Monitor]]** | ✅ Ready | 70% | 80% | 80% |
| **[[Streaming API]]** | ✅ Ready | 75% | 70% | 75% |

### 🔄 In Development

| Component | Status | Implementation | ETA | Priority |
|-----------|--------|----------------|-----|----------|
| **[[DI Container]]** | 🚧 Planned | 0% | Q2 2025 | Medium |
| **[[Orchestration System]]** | 🚧 Planned | 0% | Q2 2025 | High |
| **[[Error Monitor]]** | 🚧 Planned | 0% | Q1 2025 | High |
| **[[Resource Controller]]** | 🚧 Planned | 0% | Q2 2025 | Medium |

### ❌ Missing but Planned

| Component | Reason | Impact | Workaround |
|-----------|--------|--------|------------|
| **Migration System** | Not prioritized | Medium | Manual DB updates |
| **Advanced Monitoring** | Basic version sufficient | Low | Current health checks |
| **Kubernetes Integration** | Single-binary focus | Low | Docker containers |
| **Multi-tenant Support** | Not required yet | None | Single-user focus |

## 🔗 Navigation Links

### 📚 Detailed Component Documentation
- [[Memory Crate - Трёхслойная система памяти]] - Memory system details
- [[AI Crate - Embedding и модели]] - AI/ML pipeline  
- [[CLI Crate - Пользовательский интерфейс]] - Command interface (TODO)
- [[LLM Crate - Языковые модели]] - Language model integration (TODO)

### 🎯 Architectural Views
- [[Полная архитектурная документация MAGRAY CLI]] - Complete architecture
- [[Состояние готовности компонентов]] - Component status matrix
- [[Roadmap развития проекта]] - Development roadmap

### 🛠️ Technical Guides
- [[Руководство по установке и использованию]] - Installation guide
- [[Performance Optimization Guide]] - Performance tuning (TODO)
- [[Troubleshooting Guide]] - Problem resolution (TODO)

---

*Создано: 05.08.2025*  
*Основано на полном анализе архитектуры MAGRAY CLI*  
*Все связи и зависимости проверены в коде*