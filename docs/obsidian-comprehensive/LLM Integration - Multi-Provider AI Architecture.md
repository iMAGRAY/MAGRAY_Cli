# LLM Integration - Multi-Provider AI Architecture

*MAGRAY CLI - Production-Ready LLM Integration System*

**–°—Ç–∞—Ç—É—Å –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞**: üü° –í —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ (80% –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏)  
**–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç**: –í—ã—Å–æ–∫–∏–π  
**–ü–æ—Å–ª–µ–¥–Ω–µ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ**: 2025-08-05

## üìã –û–±–∑–æ—Ä —Å–∏—Å—Ç–µ–º—ã

LLM Crate –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å–æ–±–æ–π –º–Ω–æ–≥–æ–ø—Ä–æ–≤–∞–π–¥–µ—Ä–Ω—É—é —Å–∏—Å—Ç–µ–º—É –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Å –∫—Ä—É–ø–Ω—ã–º–∏ —è–∑—ã–∫–æ–≤—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏, –æ–±–µ—Å–ø–µ—á–∏–≤–∞—é—â—É—é –µ–¥–∏–Ω—ã–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å OpenAI, Anthropic –∏ –ª–æ–∫–∞–ª—å–Ω—ã–º–∏ LLM –º–æ–¥–µ–ª—è–º–∏. –°–∏—Å—Ç–µ–º–∞ –≤–∫–ª—é—á–∞–µ—Ç —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö AI –∞–≥–µ–Ω—Ç–æ–≤ –¥–ª—è —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –∑–∞–¥–∞—á –∏ smart routing –¥–ª—è –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ –≤—ã–±–æ—Ä–∞ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤.

### üîó –°–≤—è–∑–∞–Ω–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
- [[Memory Crate - –¢—Ä—ë—Ö—Å–ª–æ–π–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –ø–∞–º—è—Ç–∏]] - –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –ø–∞–º—è—Ç–∏
- [[CLI Interface - Commands & User Experience]] - –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å
- [[–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Å–∏—Å—Ç–µ–º—ã - –î–µ—Ç–∞–ª—å–Ω—ã–π –æ–±–∑–æ—Ä]] - –æ–±—â–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞

## üèóÔ∏è –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω–∞—è —Å—Ö–µ–º–∞

```mermaid
graph TB
    subgraph "LLM Integration Layer"
        LC[LlmClient] --> OAI[OpenAI Provider]
        LC --> ANT[Anthropic Provider]  
        LC --> LOC[Local LLM Provider]
    end
    
    subgraph "AI Agents System"
        IA[IntentAnalyzerAgent] --> LC
        TS[ToolSelectorAgent] --> LC
        PE[ParameterExtractorAgent] --> LC
        AP[ActionPlannerAgent] --> LC
    end
    
    subgraph "Smart Routing"
        SR[SmartRouter] --> IA
        SR --> TS
        SR --> PE
        SR --> AP
        SR --> TR[ToolRegistry]
    end
    
    subgraph "Orchestration"
        UA[UnifiedAgent] --> LC
        UA --> SR
        UA --> MS[MemoryService]
    end
    
    subgraph "External APIs"
        OAI --> OAPI[OpenAI API]
        ANT --> AAPI[Anthropic API]
        LOC --> LAPI[Local LLM Server]
    end
```

## üîß –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã —Å–∏—Å—Ç–µ–º—ã –∏ –∏—Ö —Å—Ç–∞—Ç—É—Å

### 1. Multi-Provider LLM Client
**–§–∞–π–ª**: `crates/llm/src/lib.rs`  
**CTL –ê–Ω–Ω–æ—Ç–∞—Ü–∏—è**: `@component: {"k":"C","id":"llm_client","t":"Multi-provider LLM client","m":{"cur":80,"tgt":95,"u":"%"},"f":["llm","agents","multi-provider"]}`

```rust
pub enum LlmProvider {
    OpenAI { api_key: String, model: String },
    Anthropic { api_key: String, model: String },
    Local { url: String, model: String },
}

pub struct LlmClient {
    provider: LlmProvider,
    client: reqwest::Client,
    max_tokens: u32,
    temperature: f32,
}
```

**–í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏**:
- ‚úÖ –ü–æ–¥–¥–µ—Ä–∂–∫–∞ OpenAI GPT –º–æ–¥–µ–ª–µ–π (gpt-4o-mini –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)
- ‚úÖ –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å Anthropic Claude (claude-3-haiku-20240307)
- ‚úÖ –†–∞–±–æ—Ç–∞ —Å –ª–æ–∫–∞–ª—å–Ω—ã–º–∏ LLM —á–µ—Ä–µ–∑ OpenAI-compatible API
- ‚úÖ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —á–µ—Ä–µ–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
- ‚úÖ –ï–¥–∏–Ω—ã–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è –≤—Å–µ—Ö –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤

**–ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ features**:
- ‚ùå Rate limiting –∏ retry –ª–æ–≥–∏–∫–∞
- ‚ùå Streaming responses
- ‚ùå Request/response caching
- ‚ùå Load balancing –º–µ–∂–¥—É –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞–º–∏
- ‚ùå Metrics –∏ monitoring

### 2. Specialized AI Agents
**–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è**: `crates/llm/src/agents/`

#### IntentAnalyzerAgent üéØ
**–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ**: –ê–Ω–∞–ª–∏–∑ –Ω–∞–º–µ—Ä–µ–Ω–∏–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –¥–ª—è –≤—ã–±–æ—Ä–∞ –º–µ–∂–¥—É chat –∏ tools —Ä–µ–∂–∏–º–∞–º–∏

```rust
pub struct IntentDecision {
    pub action_type: String, // "chat" –∏–ª–∏ "tools"
    pub confidence: f32,
    pub reasoning: String,
}
```

**–ö—Ä–∏—Ç–µ—Ä–∏–∏ –¥–ª—è tools**:
- –†–∞–±–æ—Ç–∞ —Å —Ñ–∞–π–ª–∞–º–∏: "—Å–æ–∑–¥–∞–π —Ñ–∞–π–ª", "–ø—Ä–æ—á–∏—Ç–∞–π —Ñ–∞–π–ª"
- Git –æ–ø–µ—Ä–∞—Ü–∏–∏: "git status", "—Å–¥–µ–ª–∞–π –∫–æ–º–º–∏—Ç"
- –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∫–æ–º–∞–Ω–¥: "–≤—ã–ø–æ–ª–Ω–∏ –∫–æ–º–∞–Ω–¥—É", "cargo build"
- –ü–æ–∏—Å–∫ –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ: "–Ω–∞–π–¥–∏ –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ"

#### ToolSelectorAgent üîß
**–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ**: –í—ã–±–æ—Ä –ø–æ–¥—Ö–æ–¥—è—â–µ–≥–æ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞ –∏–∑ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö

```rust
pub struct ToolSelection {
    pub tool_name: String,
    pub confidence: f32,
    pub reasoning: String,
}
```

#### ParameterExtractorAgent üì•
**–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ**: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–ª—è –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞

```rust
pub struct ParameterExtraction {
    pub parameters: HashMap<String, String>,
    pub confidence: f32,
    pub missing_params: Vec<String>,
}
```

#### ActionPlannerAgent üìã
**–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ**: –°–æ–∑–¥–∞–Ω–∏–µ –º–Ω–æ–≥–æ—à–∞–≥–æ–≤–æ–≥–æ –ø–ª–∞–Ω–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —Å–ª–æ–∂–Ω—ã—Ö –∑–∞–¥–∞—á

```rust
pub struct ActionPlan {
    pub reasoning: String,
    pub steps: Vec<PlanStep>,
    pub confidence: f32,
}
```

### 3. Smart Router System
**–§–∞–π–ª**: `crates/router/src/lib.rs`  
**CTL –ê–Ω–Ω–æ—Ç–∞—Ü–∏—è**: `@component: {"k":"C","id":"smart_router","t":"Smart task orchestration","m":{"cur":70,"tgt":90,"u":"%"},"d":["llm_client","tools"],"f":["routing","orchestration"]}`

**–†–µ–∂–∏–º—ã —Ä–∞–±–æ—Ç—ã**:
1. **Single Tool Request** - –¥–ª—è –ø—Ä–æ—Å—Ç—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
   - –í—ã–±–æ—Ä –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞ ‚Üí –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ ‚Üí –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ
2. **Multi-Step Planning** - –¥–ª—è —Å–ª–æ–∂–Ω—ã—Ö –∑–∞–¥–∞—á
   - –ê–Ω–∞–ª–∏–∑ ‚Üí –ü–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ ‚Üí –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ

### 4. Unified Agent Orchestrator
**–§–∞–π–ª**: `crates/cli/src/agent.rs`  
**CTL –ê–Ω–Ω–æ—Ç–∞—Ü–∏—è**: `@component: {"k":"C","id":"unified_agent","t":"Main agent orchestrator","m":{"cur":70,"tgt":95,"u":"%"},"d":["llm_client","smart_router","di_memory_service"]}`

```rust
pub struct UnifiedAgent {
    llm_client: LlmClient,
    smart_router: SmartRouter,
    intent_analyzer: IntentAnalyzerAgent,
    memory_service: DIMemoryService,
}
```

## ‚öôÔ∏è –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ —Å—Ö–µ–º—ã

### Environment Variables Configuration

```bash
# Provider Selection
LLM_PROVIDER=openai          # openai | anthropic | local
MAX_TOKENS=1000              # Default: 1000
TEMPERATURE=0.7              # Default: 0.7

# OpenAI Configuration
OPENAI_API_KEY=sk-...        # Required for OpenAI
OPENAI_MODEL=gpt-4o-mini     # Default model

# Anthropic Configuration  
ANTHROPIC_API_KEY=ant-...    # Required for Anthropic
ANTHROPIC_MODEL=claude-3-haiku-20240307

# Local LLM Configuration
LOCAL_LLM_URL=http://localhost:1234/v1    # Local server URL
LOCAL_LLM_MODEL=llama-3.2-3b-instruct     # Model name
```

### Provider-Specific Settings

#### OpenAI Provider
- **Base URL**: `https://api.openai.com/v1/chat/completions`
- **Headers**: `Authorization: Bearer {api_key}`
- **–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ –º–æ–¥–µ–ª–∏**: gpt-4o-mini, gpt-4, gpt-3.5-turbo
- **Rate Limits**: –ó–∞–≤–∏—Å—è—Ç –æ—Ç plan (RPM/TPM –ª–∏–º–∏—Ç—ã)

#### Anthropic Provider  
- **Base URL**: `https://api.anthropic.com/v1/messages`
- **Headers**: 
  - `Authorization: Bearer {api_key}`
  - `anthropic-version: 2023-06-01`
- **–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ –º–æ–¥–µ–ª–∏**: claude-3-haiku, claude-3-sonnet, claude-3-opus
- **Rate Limits**: Message-based pricing

#### Local LLM Provider
- **Base URL**: –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º—ã–π (–Ω–∞–ø—Ä–∏–º–µ—Ä, LM Studio)
- **–°–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å**: OpenAI-compatible API
- **–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã**: llama.cpp, ollama, vLLM
- **No Rate Limits**: –ó–∞–≤–∏—Å–∏—Ç –æ—Ç –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ —Å–µ—Ä–≤–µ—Ä–∞

## üîÑ Request Flow –∏ Processing Patterns

### 1. Intent Analysis Flow
```mermaid
sequenceDiagram
    participant User
    participant UA as UnifiedAgent
    participant IA as IntentAnalyzer
    participant LC as LlmClient
    
    User->>UA: "—Å–æ–∑–¥–∞–π —Ñ–∞–π–ª main.rs"
    UA->>IA: analyze_intent()
    IA->>LC: chat_simple(prompt)
    LC->>IA: JSON decision
    IA->>UA: {action_type: "tools", confidence: 0.9}
    UA->>UA: route to SmartRouter
```

### 2. Tool Execution Flow
```mermaid
sequenceDiagram
    participant SR as SmartRouter
    participant TS as ToolSelector
    participant PE as ParameterExtractor
    participant TR as ToolRegistry
    
    SR->>TS: select_tool()
    TS->>SR: {tool_name: "file_write", confidence: 0.95}
    SR->>PE: extract_parameters()
    PE->>SR: {path: "main.rs", content: "..."}
    SR->>TR: execute_tool()
    TR->>SR: ToolOutput
```

## üö´ –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ Production Features

### Rate Limiting –∏ Retry Logic
**–°—Ç–∞—Ç—É—Å**: ‚ùå –ù–µ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω  
**–ö—Ä–∏—Ç–∏—á–Ω–æ—Å—Ç—å**: –í—ã—Å–æ–∫–∞—è

```rust
// –û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ —Ç–µ–∫—É—â–µ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏
pub struct RateLimiter {
    requests_per_minute: u32,
    requests_per_day: u32,
    current_usage: Usage,
}

pub struct RetryConfig {
    max_retries: u8,
    backoff_strategy: BackoffStrategy,
    retryable_errors: Vec<ErrorType>,
}
```

### Streaming Support
**–°—Ç–∞—Ç—É—Å**: ‚ùå –ù–µ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω  
**–í–∞–∂–Ω–æ—Å—Ç—å**: –°—Ä–µ–¥–Ω—è—è

```rust
// –¢—Ä–µ–±—É–µ—Ç—Å—è –¥–ª—è real-time responses
pub async fn stream_completion(&self, request: CompletionRequest) 
    -> Result<impl Stream<Item = Result<String>>>
```

### Caching System  
**–°—Ç–∞—Ç—É—Å**: ‚ùå –ù–µ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω  
**–í–∞–∂–Ω–æ—Å—Ç—å**: –í—ã—Å–æ–∫–∞—è –¥–ª—è cost optimization

### Load Balancing
**–°—Ç–∞—Ç—É—Å**: ‚ùå –ù–µ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω  
**–í–∞–∂–Ω–æ—Å—Ç—å**: –°—Ä–µ–¥–Ω—è—è

## üîí Error Handling Strategies

### Current Implementation
- –ë–∞–∑–æ–≤–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ HTTP –æ—à–∏–±–æ–∫
- –ü—Ä–æ—Å—Ç–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞—Ç—É—Å–∞ –æ—Ç–≤–µ—Ç–∞
- JSON parsing —Å fallback

### Required Improvements
1. **Provider-specific error handling**
2. **Graceful degradation** –º–µ–∂–¥—É –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞–º–∏
3. **Circuit breaker pattern** –¥–ª—è failing providers
4. **Comprehensive error categorization**

```rust
// –¢—Ä–µ–±—É–µ–º–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –æ—à–∏–±–æ–∫
#[derive(Debug, thiserror::Error)]
pub enum LlmError {
    #[error("Rate limit exceeded for provider {provider}")]
    RateLimitExceeded { provider: String, retry_after: Duration },
    
    #[error("Provider {provider} is temporarily unavailable")]
    ProviderUnavailable { provider: String },
    
    #[error("Authentication failed for provider {provider}")]
    AuthenticationFailed { provider: String },
}
```

## üìä Performance Optimization Strategies

### Request Batching
**–°—Ç–∞—Ç—É—Å**: –ß–∞—Å—Ç–∏—á–Ω–æ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω –≤ memory integration  
**–ü—Ä–∏–º–µ–Ω–∏–º–æ—Å—Ç—å**: Tool execution, context processing

### Response Caching
**–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏**:
- TTL-based cache –¥–ª—è repeated queries
- Content-based hashing –¥–ª—è cache keys
- Memory-efficient storage

### Connection Pooling
**–¢–µ–∫—É—â–∏–π —Å—Ç–∞—Ç—É—Å**: –ò—Å–ø–æ–ª—å–∑—É–µ—Ç reqwest::Client (built-in pooling)  
**–£–ª—É—á—à–µ–Ω–∏—è**: Custom pool configuration, connection limits

## üß† Memory Integration Patterns

### Context Management
- –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å [[Memory Crate - –¢—Ä—ë—Ö—Å–ª–æ–π–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –ø–∞–º—è—Ç–∏]]
- –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ conversation context
- Vector-based context retrieval –¥–ª—è relevant history

### Conversation State
```rust
pub struct ConversationContext {
    pub messages: Vec<ChatMessage>,
    pub session_id: String,
    pub created_at: DateTime<Utc>,
    pub metadata: HashMap<String, String>,
}
```

## üí∞ Cost Optimization Guidelines

### Provider Cost Comparison
| Provider | Input Cost (1M tokens) | Output Cost (1M tokens) | Notes |
|----------|------------------------|--------------------------|-------|
| OpenAI GPT-4o-mini | $0.15 | $0.60 | –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –¥–ª—è production |
| Anthropic Claude-3-Haiku | $0.25 | $1.25 | –ë—ã—Å—Ç—Ä—ã–µ responses |
| Local LLM | $0.00 | $0.00 | –¢–æ–ª—å–∫–æ compute costs |

### Optimization Strategies
1. **Model Selection**: –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ smaller models –¥–ª—è simple tasks
2. **Token Management**: –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–π—Ç–µ max_tokens –¥–ª—è cost control
3. **Caching**: –ò–∑–±–µ–≥–∞–π—Ç–µ duplicate requests
4. **Local Fallback**: –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ local models –¥–ª—è development

## üîß Best Practices –¥–ª—è Production

### Configuration Management
```rust
pub struct LlmConfig {
    pub primary_provider: LlmProvider,
    pub fallback_providers: Vec<LlmProvider>,
    pub timeout: Duration,
    pub retry_config: RetryConfig,
    pub rate_limits: HashMap<String, RateLimit>,
}
```

### Monitoring –∏ Observability
- Request/response logging
- Latency metrics –ø–æ provider
- Error rate tracking
- Cost monitoring

### Security Considerations
- API key rotation strategies
- Request sanitization
- Response filtering –¥–ª—è sensitive data
- Audit logging

## üöß Development Status –∏ Roadmap

### –¢–µ–∫—É—â–∏–π —Å—Ç–∞—Ç—É—Å (80% –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏)
- ‚úÖ Multi-provider client architecture
- ‚úÖ Specialized AI agents system  
- ‚úÖ Basic smart routing
- ‚úÖ Environment-based configuration
- ‚úÖ Error handling foundations

### –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ gap'—ã –¥–ª—è production
1. **Rate limiting implementation** - –≤—ã—Å–æ–∫–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç
2. **Retry logic —Å exponential backoff** - –≤—ã—Å–æ–∫–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç  
3. **Provider fallback strategies** - —Å—Ä–µ–¥–Ω–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç
4. **Streaming support** - —Å—Ä–µ–¥–Ω–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç
5. **Comprehensive testing** - –≤—ã—Å–æ–∫–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç

### –°–ª–µ–¥—É—é—â–∏–µ —Å–ø—Ä–∏–Ω—Ç—ã
- [ ] Implement rate limiting –¥–ª—è –≤—Å–µ—Ö providers
- [ ] Add retry mechanism —Å circuit breaker
- [ ] Create comprehensive test suite
- [ ] Add streaming support –¥–ª—è real-time responses
- [ ] Implement response caching system

## üîó –°–≤—è–∑–∞–Ω–Ω—ã–µ —Ä–µ—Å—É—Ä—Å—ã

### Internal Links
- [[Memory Crate - –¢—Ä—ë—Ö—Å–ª–æ–π–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –ø–∞–º—è—Ç–∏#Memory Integration]] - –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º
- [[CLI Interface - Commands & User Experience#Agent Commands]] - CLI –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å
- [[Production –º–µ—Ç—Ä–∏–∫–∏ –∏ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥#LLM Metrics]] - –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ LLM calls

### External Documentation
- [OpenAI API Documentation](https://platform.openai.com/docs/api-reference)
- [Anthropic Claude API](https://docs.anthropic.com/claude/reference)
- [LM Studio Local API](https://lmstudio.ai/docs/local-api)

### Code References
- `crates/llm/src/lib.rs` - –æ—Å–Ω–æ–≤–Ω–æ–π LLM client
- `crates/llm/src/agents/` - specialized agents
- `crates/router/src/lib.rs` - smart routing system
- `crates/cli/src/agent.rs` - unified orchestrator

---

*–î–æ–∫—É–º–µ–Ω—Ç —Å–æ–∑–¥–∞–Ω –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏–∑ –∞–Ω–∞–ª–∏–∑–∞ –∫–æ–¥–æ–≤–æ–π –±–∞–∑—ã MAGRAY CLI*  
*–°—Ç–∞—Ç—É—Å –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ –º–æ–∂–µ—Ç –∏–∑–º–µ–Ω—è—Ç—å—Å—è, –ø—Ä–æ–≤–µ—Ä—è–π—Ç–µ –∞–∫—Ç—É–∞–ª—å–Ω—ã–µ CTL –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏*