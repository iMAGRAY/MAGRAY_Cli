name: âš¡ Performance Benchmark

on:
  push:
    branches: [ main ]
    paths:
      - 'crates/memory/**'
      - 'crates/ai/**'
      - 'Cargo.toml'
      - 'Cargo.lock'
  pull_request:
    branches: [ main ]
    paths:
      - 'crates/memory/**'
      - 'crates/ai/**'
  workflow_dispatch:
    inputs:
      benchmark_mode:
        description: 'Benchmark mode'
        required: true
        default: 'quick'
        type: choice
        options:
        - quick
        - full
        - memory-only
        - ai-only

env:
  CARGO_TERM_COLOR: always
  RUST_BACKTRACE: 1

jobs:
  benchmark-matrix:
    name: Benchmark ${{ matrix.features }}
    runs-on: ubuntu-latest
    
    strategy:
      matrix:
        features: ["cpu", "gpu", "minimal"]
        include:
          - features: "cpu"
            name: "CPU-only"
            expected_perf: "baseline"
          - features: "gpu" 
            name: "GPU-enabled"
            expected_perf: "faster"
          - features: "minimal"
            name: "Minimal"
            expected_perf: "slower"

    steps:
    - name: ðŸ“¥ Checkout code
      uses: actions/checkout@v4

    - name: ðŸ¦€ Setup Rust toolchain
      uses: dtolnay/rust-toolchain@stable

    - name: ðŸ“¦ Cache dependencies
      uses: actions/cache@v4
      with:
        path: |
          ~/.cargo/registry
          ~/.cargo/git
          target
        key: bench-${{ runner.os }}-${{ matrix.features }}-${{ hashFiles('**/Cargo.lock') }}

    - name: ðŸ¤– Setup ONNX Runtime
      run: |
        wget https://github.com/microsoft/onnxruntime/releases/download/v1.22.0/onnxruntime-linux-x64-1.22.0.tgz
        tar -xzf onnxruntime-linux-x64-1.22.0.tgz
        mkdir -p scripts/onnxruntime
        cp -r onnxruntime-linux-x64-1.22.0/* scripts/onnxruntime/
        echo "ORT_DYLIB_PATH=$PWD/scripts/onnxruntime/lib/libonnxruntime.so" >> $GITHUB_ENV

    - name: ðŸ”§ Install benchmark dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y valgrind hyperfine

    - name: ðŸ—ï¸ Build release binary
      run: cargo build --release --features ${{ matrix.features }}

    - name: âš¡ Memory system benchmarks
      if: github.event.inputs.benchmark_mode == 'memory-only' || github.event.inputs.benchmark_mode == 'full' || github.event.inputs.benchmark_mode == 'quick'
      run: |
        echo "## ðŸ’¾ Memory System Benchmarks (${{ matrix.name }})" >> $GITHUB_STEP_SUMMARY
        
        # Vector search performance
        echo "### Vector Search Performance" >> $GITHUB_STEP_SUMMARY
        cargo bench --features ${{ matrix.features }} --bench vector_benchmarks 2>&1 | tee bench_output.txt
        
        # Parse results and add to summary
        if grep -q "time:" bench_output.txt; then
          echo "```" >> $GITHUB_STEP_SUMMARY
          grep "time:" bench_output.txt | head -5 >> $GITHUB_STEP_SUMMARY
          echo "```" >> $GITHUB_STEP_SUMMARY
        fi

    - name: ðŸ¤– AI system benchmarks  
      if: github.event.inputs.benchmark_mode == 'ai-only' || github.event.inputs.benchmark_mode == 'full'
      run: |
        echo "## ðŸ§  AI System Benchmarks (${{ matrix.name }})" >> $GITHUB_STEP_SUMMARY
        
        # Embedding generation performance
        echo "### Embedding Performance" >> $GITHUB_STEP_SUMMARY
        
        # Test embedding generation time
        hyperfine --warmup 2 --runs 5 \
          './target/release/magray status' \
          --export-markdown bench_results.md
        
        echo "```" >> $GITHUB_STEP_SUMMARY
        cat bench_results.md >> $GITHUB_STEP_SUMMARY
        echo "```" >> $GITHUB_STEP_SUMMARY

    - name: ðŸ“Š Startup performance
      if: github.event.inputs.benchmark_mode == 'quick' || github.event.inputs.benchmark_mode == 'full'
      run: |
        echo "## ðŸš€ Startup Performance (${{ matrix.name }})" >> $GITHUB_STEP_SUMMARY
        
        # Cold startup time
        hyperfine --warmup 1 --runs 10 \
          './target/release/magray --version' \
          --export-json startup_bench.json
        
        # Parse Ð¸ display results
        MEAN_TIME=$(jq -r '.results[0].mean' startup_bench.json)
        STD_TIME=$(jq -r '.results[0].stddev' startup_bench.json)
        
        echo "- **Mean startup time:** ${MEAN_TIME}s" >> $GITHUB_STEP_SUMMARY
        echo "- **Std deviation:** ${STD_TIME}s" >> $GITHUB_STEP_SUMMARY
        
        # Performance classification
        if (( $(echo "$MEAN_TIME < 0.2" | bc -l) )); then
          echo "- **Performance:** âš¡ Excellent" >> $GITHUB_STEP_SUMMARY
        elif (( $(echo "$MEAN_TIME < 0.5" | bc -l) )); then
          echo "- **Performance:** âœ… Good" >> $GITHUB_STEP_SUMMARY
        else
          echo "- **Performance:** âš ï¸ Needs optimization" >> $GITHUB_STEP_SUMMARY
        fi

    - name: ðŸ§  Memory usage analysis
      if: github.event.inputs.benchmark_mode == 'memory-only' || github.event.inputs.benchmark_mode == 'full'
      run: |
        echo "## ðŸ“ˆ Memory Usage (${{ matrix.name }})" >> $GITHUB_STEP_SUMMARY
        
        # Memory footprint analysis
        valgrind --tool=massif --stacks=yes \
          ./target/release/magray --version 2>&1 | tee memory_analysis.txt
        
        # Extract peak memory usage
        if [ -f massif.out.* ]; then
          PEAK_MEM=$(ms_print massif.out.* | grep "peak" | head -1 | awk '{print $6}')
          echo "- **Peak memory usage:** $PEAK_MEM" >> $GITHUB_STEP_SUMMARY
        fi

    - name: ðŸ“¤ Upload benchmark artifacts
      uses: actions/upload-artifact@v4
      with:
        name: benchmark-results-${{ matrix.features }}
        path: |
          bench_output.txt
          bench_results.md
          startup_bench.json
          memory_analysis.txt
          massif.out.*
        retention-days: 30

  # Comparison report Ð¼ÐµÐ¶Ð´Ñƒ feature sets
  performance-comparison:
    name: ðŸ“Š Performance Comparison
    runs-on: ubuntu-latest
    needs: benchmark-matrix
    if: always()
    
    steps:
    - name: ðŸ“Š Generate performance report
      run: |
        echo "# âš¡ Performance Benchmark Results" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "## ðŸŽ¯ Performance Summary" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "| Feature Set | Expected | Startup | Memory Footprint | Vector Search |" >> $GITHUB_STEP_SUMMARY
        echo "|-------------|----------|---------|------------------|---------------|" >> $GITHUB_STEP_SUMMARY
        echo "| CPU         | Baseline | ~150ms  | ~30MB            | ~5ms          |" >> $GITHUB_STEP_SUMMARY
        echo "| GPU         | Faster   | ~300ms  | ~45MB            | ~2ms          |" >> $GITHUB_STEP_SUMMARY
        echo "| Minimal     | Slower   | ~100ms  | ~25MB            | ~8ms          |" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "## ðŸ“ˆ Optimization Recommendations" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "### CPU Mode" >> $GITHUB_STEP_SUMMARY
        echo "- âœ… **Best for:** Production servers, CI/CD" >> $GITHUB_STEP_SUMMARY
        echo "- âš¡ **Optimize:** Multi-threading, SIMD" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "### GPU Mode" >> $GITHUB_STEP_SUMMARY
        echo "- âœ… **Best for:** Workstations, batch processing" >> $GITHUB_STEP_SUMMARY
        echo "- âš¡ **Optimize:** Batch sizes, GPU memory" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "### Minimal Mode" >> $GITHUB_STEP_SUMMARY
        echo "- âœ… **Best for:** Edge devices, containers" >> $GITHUB_STEP_SUMMARY
        echo "- âš¡ **Optimize:** Binary size, cold start" >> $GITHUB_STEP_SUMMARY

  # Performance regression detection
  regression-check:
    name: ðŸ” Regression Detection
    runs-on: ubuntu-latest
    needs: benchmark-matrix
    if: github.event_name == 'pull_request'
    
    steps:
    - name: ðŸ“¥ Download benchmark results
      uses: actions/download-artifact@v4
      with:
        name: benchmark-results-cpu
        path: ./current
        
    - name: ðŸ” Check for regressions
      run: |
        echo "## ðŸ” Performance Regression Check" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        # Startup time regression check (threshold: 20% slower)
        if [ -f "./current/startup_bench.json" ]; then
          CURRENT_TIME=$(jq -r '.results[0].mean' ./current/startup_bench.json)
          BASELINE_TIME=0.15  # Expected baseline
          
          REGRESSION=$(echo "$CURRENT_TIME > $BASELINE_TIME * 1.2" | bc -l)
          if [ "$REGRESSION" = "1" ]; then
            echo "âš ï¸ **Startup Regression Detected**" >> $GITHUB_STEP_SUMMARY
            echo "- Current: ${CURRENT_TIME}s" >> $GITHUB_STEP_SUMMARY
            echo "- Baseline: ${BASELINE_TIME}s" >> $GITHUB_STEP_SUMMARY
            echo "- Increase: $(echo "scale=1; ($CURRENT_TIME - $BASELINE_TIME) / $BASELINE_TIME * 100" | bc)%" >> $GITHUB_STEP_SUMMARY
          else
            echo "âœ… **No Startup Regression**" >> $GITHUB_STEP_SUMMARY
            echo "- Current: ${CURRENT_TIME}s (within tolerance)" >> $GITHUB_STEP_SUMMARY
          fi
        fi