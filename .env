# LLM Configuration
LLM_PROVIDER=openai
OPENAI_API_KEY=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
OPENAI_MODEL=gpt-4.1-mini

# Alternative: Local LLM
# LLM_PROVIDER=local
# LOCAL_LLM_URL=http://localhost:1234/v1
# LOCAL_LLM_MODEL=llama-3.2-3b-instruct

# Alternative: Anthropic
# LLM_PROVIDER=anthropic
# ANTHROPIC_API_KEY=your-anthropic-api-key-here
# ANTHROPIC_MODEL=claude-3-haiku-20240307

# Chat settings
MAX_TOKENS=500
TEMPERATURE=0.7

# ONNX Runtime Configuration
ORT_USE_CUDA=0
RUST_LOG=debug