//! MAGRAY CLI Human-Like Testing System - Main Executable
//! 
//! –ó–∞–ø—É—Å–∫–∞–µ—Ç –ø–æ–ª–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ MAGRAY CLI —Å GPT-5 nano evaluation
//! 
//! Usage:
//!   cargo run --bin magray_testing
//!   cargo run --bin magray_testing -- --type complex_task
//!   cargo run --bin magray_testing -- --scenarios custom_scenarios.yaml

use std::path::Path;
use clap::{Parser, Subcommand};
use anyhow::Result;
use tokio;

// –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –Ω–∞—à–∏ –º–æ–¥—É–ª–∏
mod integration {
    pub mod human_like_testing;
}
mod scenarios {
    pub mod scenario_manager;
}
mod evaluators {
    pub mod gpt5_evaluator;
}
mod reports {
    pub mod test_report_generator;
}

use integration::human_like_testing::TestExecutor;
use scenarios::scenario_manager::ScenarioManager;
use evaluators::gpt5_evaluator::Gpt5Evaluator;
use reports::test_report_generator::TestReportGenerator;

/// MAGRAY CLI Human-Like Testing System
#[derive(Parser)]
#[command(author, version, about, long_about = None)]
struct Cli {
    #[command(subcommand)]
    command: Option<Commands>,

    /// Scenarios file to use (default: complex_scenarios.yaml)
    #[arg(short, long, default_value = "complex_scenarios.yaml")]
    scenarios: String,

    /// Output directory for reports (default: ./test_reports)
    #[arg(short, long, default_value = "./test_reports")]
    output: String,

    /// Only run scenarios of specific type
    #[arg(short = 't', long)]
    scenario_type: Option<String>,

    /// Verbose output
    #[arg(short, long)]
    verbose: bool,

    /// Skip GPT-5 evaluation (faster testing)
    #[arg(long)]
    skip_evaluation: bool,
}

#[derive(Subcommand)]
enum Commands {
    /// Run full test suite
    Run {
        /// Custom scenarios file
        #[arg(short, long)]
        file: Option<String>,
    },
    /// Check system readiness
    Check,
    /// List available scenarios
    List,
    /// Run health check only
    Health,
    /// Generate sample scenarios file
    Sample,
}

#[tokio::main]
async fn main() -> Result<()> {
    env_logger::init();
    
    let cli = Cli::parse();

    // –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –≤–µ—Ä–±–∞–ª—å–Ω–æ–≥–æ –≤—ã–≤–æ–¥–∞
    if cli.verbose {
        println!("üîß Verbose mode enabled");
        println!("üìÅ Scenarios file: {}", cli.scenarios);
        println!("üìÇ Output directory: {}", cli.output);
    }

    match cli.command {
        Some(Commands::Run { file }) => {
            let scenarios_file = file.unwrap_or(cli.scenarios);
            run_test_suite(&scenarios_file, &cli.output, cli.scenario_type, cli.skip_evaluation, cli.verbose).await?;
        }
        Some(Commands::Check) => {
            check_system_readiness(&cli.output).await?;
        }
        Some(Commands::List) => {
            list_scenarios(&cli.scenarios).await?;
        }
        Some(Commands::Health) => {
            run_health_check().await?;
        }
        Some(Commands::Sample) => {
            generate_sample_scenarios().await?;
        }
        None => {
            // Default: run full test suite
            run_test_suite(&cli.scenarios, &cli.output, cli.scenario_type, cli.skip_evaluation, cli.verbose).await?;
        }
    }

    Ok(())
}

/// –ó–∞–ø—É—Å–∫–∞–µ—Ç –ø–æ–ª–Ω—ã–π –Ω–∞–±–æ—Ä —Ç–µ—Å—Ç–æ–≤
async fn run_test_suite(
    scenarios_file: &str,
    output_dir: &str,
    scenario_type: Option<String>,
    skip_evaluation: bool,
    verbose: bool,
) -> Result<()> {
    println!("üöÄ MAGRAY CLI Human-Like Testing System");
    println!("{}", "=".repeat(60));

    // –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ñ–∞–π–ª–∞ —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤
    let scenarios_path = Path::new("./tests/scenarios").join(scenarios_file);
    if !scenarios_path.exists() {
        return Err(anyhow::anyhow!(
            "Scenarios file not found: {}. Use 'sample' command to generate one.",
            scenarios_path.display()
        ));
    }

    // 1. –°–æ–∑–¥–∞–µ–º –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã —Å–∏—Å—Ç–µ–º—ã
    let mut executor = TestExecutor::with_project_root("../");
    let scenario_manager = ScenarioManager::new("./tests/scenarios");
    let report_generator = TestReportGenerator::new(output_dir);

    // 2. Full readiness check (–≤–∫–ª—é—á–∞–µ—Ç –∫–æ–º–ø–∏–ª—è—Ü–∏—é –∏ health check)
    println!("üîç Performing full system readiness check...");
    if !executor.full_readiness_check().await? {
        return Err(anyhow::anyhow!("‚ùå System readiness check failed"));
    }
    println!("‚úÖ System is ready for testing");

    // 3. –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—Ü–µ–Ω–∞—Ä–∏–∏
    println!("üìã Loading test scenarios...");
    let scenarios = match scenario_type {
        Some(ref test_type) => {
            println!("üéØ Filtering scenarios by type: {}", test_type);
            scenario_manager.load_scenarios_by_type(test_type)?
        }
        None => scenario_manager.load_scenarios_from_file(scenarios_file)?
    };

    if scenarios.is_empty() {
        return Err(anyhow::anyhow!("No scenarios loaded"));
    }

    scenario_manager.validate_scenarios(&scenarios)?;
    println!("‚úÖ Loaded {} valid scenarios", scenarios.len());

    // 4. –í—ã–ø–æ–ª–Ω—è–µ–º —Ç–µ—Å—Ç—ã
    println!("üß™ Executing test scenarios...");
    let test_results = executor.execute_test_suite(scenarios.clone()).await?;
    
    let successful_tests = test_results.iter().filter(|r| r.success).count();
    println!("‚úÖ Test execution completed: {}/{} successful", successful_tests, test_results.len());

    // 5. –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    let evaluation_results = if skip_evaluation {
        println!("‚è≠Ô∏è  Skipping GPT-5 evaluation");
        Vec::new()
    } else {
        println!("ü§ñ Evaluating response quality with GPT-5 nano...");
        match Gpt5Evaluator::from_env_file("./.env") {
            Ok(evaluator) => {
                match evaluator.evaluate_test_batch(&scenarios, &test_results).await {
                    Ok(results) => {
                        println!("‚úÖ Evaluation completed for {} scenarios", results.len());
                        results
                    }
                    Err(e) => {
                        println!("‚ö†Ô∏è  Evaluation failed: {}", e);
                        println!("üîÑ Continuing without evaluation...");
                        Vec::new()
                    }
                }
            }
            Err(e) => {
                println!("‚ö†Ô∏è  Cannot initialize GPT-5 evaluator: {}", e);
                println!("üí° Hint: Make sure OPENAI_API_KEY is set in .env file");
                Vec::new()
            }
        }
    };

    // 6. –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç—á–µ—Ç
    println!("üìä Generating test report...");
    let session_id = format!("MAGRAY_TEST_{}", chrono::Utc::now().format("%Y%m%d_%H%M%S"));
    let report = report_generator.generate_full_report(
        &scenarios,
        &test_results,
        &evaluation_results,
        session_id,
    ).await?;

    // 7. –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç—á–µ—Ç
    let saved_files = report_generator.save_report(&report).await?;

    // 8. –í—ã–≤–æ–¥–∏–º —Å–≤–æ–¥–∫—É
    print_final_summary(&report, &saved_files, verbose);

    Ok(())
}

/// –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç—å —Å–∏—Å—Ç–µ–º—ã
async fn check_system_readiness(output_dir: &str) -> Result<()> {
    println!("üîß System Readiness Check");
    println!("{}", "=".repeat(40));

    let mut all_good = true;

    // –ü—Ä–æ–≤–µ—Ä–∫–∞ MAGRAY CLI
    print!("üîç MAGRAY CLI availability... ");
    let mut executor = TestExecutor::with_project_root("../");
    match executor.full_readiness_check().await {
        Ok(true) => println!("‚úÖ OK"),
        Ok(false) => {
            println!("‚ùå FAILED");
            all_good = false;
        }
        Err(e) => {
            println!("‚ùå ERROR: {}", e);
            all_good = false;
        }
    }

    // –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤
    print!("üìã Test scenarios... ");
    let scenario_manager = ScenarioManager::new("./tests/scenarios");
    match scenario_manager.get_scenarios_stats() {
        Ok(stats) => {
            println!("‚úÖ {} scenarios available", stats.total_count);
            if stats.total_count == 0 {
                println!("‚ö†Ô∏è  No scenarios found - use 'sample' command to generate");
            }
        }
        Err(e) => {
            println!("‚ùå ERROR: {}", e);
            all_good = false;
        }
    }

    // –ü—Ä–æ–≤–µ—Ä–∫–∞ API –∫–ª—é—á–∞
    print!("üîë OpenAI API key... ");
    match Gpt5Evaluator::from_env_file("./.env") {
        Ok(_) => println!("‚úÖ Found"),
        Err(_) => {
            println!("‚ö†Ô∏è  Not found in .env file");
            println!("üí° Evaluation will be skipped without API key");
        }
    }

    // –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –æ—Ç—á–µ—Ç–æ–≤
    print!("üìÇ Reports directory... ");
    match std::fs::create_dir_all(output_dir) {
        Ok(_) => println!("‚úÖ {} ready", output_dir),
        Err(e) => {
            println!("‚ùå ERROR: {}", e);
            all_good = false;
        }
    }

    println!();
    if all_good {
        println!("üéâ System is ready for testing!");
    } else {
        println!("‚ùå System has issues that need to be resolved");
        return Err(anyhow::anyhow!("System readiness check failed"));
    }

    Ok(())
}

/// –í—ã–≤–æ–¥–∏—Ç —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤
async fn list_scenarios(scenarios_file: &str) -> Result<()> {
    println!("üìã Available Test Scenarios");
    println!("{}", "=".repeat(50));

    let scenario_manager = ScenarioManager::new("./tests/scenarios");
    
    // –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
    match scenario_manager.get_scenarios_stats() {
        Ok(stats) => {
            println!("üìä Overview:");
            println!("   ‚Ä¢ Total scenarios: {}", stats.total_count);
            println!("   ‚Ä¢ Estimated time: {} minutes", stats.estimated_time_minutes);
            println!("   ‚Ä¢ Categories: {}", stats.categories.join(", "));
            println!();

            println!("üìà By type:");
            for (test_type, count) in &stats.by_type {
                println!("   ‚Ä¢ {}: {} scenarios", test_type, count);
            }
            println!();
        }
        Err(e) => {
            println!("‚ùå Failed to load scenario stats: {}", e);
        }
    }

    // –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Å—Ü–µ–Ω–∞—Ä–∏–∏ –∏–∑ —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
    match scenario_manager.load_scenarios_from_file(scenarios_file) {
        Ok(scenarios) => {
            println!("üìÑ From {}:", scenarios_file);
            for (i, scenario) in scenarios.iter().enumerate() {
                println!("   {}. {} ({})", 
                       i + 1, 
                       scenario.name, 
                       scenario.expected_type);
                println!("      Input: {}", 
                       if scenario.input.len() > 60 {
                           format!("{}...", &scenario.input[..60])
                       } else {
                           scenario.input.clone()
                       });
                println!("      Timeout: {}s", scenario.timeout_seconds);
                println!();
            }
        }
        Err(e) => {
            println!("‚ùå Failed to load scenarios from {}: {}", scenarios_file, e);
            println!("üí° Use 'sample' command to generate a scenarios file");
        }
    }

    Ok(())
}

/// –ó–∞–ø—É—Å–∫–∞–µ—Ç —Ç–æ–ª—å–∫–æ health check
async fn run_health_check() -> Result<()> {
    println!("üîç MAGRAY CLI Health Check");
    println!("{}", "=".repeat(30));

    let mut executor = TestExecutor::with_project_root("../");
    
    match executor.full_readiness_check().await {
        Ok(true) => {
            println!("‚úÖ MAGRAY CLI is healthy and fully ready");
            println!("üéØ System is ready for comprehensive testing");
        }
        Ok(false) => {
            println!("‚ùå MAGRAY CLI readiness check failed");
            println!("üí° Trying basic health check...");
            
            // Fallback –∫ –±–∞–∑–æ–≤–æ–º—É health check
            match executor.health_check().await {
                Ok(true) => {
                    println!("‚úÖ Basic health check passed");
                    println!("‚ö†Ô∏è  Some features may not be available");
                }
                Ok(false) => {
                    println!("‚ùå Even basic health check failed");
                    return Err(anyhow::anyhow!("Health check failed"));
                }
                Err(e) => {
                    println!("üí• Health check error: {}", e);
                    return Err(e);
                }
            }
        }
        Err(e) => {
            println!("üí• Readiness check error: {}", e);
            return Err(e);
        }
    }

    Ok(())
}

/// –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –ø—Ä–∏–º–µ—Ä —Ñ–∞–π–ª–∞ —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤
async fn generate_sample_scenarios() -> Result<()> {
    println!("üìù Generating sample scenarios file...");
    
    let scenarios_dir = Path::new("./tests/scenarios");
    std::fs::create_dir_all(scenarios_dir)?;
    
    let sample_file = scenarios_dir.join("sample_scenarios.yaml");
    
    if sample_file.exists() {
        println!("‚ö†Ô∏è  File already exists: {}", sample_file.display());
        println!("üí° Use a different name or delete the existing file");
        return Ok(());
    }

    let sample_content = r#"# Sample MAGRAY CLI Test Scenarios
scenarios:
  - id: "quick_test"
    name: "Quick Response Test"
    input: "–ø—Ä–∏–≤–µ—Ç, –∫–∞–∫ –¥–µ–ª–∞?"
    expected_type: "simple_response"
    timeout_seconds: 15
    evaluation_criteria:
      - "responds_appropriately"
      - "shows_politeness"

  - id: "help_test"  
    name: "Help Request Test"
    input: "–ø–æ–º–æ–≥–∏ –º–Ω–µ —Å–æ–∑–¥–∞—Ç—å –ø—Ä–æ—Å—Ç–æ–µ Rust –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ"
    expected_type: "complex_task"
    timeout_seconds: 60
    evaluation_criteria:
      - "provides_clear_instructions"
      - "includes_code_examples"
      - "explains_concepts"

  - id: "error_handling_test"
    name: "Error Handling Test"
    input: "–∞–±—Ä–∞–∫–∞–¥–∞–±—Ä–∞ nonsense 12345"
    expected_type: "error_handling" 
    timeout_seconds: 20
    evaluation_criteria:
      - "handles_gracefully"
      - "provides_helpful_message"

meta:
  version: "1.0"
  description: "Sample scenarios for testing"
  total_scenarios: 3
  estimated_total_time_minutes: 5
  categories: ["basic", "help", "error"]
"#;

    std::fs::write(&sample_file, sample_content)?;
    println!("‚úÖ Sample scenarios created: {}", sample_file.display());
    println!("üöÄ You can now run: cargo run --bin magray_testing -- --scenarios sample_scenarios.yaml");

    Ok(())
}

/// –í—ã–≤–æ–¥–∏—Ç —Ñ–∏–Ω–∞–ª—å–Ω—É—é —Å–≤–æ–¥–∫—É —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
fn print_final_summary(
    report: &reports::test_report_generator::TestSummaryReport,
    saved_files: &[String],
    verbose: bool,
) {
    println!();
    println!("üèÅ TEST SUITE COMPLETED");
    println!("{}", "=".repeat(60));
    
    // –û—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
    println!("üìä EXECUTION RESULTS:");
    println!("   ‚Ä¢ Total Tests: {}", report.execution_summary.total_tests);
    println!("   ‚Ä¢ Success Rate: {:.1}%", report.execution_summary.success_rate);
    println!("   ‚Ä¢ Average Response Time: {:.0}ms", report.execution_summary.average_response_time_ms);
    
    // –ö–∞—á–µ—Å—Ç–≤–æ (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–æ)
    if report.evaluation_summary.total_evaluations > 0 {
        println!("\nüéØ QUALITY EVALUATION:");
        println!("   ‚Ä¢ Overall Score: {:.1}/10", report.evaluation_summary.average_overall_score);
        println!("   ‚Ä¢ Technical Accuracy: {:.1}/10", report.evaluation_summary.average_scores.technical_accuracy);
        println!("   ‚Ä¢ Completeness: {:.1}/10", report.evaluation_summary.average_scores.completeness);
        
        // –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –æ—Ü–µ–Ω–æ–∫
        println!("\nüìà SCORE DISTRIBUTION:");
        println!("   ‚Ä¢ Excellent (9-10): {} scenarios", report.evaluation_summary.score_distribution.excellent);
        println!("   ‚Ä¢ Good (7-8.9): {} scenarios", report.evaluation_summary.score_distribution.good);
        println!("   ‚Ä¢ Satisfactory (5-6.9): {} scenarios", report.evaluation_summary.score_distribution.satisfactory);
        println!("   ‚Ä¢ Poor (1-4.9): {} scenarios", report.evaluation_summary.score_distribution.poor);
    }

    // –ö–ª—é—á–µ–≤—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
    if !report.recommendations.is_empty() {
        println!("\nüí° KEY RECOMMENDATIONS:");
        for (i, rec) in report.recommendations.iter().take(3).enumerate() {
            println!("   {}. {}", i + 1, rec);
        }
        
        if report.recommendations.len() > 3 {
            println!("   ... and {} more in the detailed report", report.recommendations.len() - 3);
        }
    }

    // –°–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
    println!("\nüìÑ REPORTS GENERATED:");
    for file in saved_files {
        let extension = Path::new(file).extension()
            .and_then(|ext| ext.to_str())
            .unwrap_or("unknown");
        
        let icon = match extension {
            "html" => "üåê",
            "json" => "üìã", 
            "md" => "üìù",
            _ => "üìÑ",
        };
        
        println!("   {} {}", icon, file);
    }

    // –î–µ—Ç–∞–ª–∏ –≤ verbose —Ä–µ–∂–∏–º–µ
    if verbose {
        println!("\nüîç DETAILED BREAKDOWN:");
        println!("   ‚Ä¢ Test Duration: {:.1} minutes", report.metadata.test_duration_minutes);
        println!("   ‚Ä¢ MAGRAY Version: {}", report.metadata.magray_version);
        println!("   ‚Ä¢ Report ID: {}", report.metadata.report_id);
        
        if !report.execution_summary.tests_by_type.is_empty() {
            println!("\nüìä TESTS BY TYPE:");
            for (test_type, count) in &report.execution_summary.tests_by_type {
                println!("   ‚Ä¢ {}: {} tests", test_type, count);
            }
        }
    }

    println!("\nüéâ Testing completed successfully!");
    println!("üí° Open the HTML report for detailed analysis");
    println!("{}", "=".repeat(60));
}