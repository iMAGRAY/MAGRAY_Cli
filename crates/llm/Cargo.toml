[package]
name = "llm"
version.workspace = true
edition.workspace = true

[features]
default = ["cpu"]

# Minimal build - mock providers only  
minimal = []

# CPU build - full API provider support
cpu = [
    "anthropic",
    "openai", 
    "groq",
    "azure",
    "local"
]

# GPU build - same as CPU but with potential GPU-aware local models
gpu = ["cpu"]

# Individual LLM providers
anthropic = ["reqwest"]
openai = ["reqwest"] 
groq = ["reqwest"]
azure = ["reqwest"]
local = []

# Tests feature to include extended/slow suites
extended-tests = []

[dependencies]
tokio = { workspace = true }
anyhow = { workspace = true }
serde = { workspace = true }
serde_json = { workspace = true }
reqwest = { workspace = true, optional = true, features = ["stream"] }
tracing = { workspace = true }
dotenv = { workspace = true }
async-trait = "0.1.74"
tokio-stream = "0.1"
futures-util = "0.3"
futures = "0.3"
bytes = "1.0"
rand = "0.8"
uuid = { version = "1.0", features = ["v4", "serde"] }
[dev-dependencies]
mockito = "1.5"
