use anyhow::Result;
use memory::{MemoryService, MemoryConfig, Record, Layer, default_config};
use ai::gpu_detector::GpuDetector;
use std::time::Instant;
use tracing::info;
use uuid::Uuid;
use chrono::Utc;

#[tokio::main]
async fn main() -> Result<()> {
    // –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
    tracing_subscriber::fmt::init();

    info!("üöÄ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ GPU —É—Å–∫–æ—Ä–µ–Ω–∏—è –¥–ª—è —Å–∏—Å—Ç–µ–º—ã –ø–∞–º—è—Ç–∏ MAGRAY CLI");
    
    // 1. –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ GPU
    test_gpu_detection()?;
    
    // 2. –¢–µ—Å—Ç –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ GPU —Å —Å–∏—Å—Ç–µ–º–æ–π –ø–∞–º—è—Ç–∏
    test_memory_gpu_integration().await?;
    
    // 3. –¢–µ—Å—Ç –±–∞—Ç—á–µ–≤–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
    test_batch_processing().await?;
    
    // 4. –¢–µ—Å—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ CPU vs GPU
    test_performance_comparison().await?;
    
    // 5. –¢–µ—Å—Ç –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ —Å GPU —ç–º–±–µ–¥–¥–∏–Ω–≥–∞–º–∏
    test_vector_search().await?;
    
    info!("‚úÖ –í—Å–µ —Ç–µ—Å—Ç—ã –∑–∞–≤–µ—Ä—à–µ–Ω—ã —É—Å–ø–µ—à–Ω–æ!");
    
    Ok(())
}

/// –¢–µ—Å—Ç –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è GPU
fn test_gpu_detection() -> Result<()> {
    info!("\nüìç –¢–µ—Å—Ç 1: –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ GPU");
    
    let detector = GpuDetector::detect();
    
    if detector.available {
        info!("‚úÖ GPU –æ–±–Ω–∞—Ä—É–∂–µ–Ω!");
        info!("  - –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É—Å—Ç—Ä–æ–π—Å—Ç–≤: {}", detector.devices.len());
        info!("  - CUDA –≤–µ—Ä—Å–∏—è: {}", detector.cuda_version);
        info!("  - –î—Ä–∞–π–≤–µ—Ä: {}", detector.driver_version);
        
        for (idx, device) in detector.devices.iter().enumerate() {
            info!("\n  GPU #{}: {}", idx, device.name);
            info!("    - –ü–∞–º—è—Ç—å: {} MB (—Å–≤–æ–±–æ–¥–Ω–æ: {} MB)", 
                device.total_memory_mb, device.free_memory_mb);
            if let Some(temp) = device.temperature_c {
                info!("    - –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞: {}¬∞C", temp);
            }
            if let Some(util) = device.utilization_percent {
                info!("    - –ó–∞–≥—Ä—É–∑–∫–∞: {}%", util);
            }
            info!("    - Compute capability: {}", device.compute_capability);
        }
        
        // –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ GPU –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏
        info!("\n  ‚úÖ GPU –≥–æ—Ç–æ–≤ –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ ONNX Runtime");
    } else {
        info!("‚ùå GPU –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω, –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è CPU");
    }
    
    Ok(())
}

/// –¢–µ—Å—Ç –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ GPU —Å —Å–∏—Å—Ç–µ–º–æ–π –ø–∞–º—è—Ç–∏
async fn test_memory_gpu_integration() -> Result<()> {
    info!("\nüìç –¢–µ—Å—Ç 2: –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è GPU —Å —Å–∏—Å—Ç–µ–º–æ–π –ø–∞–º—è—Ç–∏");
    
    // –°–æ–∑–¥–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é —Å GPU
    let mut config = default_config().unwrap();
    config.ai_config.embedding.use_gpu = true;
    
    // –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–µ—Ä–≤–∏—Å
    let service = MemoryService::new(config).await?;
    
    // –¢–µ—Å—Ç–∏—Ä—É–µ–º –æ–¥–∏–Ω–æ—á–Ω—É—é –≤—Å—Ç–∞–≤–∫—É
    let record = Record {
        id: Uuid::new_v4(),
        text: "Testing GPU-accelerated embeddings in memory system".to_string(),
        embedding: vec![],
        layer: Layer::Interact,
        kind: "test".to_string(),
        tags: vec!["gpu".to_string()],
        project: "gpu_test".to_string(),
        session: Uuid::new_v4().to_string(),
        score: 0.5,
        access_count: 1,
        ts: Utc::now(),
        last_access: Utc::now(),
    };
    
    let start = Instant::now();
    service.insert(record).await?;
    info!("  –û–¥–∏–Ω–æ—á–Ω–∞—è –≤—Å—Ç–∞–≤–∫–∞ —Å GPU: {:?}", start.elapsed());
    
    // –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∫—ç—à–∞
    let (hits, misses, size) = service.cache_stats();
    info!("  Cache stats - Hits: {}, Misses: {}, Size: {} bytes", hits, misses, size);
    
    Ok(())
}

/// –¢–µ—Å—Ç –±–∞—Ç—á–µ–≤–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
async fn test_batch_processing() -> Result<()> {
    info!("\nüìç –¢–µ—Å—Ç 3: –ë–∞—Ç—á–µ–≤–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤");
    
    let mut config = default_config().unwrap();
    config.ai_config.embedding.use_gpu = true;
    let service = MemoryService::new(config).await?;
    
    let batch_sizes = vec![10, 50, 100, 200];
    
    for size in batch_sizes {
        let records: Vec<Record> = (0..size)
            .map(|i| Record {
                id: Uuid::new_v4(),
                text: format!("Batch test record #{}: Testing GPU batch processing with meaningful text content for better embeddings", i),
                embedding: vec![],
                layer: Layer::Interact,
                kind: "batch_test".to_string(),
                tags: vec!["batch".to_string(), "gpu".to_string()],
                project: "gpu_test".to_string(),
                session: Uuid::new_v4().to_string(),
                score: 0.5,
                access_count: 1,
                ts: Utc::now(),
                last_access: Utc::now(),
            })
            .collect();
        
        let start = Instant::now();
        service.insert_batch(records).await?;
        let elapsed = start.elapsed();
        
        info!("  Batch size {}: {:.2}ms ({:.1} records/sec)", 
            size, 
            elapsed.as_millis(),
            size as f64 / elapsed.as_secs_f64()
        );
    }
    
    Ok(())
}

/// –¢–µ—Å—Ç —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏  
async fn test_performance_comparison() -> Result<()> {
    info!("\nüìç –¢–µ—Å—Ç 4: –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ CPU vs GPU");
    
    let test_data: Vec<String> = (0..100)
        .map(|i| format!("Test text #{}: This is a meaningful sentence for testing embedding performance with both CPU and GPU implementations", i))
        .collect();
    
    // CPU –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
    let mut cpu_config = MemoryConfig::default();
    cpu_config.ai_config.embedding.use_gpu = false;
    cpu_config.db_path = cpu_config.db_path.parent().unwrap().join("cpu_test_db");
    cpu_config.cache_path = cpu_config.cache_path.parent().unwrap().join("cpu_test_cache");
    
    // GPU –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
    let mut gpu_config = MemoryConfig::default();
    gpu_config.ai_config.embedding.use_gpu = true;
    gpu_config.db_path = gpu_config.db_path.parent().unwrap().join("gpu_test_db");
    gpu_config.cache_path = gpu_config.cache_path.parent().unwrap().join("gpu_test_cache");
    
    // –¢–µ—Å—Ç CPU
    info!("\nüíª –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ CPU:");
    let cpu_service = MemoryService::new(cpu_config).await?;
    
    let cpu_records: Vec<Record> = test_data.iter()
        .map(|text| Record {
            id: Uuid::new_v4(),
            text: text.clone(),
            embedding: vec![],
            layer: Layer::Interact,
            kind: "perf_test".to_string(),
            tags: vec!["cpu".to_string()],
            project: "perf_test".to_string(),
            session: Uuid::new_v4().to_string(),
            score: 0.5,
            access_count: 1,
            ts: Utc::now(),
            last_access: Utc::now(),
        })
        .collect();
    
    let start = Instant::now();
    cpu_service.insert_batch(cpu_records).await?;
    let cpu_time = start.elapsed();
    info!("  CPU –≤—Ä–µ–º—è: {:?} ({:.1} texts/sec)", cpu_time, test_data.len() as f64 / cpu_time.as_secs_f64());
    
    // –¢–µ—Å—Ç GPU
    info!("\nüéÆ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ GPU:");
    let gpu_service = MemoryService::new(gpu_config).await?;
    
    let gpu_records: Vec<Record> = test_data.iter()
        .map(|text| Record {
            id: Uuid::new_v4(),
            text: text.clone(),
            embedding: vec![],
            layer: Layer::Interact,
            kind: "perf_test".to_string(),
            tags: vec!["gpu".to_string()],
            project: "perf_test".to_string(),
            session: Uuid::new_v4().to_string(),
            score: 0.5,
            access_count: 1,
            ts: Utc::now(),
            last_access: Utc::now(),
        })
        .collect();
    
    let start = Instant::now();
    gpu_service.insert_batch(gpu_records).await?;
    let gpu_time = start.elapsed();
    info!("  GPU –≤—Ä–µ–º—è: {:?} ({:.1} texts/sec)", gpu_time, test_data.len() as f64 / gpu_time.as_secs_f64());
    
    // –°—Ä–∞–≤–Ω–µ–Ω–∏–µ
    if gpu_time < cpu_time {
        let speedup = cpu_time.as_secs_f64() / gpu_time.as_secs_f64();
        info!("\nüìä GPU —É—Å–∫–æ—Ä–µ–Ω–∏–µ: {:.2}x –±—ã—Å—Ç—Ä–µ–µ", speedup);
    } else {
        info!("\nüìä CPU –æ–∫–∞–∑–∞–ª—Å—è –±—ã—Å—Ç—Ä–µ–µ (–≤–æ–∑–º–æ–∂–Ω–æ, GPU –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω)");
    }
    
    Ok(())
}

/// –¢–µ—Å—Ç –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ —Å GPU —ç–º–±–µ–¥–¥–∏–Ω–≥–∞–º–∏
async fn test_vector_search() -> Result<()> {
    info!("\nüìç –¢–µ—Å—Ç 5: –í–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫ —Å GPU —ç–º–±–µ–¥–¥–∏–Ω–≥–∞–º–∏");
    
    let mut config = default_config().unwrap();
    config.ai_config.embedding.use_gpu = true;
    let service = MemoryService::new(config).await?;
    
    // –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã
    let documents = vec![
        "GPU acceleration enables faster machine learning model training",
        "CUDA cores are specialized processors designed for parallel computing",
        "TensorRT optimizes neural network inference on NVIDIA GPUs",
        "Vector databases use embeddings for semantic search capabilities",
        "HNSW algorithm provides efficient approximate nearest neighbor search",
        "Memory caching reduces latency in embedding generation pipelines",
        "Rust provides memory safety without garbage collection overhead",
        "The quick brown fox jumps over the lazy dog",
    ];
    
    info!("  –î–æ–±–∞–≤–ª–µ–Ω–∏–µ {} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤...", documents.len());
    let records: Vec<Record> = documents.iter()
        .map(|text| Record {
            id: Uuid::new_v4(),
            text: text.to_string(),
            embedding: vec![],
            layer: Layer::Insights,
            kind: "document".to_string(),
            tags: vec!["search_test".to_string()],
            project: "gpu_search".to_string(),
            session: Uuid::new_v4().to_string(),
            score: 0.5,
            access_count: 1,
            ts: Utc::now(),
            last_access: Utc::now(),
        })
        .collect();
    
    service.insert_batch(records).await?;
    
    // –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–æ–∏—Å–∫
    let queries = vec![
        "GPU parallel computing",
        "vector search algorithm",
        "memory safety Rust",
    ];
    
    for query in queries {
        info!("\n  –ü–æ–∏—Å–∫: '{}'", query);
        let start = Instant::now();
        
        let results = service.search(query)
            .with_layer(Layer::Insights)
            .top_k(3)
            .execute()
            .await?;
        
        let search_time = start.elapsed();
        info!("    –í—Ä–µ–º—è –ø–æ–∏—Å–∫–∞: {:?}", search_time);
        
        for (i, result) in results.iter().enumerate() {
            info!("    {}. Score: {:.3} - {}", 
                i + 1, 
                result.score,
                &result.text[..result.text.len().min(60)]
            );
        }
    }
    
    // –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    info!("\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–∏—Å—Ç–µ–º—ã:");
    let (hits, misses, size) = service.cache_stats();
    info!("  Cache - Hits: {}, Misses: {}, Size: {} KB", hits, misses, size / 1024);
    info!("  Cache hit rate: {:.1}%", service.cache_hit_rate() * 100.0);
    
    let health = service.get_system_health();
    info!("  System health: {:?}", health);
    
    Ok(())
}

#[cfg(test)]
mod tests {
    use super::*;
    use tempfile::TempDir;
    
    #[tokio::test]
    async fn test_memory_gpu_basic() {
        let temp_dir = TempDir::new().unwrap();
        let mut config = default_config().unwrap();
        config.db_path = temp_dir.path().join("test_db");
        config.cache_path = temp_dir.path().join("test_cache");
        
        // –î–æ–ª–∂–µ–Ω —Å–æ–∑–¥–∞—Ç—å—Å—è —Å CPU fallback –µ—Å–ª–∏ –Ω–µ—Ç GPU
        let service = MemoryService::new(config).await.unwrap();
        
        // –ë–∞–∑–æ–≤—ã–π —Ç–µ—Å—Ç –≤—Å—Ç–∞–≤–∫–∏
        let record = Record {
            id: Uuid::new_v4(),
            text: "Test".to_string(),
            embedding: vec![],
            layer: Layer::Interact,
            kind: "test".to_string(),
            tags: vec![],
            project: "test".to_string(),
            session: Uuid::new_v4().to_string(),
            score: 0.5,
            access_count: 1,
            ts: Utc::now(),
            last_access: Utc::now(),
        };
        
        assert!(service.insert(record).await.is_ok());
    }
}