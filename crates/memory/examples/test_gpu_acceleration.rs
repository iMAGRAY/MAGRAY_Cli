use ai::{
    EmbeddingConfig, 
    GpuConfig,
    auto_device_selector::{AutoDeviceSelector, SmartEmbeddingFactory},
    gpu_detector::GpuDetector,
    gpu_memory_pool::GPU_MEMORY_POOL,
    embeddings_optimized_v2::OptimizedEmbeddingServiceV2,
};
use std::time::Instant;
use tracing::{info, error, warn};
use tracing_subscriber::{layer::SubscriberExt, util::SubscriberInitExt, EnvFilter};
use anyhow::Result;

#[tokio::main]
async fn main() -> Result<()> {
    // –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
    tracing_subscriber::registry()
        .with(EnvFilter::from_default_env().add_directive("info".parse().unwrap()))
        .with(tracing_subscriber::fmt::layer())
        .init();

    info!("üöÄ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ GPU —É—Å–∫–æ—Ä–µ–Ω–∏—è –¥–ª—è MAGRAY CLI");
    
    // 1. –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ GPU
    test_gpu_detection()?;
    
    // 2. –¢–µ—Å—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –≤—ã–±–æ—Ä–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞
    test_auto_device_selection().await?;
    
    // 3. –¢–µ—Å—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ CPU vs GPU
    test_performance_comparison().await?;
    
    // 4. –¢–µ—Å—Ç memory pooling
    test_memory_pooling()?;
    
    // 5. –¢–µ—Å—Ç –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–π –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
    test_dynamic_optimization().await?;
    
    info!("‚úÖ –í—Å–µ —Ç–µ—Å—Ç—ã –∑–∞–≤–µ—Ä—à–µ–Ω—ã —É—Å–ø–µ—à–Ω–æ!");
    
    Ok(())
}

/// –¢–µ—Å—Ç –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è GPU
fn test_gpu_detection() -> Result<()> {
    info!("\nüìç –¢–µ—Å—Ç 1: –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ GPU");
    
    let detector = GpuDetector::detect();
    
    if detector.available {
        info!("‚úÖ GPU –æ–±–Ω–∞—Ä—É–∂–µ–Ω!");
        info!("  - –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É—Å—Ç—Ä–æ–π—Å—Ç–≤: {}", detector.devices.len());
        info!("  - CUDA –≤–µ—Ä—Å–∏—è: {}", detector.cuda_version);
        info!("  - –î—Ä–∞–π–≤–µ—Ä: {}", detector.driver_version);
        
        for (idx, device) in detector.devices.iter().enumerate() {
            info!("\n  GPU #{}: {}", idx, device.name);
            info!("    - –ü–∞–º—è—Ç—å: {} MB (—Å–≤–æ–±–æ–¥–Ω–æ: {} MB)", 
                device.total_memory_mb, device.free_memory_mb);
            info!("    - –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞: {}¬∞C", device.temperature);
            info!("    - –ó–∞–≥—Ä—É–∑–∫–∞: {}%", device.utilization);
            info!("    - Compute capability: {}.{}", 
                device.compute_capability_major, device.compute_capability_minor);
        }
        
        // –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
        let optimal = detector.get_optimal_params(500); // 500MB –º–æ–¥–µ–ª—å
        info!("\n  –û–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –º–æ–¥–µ–ª–∏ 500MB:");
        info!("    - Batch size: {}", optimal.batch_size);
        info!("    - Max sequence: {}", optimal.max_sequence_length);
        info!("    - FP16: {}", optimal.use_fp16);
        info!("    - GPU: {}", optimal.gpu_device_id);
    } else {
        info!("‚ùå GPU –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω, –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è CPU");
    }
    
    Ok(())
}

/// –¢–µ—Å—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –≤—ã–±–æ—Ä–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞
async fn test_auto_device_selection() -> Result<()> {
    info!("\nüìç –¢–µ—Å—Ç 2: –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –≤—ã–±–æ—Ä CPU/GPU");
    
    let mut selector = AutoDeviceSelector::new();
    let config = EmbeddingConfig {
        model_name: "bge-m3".to_string(),
        use_gpu: false, // –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—Å—è
        batch_size: 32,
        ..Default::default()
    };
    
    let decision = selector.select_device(&config).await?;
    
    info!("üìä –†–µ–∑—É–ª—å—Ç–∞—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –≤—ã–±–æ—Ä–∞:");
    info!("  - –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {}", if decision.use_gpu { "GPU" } else { "CPU" });
    info!("  - –ü—Ä–∏—á–∏–Ω–∞: {}", decision.reason);
    info!("  - CPU score: {:.2} items/sec", decision.cpu_score);
    if let Some(gpu_score) = decision.gpu_score {
        info!("  - GPU score: {:.2} items/sec", gpu_score);
        info!("  - –£—Å–∫–æ—Ä–µ–Ω–∏–µ: {:.1}x", gpu_score / decision.cpu_score);
    }
    info!("  - –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–π batch size: {}", decision.recommended_batch_size);
    
    Ok(())
}

/// –¢–µ—Å—Ç —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
async fn test_performance_comparison() -> Result<()> {
    info!("\nüìç –¢–µ—Å—Ç 3: –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ CPU vs GPU");
    
    let test_sizes = vec![10, 50, 100, 500];
    let test_texts: Vec<String> = (0..500)
        .map(|i| format!("This is a test sentence number {} for benchmarking the embedding performance of our optimized service.", i))
        .collect();
    
    // –¢–µ—Å—Ç CPU
    info!("\nüíª –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ CPU:");
    
    let cpu_config = EmbeddingConfig {
        model_name: "bge-m3".to_string(),
        use_gpu: false,
        batch_size: 32,
        ..Default::default()
    };
    
    if let Ok(cpu_service) = OptimizedEmbeddingServiceV2::new(cpu_config) {
        for &size in &test_sizes {
            let batch = test_texts.iter().take(size).cloned().collect();
            let start = Instant::now();
            
            match cpu_service.embed_batch(batch).await {
                Ok(embeddings) => {
                    let elapsed = start.elapsed();
                    info!("  {} —Ç–µ–∫—Å—Ç–æ–≤: {:.2}ms ({:.1} texts/sec)", 
                        size, 
                        elapsed.as_millis(),
                        size as f64 / elapsed.as_secs_f64()
                    );
                }
                Err(e) => {
                    error!("  –û—à–∏–±–∫–∞ –¥–ª—è {} —Ç–µ–∫—Å—Ç–æ–≤: {}", size, e);
                }
            }
        }
        
        // –í—ã–≤–æ–¥–∏–º –º–µ—Ç—Ä–∏–∫–∏
        cpu_service.print_metrics();
    }
    
    // –¢–µ—Å—Ç GPU (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω)
    #[cfg(feature = "gpu")]
    {
        let detector = GpuDetector::detect();
        if detector.available {
            info!("\nüéÆ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ GPU:");
            
            let gpu_config = EmbeddingConfig {
                model_name: "bge-m3".to_string(),
                use_gpu: true,
                gpu_config: Some(GpuConfig::auto_optimized()),
                batch_size: 128,
                ..Default::default()
            };
            
            match OptimizedEmbeddingServiceV2::new(gpu_config) {
                Ok(gpu_service) => {
                    for &size in &test_sizes {
                        let batch = test_texts.iter().take(size).cloned().collect();
                        let start = Instant::now();
                        
                        match gpu_service.embed_batch(batch).await {
                            Ok(embeddings) => {
                                let elapsed = start.elapsed();
                                info!("  {} —Ç–µ–∫—Å—Ç–æ–≤: {:.2}ms ({:.1} texts/sec)", 
                                    size, 
                                    elapsed.as_millis(),
                                    size as f64 / elapsed.as_secs_f64()
                                );
                            }
                            Err(e) => {
                                error!("  –û—à–∏–±–∫–∞ –¥–ª—è {} —Ç–µ–∫—Å—Ç–æ–≤: {}", size, e);
                            }
                        }
                    }
                    
                    // –í—ã–≤–æ–¥–∏–º –º–µ—Ç—Ä–∏–∫–∏
                    gpu_service.print_metrics();
                }
                Err(e) => {
                    error!("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å GPU —Å–µ—Ä–≤–∏—Å: {}", e);
                }
            }
        }
    }
    
    Ok(())
}

/// –¢–µ—Å—Ç memory pooling
fn test_memory_pooling() -> Result<()> {
    info!("\nüìç –¢–µ—Å—Ç 4: GPU Memory Pooling");
    
    // –¢–µ—Å—Ç–∏—Ä—É–µ–º –≤—ã–¥–µ–ª–µ–Ω–∏–µ –∏ –æ—Å–≤–æ–±–æ–∂–¥–µ–Ω–∏–µ –ø–∞–º—è—Ç–∏
    let sizes = vec![1024, 4096, 1024*1024, 4*1024*1024];
    
    for size in sizes {
        let buffer = GPU_MEMORY_POOL.acquire_buffer(size)?;
        info!("  –í—ã–¥–µ–ª–µ–Ω –±—É—Ñ–µ—Ä: {} KB", buffer.capacity() / 1024);
        GPU_MEMORY_POOL.release_buffer(buffer);
    }
    
    // –¢–µ—Å—Ç–∏—Ä—É–µ–º with_buffer
    let result = GPU_MEMORY_POOL.with_buffer(1024*1024, |buffer| {
        buffer.extend_from_slice(&vec![42u8; 1000]);
        Ok(buffer.len())
    })?;
    info!("  –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Å –≤—Ä–µ–º–µ–Ω–Ω—ã–º –±—É—Ñ–µ—Ä–æ–º: {} –±–∞–π—Ç", result);
    
    // –í—ã–≤–æ–¥–∏–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
    GPU_MEMORY_POOL.print_stats();
    
    Ok(())
}

/// –¢–µ—Å—Ç –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–π –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
async fn test_dynamic_optimization() -> Result<()> {
    info!("\nüìç –¢–µ—Å—Ç 5: –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è");
    
    // –ò—Å–ø–æ–ª—å–∑—É–µ–º SmartEmbeddingFactory
    let base_config = EmbeddingConfig {
        model_name: "bge-m3".to_string(),
        ..Default::default()
    };
    
    match SmartEmbeddingFactory::create_optimized(base_config).await {
        Ok((service, decision)) => {
            info!("‚úÖ –°–æ–∑–¥–∞–Ω –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–µ—Ä–≤–∏—Å:");
            info!("  - –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {}", if decision.use_gpu { "GPU" } else { "CPU" });
            info!("  - Batch size: {}", decision.recommended_batch_size);
            
            // –¢–µ—Å—Ç–∏—Ä—É–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ –∑–∞–ø—Ä–æ—Å–æ–≤
            let test_batches = vec![
                vec!["Short text".to_string()],
                vec!["Medium length text that contains more words".to_string(); 10],
                vec!["This is a longer text that simulates real world usage with multiple sentences and various complexity levels.".to_string(); 50],
            ];
            
            for (idx, batch) in test_batches.into_iter().enumerate() {
                let size = batch.len();
                let start = Instant::now();
                
                match service.embed_batch(batch).await {
                    Ok(embeddings) => {
                        let elapsed = start.elapsed();
                        info!("  Batch {}: {} —Ç–µ–∫—Å—Ç–æ–≤ –∑–∞ {:.2}ms", idx + 1, size, elapsed.as_millis());
                    }
                    Err(e) => {
                        error!("  –û—à–∏–±–∫–∞ –≤ batch {}: {}", idx + 1, e);
                    }
                }
            }
        }
        Err(e) => {
            error!("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–µ—Ä–≤–∏—Å: {}", e);
        }
    }
    
    Ok(())
}

#[cfg(test)]
mod tests {
    use super::*;
    
    #[tokio::test]
    async fn test_gpu_system() {
        // –ü—Ä–æ—Å—Ç–æ –ø—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –æ—Å–Ω–æ–≤–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –∫–æ–º–ø–∏–ª–∏—Ä—É—é—Ç—Å—è
        let detector = GpuDetector::detect();
        assert!(detector.cuda_version.is_empty() || !detector.cuda_version.is_empty());
        
        let selector = AutoDeviceSelector::new();
        assert!(true); // –ü—Ä–æ—Å—Ç–æ –ø—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è
    }
}