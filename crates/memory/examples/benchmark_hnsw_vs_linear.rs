use anyhow::Result;
use memory::{VectorIndexHnswRs, HnswRsConfig};
use std::time::Instant;

/// Benchmark —Å—Ä–∞–≤–Ω–µ–Ω–∏—è HNSW vs Linear search –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
#[tokio::main]
async fn main() -> Result<()> {
    println!("üèÅ –ë–µ–Ω—á–º–∞—Ä–∫: HNSW vs Linear Search Performance");
    println!("================================================\n");

    // Test configurations
    let dataset_sizes = vec![100, 500, 1000, 2000, 5000];
    let query_count = 100;
    let k = 10;
    let dimension = 1024;

    for dataset_size in dataset_sizes {
        println!("üìä –¢–µ—Å—Ç —Å {} –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏:", dataset_size);
        
        // Generate test data
        let mut vectors = Vec::new();
        for i in 0..dataset_size {
            let mut vector = vec![0.0f32; dimension];
            for j in 0..dimension {
                vector[j] = (i as f32 + j as f32 * 0.001 + rand::random::<f32>() * 0.1) / 100.0;
            }
            vectors.push((format!("doc_{}", i), vector));
        }

        // Generate query vectors
        let mut queries = Vec::new();
        for i in 0..query_count {
            let mut query = vec![0.0f32; dimension];
            for j in 0..dimension {
                query[j] = (i as f32 + j as f32 * 0.001 + rand::random::<f32>() * 0.05) / 100.0;
            }
            queries.push(query);
        }

        // Test HNSW
        println!("  üöÄ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ HNSW...");
        let hnsw_config = HnswRsConfig {
            dimension,
            max_connections: 24,
            ef_construction: 400,
            ef_search: 100,
            max_elements: dataset_size * 2,
            max_layers: 16,
            use_parallel: true,
        };
        
        let hnsw_index = VectorIndexHnswRs::new(hnsw_config)?;
        
        // Build HNSW index
        let build_start = Instant::now();
        hnsw_index.add_batch(vectors.clone())?;
        let hnsw_build_time = build_start.elapsed();
        
        // Search with HNSW
        let search_start = Instant::now();
        let mut hnsw_total_results = 0;
        for query in &queries {
            let results = hnsw_index.search(query, k)?;
            hnsw_total_results += results.len();
        }
        let hnsw_search_time = search_start.elapsed();
        let hnsw_avg_search = hnsw_search_time.as_micros() as f64 / query_count as f64;

        // Test Linear Search (simplified simulation)
        println!("  üìè –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ Linear Search...");
        let linear_start = Instant::now();
        let mut linear_total_results = 0;
        
        for query in &queries {
            // Simulate linear search - calculate distances to all vectors
            let mut scored_results = Vec::new();
            for (id, vector) in &vectors {
                let distance = cosine_distance(query, vector);
                scored_results.push((id.clone(), distance));
            }
            
            // Sort by distance and take top k
            scored_results.sort_by(|a, b| a.1.partial_cmp(&b.1).unwrap());
            linear_total_results += scored_results.into_iter().take(k).count();
        }
        let linear_search_time = linear_start.elapsed();
        let linear_avg_search = linear_search_time.as_micros() as f64 / query_count as f64;

        // Results
        println!("  ‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã:");
        println!("     HNSW Build Time: {:?}", hnsw_build_time);
        println!("     HNSW Search Time: {:?} ({:.1} Œºs/query)", hnsw_search_time, hnsw_avg_search);
        println!("     Linear Search Time: {:?} ({:.1} Œºs/query)", linear_search_time, linear_avg_search);
        
        let speedup = linear_avg_search / hnsw_avg_search;
        println!("     üöÄ HNSW Speedup: {:.1}x faster", speedup);
        
        let hnsw_recall = hnsw_total_results as f64 / (query_count * k) as f64;
        let linear_recall = linear_total_results as f64 / (query_count * k) as f64;
        println!("     üéØ HNSW Recall: {:.1}%", hnsw_recall * 100.0);
        println!("     üéØ Linear Recall: {:.1}%", linear_recall * 100.0);
        
        // Performance analysis
        if speedup > 10.0 {
            println!("     üéâ –ü–†–ï–í–û–°–•–û–î–ù–û: HNSW –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –æ—Ç–ª–∏—á–Ω–æ–µ —É—Å–∫–æ—Ä–µ–Ω–∏–µ!");
        } else if speedup > 3.0 {
            println!("     ‚úÖ –•–û–†–û–®–û: HNSW —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–µ–Ω –¥–ª—è —ç—Ç–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö");
        } else {
            println!("     ‚ö†Ô∏è  –î–ª—è –º–∞–ª—ã—Ö –¥–∞—Ç–∞—Å–µ—Ç–æ–≤ HNSW –º–æ–∂–µ—Ç –Ω–µ –¥–∞–≤–∞—Ç—å –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞");
        }
        
        println!();
    }

    println!("üéØ –ó–ê–ö–õ–Æ–ß–ï–ù–ò–ï:");
    println!("  - HNSW —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–µ–Ω –¥–ª—è –±–æ–ª—å—à–∏—Ö –¥–∞—Ç–∞—Å–µ—Ç–æ–≤ (>1000 –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤)");
    println!("  - Linear search –º–æ–∂–µ—Ç –±—ã—Ç—å –±—ã—Å—Ç—Ä–µ–µ –¥–ª—è –º–∞–ª—ã—Ö –¥–∞—Ç–∞—Å–µ—Ç–æ–≤ (<100 –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤)");
    println!("  - HNSW –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç —Å—É–±–ª–∏–Ω–µ–π–Ω–æ–µ –≤—Ä–µ–º—è –ø–æ–∏—Å–∫–∞ O(log n)");
    println!("  - Linear search –∏–º–µ–µ—Ç –ª–∏–Ω–µ–π–Ω–æ–µ –≤—Ä–µ–º—è O(n)");

    Ok(())
}

fn cosine_distance(a: &[f32], b: &[f32]) -> f32 {
    if a.len() != b.len() {
        return f32::INFINITY;
    }
    
    let dot_product: f32 = a.iter().zip(b.iter()).map(|(x, y)| x * y).sum();
    let norm_a: f32 = a.iter().map(|x| x * x).sum::<f32>().sqrt();
    let norm_b: f32 = b.iter().map(|x| x * x).sum::<f32>().sqrt();
    
    if norm_a == 0.0 || norm_b == 0.0 {
        return f32::INFINITY;
    }
    
    // Return distance (1 - cosine_similarity)
    1.0 - (dot_product / (norm_a * norm_b))
}