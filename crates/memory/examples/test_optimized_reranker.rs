use anyhow::Result;
use ai::{OptimizedMxbaiRerankerService, RerankBatch};
use std::path::PathBuf;
use std::time::Instant;

fn main() -> Result<()> {
    println!("=== OPTIMIZED MXBAI RERANKER SERVICE TEST ===\n");
    
    // Setup logging
    tracing_subscriber::fmt::init();
    
    println!("üöÄ Testing OPTIMIZED MXBai reranker with batch processing + memory pooling");
    
    let model_path = PathBuf::from("crates/memory/Qwen3-Reranker-0.6B-ONNX/model.onnx");
    
    println!("\n1. Creating optimized reranker service...");
    let service = match OptimizedMxbaiRerankerService::new(model_path, 512, 16) {
        Ok(service) => {
            println!("‚úÖ Optimized reranker service created successfully!");
            service
        },
        Err(e) => {
            println!("‚ùå Failed to create optimized reranker service: {}", e);
            println!("   This is expected if the MXBai model is not available");
            return Ok(());
        }
    };
    
    // Show service stats
    let stats = service.get_stats();
    println!("üìä Service Statistics:");
    println!("   Model: {}", stats.model_name);
    println!("   Max sequence length: {}", stats.max_seq_length);
    println!("   Batch size: {}", stats.batch_size);
    println!("   Optimization: {}", stats.optimization_level);
    
    // Show initial memory pool stats
    let pool_stats = service.get_pool_stats();
    println!("üß† Memory Pool Statistics (initial):");
    println!("   Total gets: {}", pool_stats.total_gets);
    println!("   Total returns: {}", pool_stats.total_returns);
    println!("   Cache hits: {}", pool_stats.cache_hits);
    println!("   Hit rate: {:.1}%", pool_stats.hit_rate * 100.0);
    
    // Test query and documents
    let query = "machine learning algorithms for natural language processing";
    let documents = vec![
        "Deep learning neural networks are powerful machine learning models used in NLP tasks".to_string(),
        "Traditional rule-based systems for parsing and grammar analysis in computational linguistics".to_string(),
        "Transformer architectures like BERT and GPT have revolutionized natural language processing".to_string(),
        "Support vector machines and logistic regression for text classification and sentiment analysis".to_string(),
        "Reinforcement learning approaches for dialogue systems and conversational AI agents".to_string(),
        "Unsupervised learning methods for topic modeling and document clustering in text mining".to_string(),
        "Computer vision techniques for image recognition and object detection using convolutional networks".to_string(),
        "Time series analysis and forecasting models for financial data and stock market prediction".to_string(),
        "Graph neural networks for social network analysis and knowledge graph reasoning".to_string(),
        "Ensemble methods like random forests and gradient boosting for structured data prediction".to_string(),
        "Recurrent neural networks and LSTM models for sequence modeling and language generation".to_string(),
        "Feature engineering and dimensionality reduction techniques for high-dimensional data analysis".to_string(),
    ];
    
    println!("\n2. Testing optimized batch reranking...");
    println!("   Query: '{}'", query);
    println!("   Documents: {} items", documents.len());
    
    // Create batch for reranking
    let batch = RerankBatch {
        query: query.to_string(),
        documents,
        top_k: Some(5), // Return top 5 most relevant documents
    };
    
    // Test optimized batch reranking
    let batch_start = Instant::now();
    let batch_result = service.rerank_batch(&batch)?;
    let batch_total_time = batch_start.elapsed().as_millis();
    
    println!("‚úÖ Optimized batch reranking completed:");
    println!("   Total time: {}ms", batch_total_time);
    println!("   Throughput: {:.1} docs/sec", batch_result.throughput_docs_per_sec);
    println!("   Results returned: {}", batch_result.results.len());
    
    // Show reranking results
    println!("\n3. Reranking results (top 5):");
    for (rank, result) in batch_result.results.iter().enumerate() {
        println!("   {}. Score: {:.4} | Doc: '{}'", 
                 rank + 1, result.score, 
                 if result.document.len() > 80 { 
                     format!("{}...", &result.document[..77])
                 } else { 
                     result.document.clone() 
                 });
    }
    
    // Test different batch sizes for performance comparison
    println!("\n4. Performance comparison with different batch sizes...");
    
    let test_docs = batch.documents[..8].to_vec(); // Use first 8 documents
    
    // Test batch processing vs individual processing
    let individual_start = Instant::now();
    let individual_results = service.rerank(query, &test_docs, Some(3))?;
    let individual_time = individual_start.elapsed().as_millis();
    
    let batch_test = RerankBatch {
        query: query.to_string(),
        documents: test_docs.clone(),
        top_k: Some(3),
    };
    
    let optimized_start = Instant::now();
    let optimized_results = service.rerank_batch(&batch_test)?;
    let optimized_time = optimized_start.elapsed().as_millis();
    
    println!("   Individual processing: {}ms", individual_time);
    println!("   Batch processing: {}ms", optimized_time);
    
    if optimized_time > 0 {
        let speedup = individual_time as f64 / optimized_time as f64;
        println!("   Speedup: {:.1}x faster", speedup);
    }
    
    // Verify results consistency
    println!("\n5. Verifying result consistency...");
    let mut scores_match = true;
    let tolerance = 0.01; // Allow small floating point differences
    
    for i in 0..individual_results.len().min(optimized_results.results.len()) {
        let score_diff = (individual_results[i].score - optimized_results.results[i].score).abs();
        if score_diff > tolerance {
            scores_match = false;
            println!("   ‚ö†Ô∏è Score mismatch at position {}: {} vs {}", 
                     i, individual_results[i].score, optimized_results.results[i].score);
        }
    }
    
    if scores_match {
        println!("   ‚úÖ All scores match between individual and batch processing");
    }
    
    // Show final memory pool stats
    let final_pool_stats = service.get_pool_stats();
    println!("\nüß† Memory Pool Statistics (final):");
    println!("   Total gets: {}", final_pool_stats.total_gets);
    println!("   Total returns: {}", final_pool_stats.total_returns);
    println!("   Cache hits: {}", final_pool_stats.cache_hits);
    println!("   Hit rate: {:.1}%", final_pool_stats.hit_rate * 100.0);
    println!("   Memory reuse efficiency: {:.1}%", 
             if final_pool_stats.total_gets > 0 { 
                 final_pool_stats.cache_hits as f64 / final_pool_stats.total_gets as f64 * 100.0 
             } else { 0.0 });
    
    // Performance summary
    println!("\nüèÜ OPTIMIZED RERANKER PERFORMANCE RESULTS:");
    println!("- Service creation: ‚úÖ");
    println!("- Batch processing optimization: ‚úÖ");
    println!("- Memory pooling optimization: ‚úÖ ({:.1}% reuse)", final_pool_stats.hit_rate * 100.0);
    println!("- Batch reranking throughput: {:.1} docs/sec", batch_result.throughput_docs_per_sec);
    println!("- Memory efficiency: ‚úÖ (pooled buffers)");
    println!("- Result consistency: {}", if scores_match { "‚úÖ" } else { "‚ö†Ô∏è" });
    
    // Calculate performance improvement estimate  
    let old_estimated_time = batch.documents.len() as u128 * 20; // Estimated 20ms per doc for old method
    let improvement = old_estimated_time as f64 / batch_total_time as f64;
    
    println!("\nüìà PERFORMANCE IMPROVEMENT:");
    println!("- Estimated old method: {}ms ({:.1} docs/sec)", old_estimated_time, 1000.0 / 20.0);
    println!("- Optimized batch method: {}ms ({:.1} docs/sec)", batch_total_time, batch_result.throughput_docs_per_sec);
    println!("- Speed improvement: {:.1}x faster", improvement);
    
    if batch_total_time < 1000 && scores_match && final_pool_stats.hit_rate > 0.5 {
        println!("\nüéä BATCH OPTIMIZATION SUCCESS: Production-ready reranking achieved!");
    } else {
        println!("\n‚úÖ Good progress, further optimizations may be beneficial");
    }
    
    Ok(())
}