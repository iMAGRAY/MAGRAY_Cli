//! Storage Layer Implementation - –ß–∏—Å—Ç–∞—è –ø–µ—Ä—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö
//!
//! SqliteStorageLayer –∏–Ω–∫–∞–ø—Å—É–ª–∏—Ä—É–µ—Ç –≤—Å–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ —Å SQLite –±–∞–∑–æ–π –¥–∞–Ω–Ω—ã—Ö
//! –±–µ–∑ –∑–Ω–∞–Ω–∏—è –æ –≤–µ–∫—Ç–æ—Ä–∞—Ö, –∏–Ω–¥–µ–∫—Å–∞—Ö –∏–ª–∏ –±–∏–∑–Ω–µ—Å-–ª–æ–≥–∏–∫–µ –ø–æ–∏—Å–∫–∞.
//!
//! RESPONSIBILITIES:
//! - CRUD –æ–ø–µ—Ä–∞—Ü–∏–∏ —Å Record
//! - Batch –æ–ø–µ—Ä–∞—Ü–∏–∏ –¥–ª—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
//! - Backup/restore —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å
//! - Database schema management
//! - SQL query optimization

use anyhow::{Result, Context};
use async_trait::async_trait;
use std::collections::HashMap;
use std::path::Path;
use std::sync::Arc;
use tokio::sync::RwLock;
use uuid::Uuid;
use sqlx::{SqlitePool, Row, Sqlite, migrate::MigrateDatabase};
use tracing::{debug, info, warn, error};
use chrono::{DateTime, Utc};

use crate::{
    types::{Record, Layer, RecordMetadata},
    backup::{BackupMetadata, BackupManager, LayerInfo},
    layers::{StorageLayer, StorageStats, LayerHealth, LayerHealthStatus, StorageConfig},
};

/// SQLite implementation –¥–ª—è Storage Layer
/// 
/// –§–æ–∫—É—Å–∏—Ä—É–µ—Ç—Å—è –¢–û–õ–¨–ö–û –Ω–∞ –ø–µ—Ä—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö:
/// - Efficient CRUD operations
/// - Transaction management
/// - Schema evolution
/// - Backup/restore capabilities
pub struct SqliteStorageLayer {
    pool: SqlitePool,
    config: StorageConfig,
    stats: Arc<RwLock<InternalStorageStats>>,
    backup_manager: Option<BackupManager>,
}

/// –í–Ω—É—Ç—Ä–µ–Ω–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
#[derive(Debug, Default)]
struct InternalStorageStats {
    total_reads: u64,
    total_writes: u64,
    total_deletes: u64,
    batch_operations: u64,
    last_optimization: Option<DateTime<Utc>>,
    fragmentation_checks: u64,
}

impl SqliteStorageLayer {
    /// –°–æ–∑–¥–∞—Ç—å –Ω–æ–≤—ã–π SQLite storage layer
    pub async fn new(config: StorageConfig) -> Result<Arc<Self>> {
        info!("üóÉÔ∏è –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è SQLite Storage Layer: {:?}", config.db_path);

        // –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        if let Some(parent) = config.db_path.parent() {
            tokio::fs::create_dir_all(parent).await
                .context("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö")?;
        }

        // –°–æ–∑–¥–∞–µ–º –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        let db_url = format!("sqlite:{}", config.db_path.display());
        if !Sqlite::database_exists(&db_url).await.unwrap_or(false) {
            info!("üìÅ –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–π SQLite –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö: {}", db_url);
            Sqlite::create_database(&db_url).await
                .context("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å SQLite –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö")?;
        }

        // –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è —Å –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏
        let pool = SqlitePool::connect_with(
            sqlx::sqlite::SqliteConnectOptions::new()
                .filename(&config.db_path)
                .create_if_missing(true)
                .journal_mode(sqlx::sqlite::SqliteJournalMode::Wal)
                .synchronous(sqlx::sqlite::SqliteSynchronous::Normal)
                .busy_timeout(std::time::Duration::from_secs(30))
                .pragma("cache_size", "10000")
                .pragma("temp_store", "memory")
                .pragma("mmap_size", "268435456"), // 256MB
        ).await.context("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ SQLite")?;

        // –ó–∞–ø—É—Å–∫–∞–µ–º –º–∏–≥—Ä–∞—Ü–∏–∏
        let storage_layer = Arc::new(Self {
            pool,
            backup_manager: None,
            config: config.clone(),
            stats: Arc::new(RwLock::new(InternalStorageStats::default())),
        });

        storage_layer.run_migrations().await?;

        // –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º backup manager –µ—Å–ª–∏ –ø—É—Ç—å —É–∫–∞–∑–∞–Ω
        let backup_manager = if config.backup_path.exists() || config.backup_path.parent().map(|p| p.exists()).unwrap_or(false) {
            Some(BackupManager::new(config.backup_path.clone()))
        } else {
            None
        };

        let mut layer = Arc::clone(&storage_layer);
        if let Some(backup_mgr) = backup_manager {
            // –ë–µ–∑–æ–ø–∞—Å–Ω–æ –æ–±–Ω–æ–≤–ª—è–µ–º backup_manager —á–µ—Ä–µ–∑ Arc
            // –≠—Ç–æ hack –¥–ª—è –æ–±—Ö–æ–¥–∞ immutability, –≤ production –∫–æ–¥–µ –Ω—É–∂–Ω–∞ –ª—É—á—à–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞
            unsafe {
                let ptr = Arc::as_ptr(&layer) as *mut SqliteStorageLayer;
                (*ptr).backup_manager = Some(backup_mgr);
            }
        }

        info!("‚úÖ SQLite Storage Layer —É—Å–ø–µ—à–Ω–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω");
        Ok(storage_layer)
    }

    /// –ó–∞–ø—É—Å—Ç–∏—Ç—å database migrations
    async fn run_migrations(&self) -> Result<()> {
        info!("üîÑ –ó–∞–ø—É—Å–∫ database migrations...");

        // –°–æ–∑–¥–∞–µ–º –æ—Å–Ω–æ–≤–Ω—ã–µ —Ç–∞–±–ª–∏—Ü—ã –¥–ª—è –≤—Å–µ—Ö —Å–ª–æ–µ–≤
        let migration_sql = r#"
        -- Records table –¥–ª—è –≤—Å–µ—Ö —Å–ª–æ–µ–≤
        CREATE TABLE IF NOT EXISTS records (
            id TEXT PRIMARY KEY NOT NULL,
            layer TEXT NOT NULL,
            content TEXT NOT NULL,
            embedding BLOB,
            metadata TEXT, -- JSON
            created_at TEXT NOT NULL,
            updated_at TEXT NOT NULL,
            
            UNIQUE(id, layer)
        );

        -- –ò–Ω–¥–µ–∫—Å—ã –¥–ª—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        CREATE INDEX IF NOT EXISTS idx_records_layer ON records(layer);
        CREATE INDEX IF NOT EXISTS idx_records_created_at ON records(layer, created_at);
        CREATE INDEX IF NOT EXISTS idx_records_updated_at ON records(layer, updated_at);
        
        -- Metadata search index (–¥–ª—è JSON queries)
        CREATE INDEX IF NOT EXISTS idx_records_metadata ON records(metadata);

        -- Schema version tracking
        CREATE TABLE IF NOT EXISTS schema_version (
            version INTEGER PRIMARY KEY,
            applied_at TEXT NOT NULL
        );

        INSERT OR IGNORE INTO schema_version (version, applied_at) 
        VALUES (1, datetime('now'));
        "#;

        sqlx::query(migration_sql)
            .execute(&self.pool)
            .await
            .context("–ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã–ø–æ–ª–Ω–∏—Ç—å database migrations")?;

        debug!("‚úÖ Database migrations –≤—ã–ø–æ–ª–Ω–µ–Ω—ã —É—Å–ø–µ—à–Ω–æ");
        Ok(())
    }

    /// –ü–æ–ª—É—á–∏—Ç—å connection pool (–¥–ª—è –≤–Ω—É—Ç—Ä–µ–Ω–Ω–µ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è)
    pub fn pool(&self) -> &SqlitePool {
        &self.pool
    }

    /// Serialize metadata to JSON
    fn serialize_metadata(metadata: &RecordMetadata) -> Result<String> {
        serde_json::to_string(metadata)
            .context("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–µ—Ä–∏–∞–ª–∏–∑–æ–≤–∞—Ç—å metadata –≤ JSON")
    }

    /// Deserialize metadata from JSON
    fn deserialize_metadata(json: &str) -> Result<RecordMetadata> {
        serde_json::from_str(json)
            .context("–ù–µ —É–¥–∞–ª–æ—Å—å –¥–µ—Å–µ—Ä–∏–∞–ª–∏–∑–æ–≤–∞—Ç—å metadata –∏–∑ JSON")
    }

    /// Convert Layer enum to string
    fn layer_to_string(layer: Layer) -> &'static str {
        match layer {
            Layer::Interact => "interact",
            Layer::Insights => "insights", 
            Layer::Assets => "assets",
        }
    }

    /// Convert string to Layer enum
    fn string_to_layer(s: &str) -> Result<Layer> {
        match s {
            "interact" => Ok(Layer::Interact),
            "insights" => Ok(Layer::Insights),
            "assets" => Ok(Layer::Assets),
            _ => Err(anyhow::anyhow!("–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π layer: {}", s)),
        }
    }

    /// Increment internal stats (non-blocking)
    fn increment_stat(&self, stat_type: StatType) {
        let stats = Arc::clone(&self.stats);
        tokio::spawn(async move {
            if let Ok(mut stats) = stats.try_write() {
                match stat_type {
                    StatType::Read => stats.total_reads += 1,
                    StatType::Write => stats.total_writes += 1,
                    StatType::Delete => stats.total_deletes += 1,
                    StatType::Batch => stats.batch_operations += 1,
                }
            }
        });
    }
}

enum StatType {
    Read,
    Write,
    Delete,
    Batch,
}

#[async_trait]
impl StorageLayer for SqliteStorageLayer {
    async fn store(&self, record: &Record) -> Result<()> {
        debug!("üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ record {} –≤ —Å–ª–æ–π {:?}", record.id, record.layer);

        let layer_str = Self::layer_to_string(record.layer);
        let metadata_json = Self::serialize_metadata(&record.metadata)?;
        let embedding_blob = bincode::serialize(&record.embedding)
            .context("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–µ—Ä–∏–∞–ª–∏–∑–æ–≤–∞—Ç—å embedding")?;

        let result = sqlx::query(r#"
            INSERT OR REPLACE INTO records 
            (id, layer, content, embedding, metadata, created_at, updated_at)
            VALUES (?, ?, ?, ?, ?, datetime('now'), datetime('now'))
        "#)
        .bind(record.id.to_string())
        .bind(layer_str)
        .bind(&record.content)
        .bind(&embedding_blob)
        .bind(&metadata_json)
        .execute(&self.pool)
        .await;

        match result {
            Ok(_) => {
                self.increment_stat(StatType::Write);
                debug!("‚úÖ Record {} —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω", record.id);
                Ok(())
            }
            Err(e) => {
                error!("‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è record {}: {}", record.id, e);
                Err(anyhow::anyhow!("Storage error: {}", e))
            }
        }
    }

    async fn store_batch(&self, records: &[&Record]) -> Result<usize> {
        if records.is_empty() {
            return Ok(0);
        }

        debug!("üîÑ Batch —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ {} records", records.len());
        
        let mut transaction = self.pool.begin().await
            .context("–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞—á–∞—Ç—å transaction –¥–ª—è batch insert")?;

        let mut successful = 0;
        let batch_size = self.config.write_batch_size.min(records.len());

        for chunk in records.chunks(batch_size) {
            for record in chunk {
                let layer_str = Self::layer_to_string(record.layer);
                let metadata_json = Self::serialize_metadata(&record.metadata)?;
                let embedding_blob = bincode::serialize(&record.embedding)
                    .context("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–µ—Ä–∏–∞–ª–∏–∑–æ–≤–∞—Ç—å embedding")?;

                let result = sqlx::query(r#"
                    INSERT OR REPLACE INTO records 
                    (id, layer, content, embedding, metadata, created_at, updated_at)
                    VALUES (?, ?, ?, ?, ?, datetime('now'), datetime('now'))
                "#)
                .bind(record.id.to_string())
                .bind(layer_str)
                .bind(&record.content)
                .bind(&embedding_blob)
                .bind(&metadata_json)
                .execute(&mut *transaction)
                .await;

                match result {
                    Ok(_) => successful += 1,
                    Err(e) => {
                        warn!("‚ö†Ô∏è –û—à–∏–±–∫–∞ –≤ batch –¥–ª—è record {}: {}", record.id, e);
                        // –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º —Å –æ—Å—Ç–∞–ª—å–Ω—ã–º–∏ records
                    }
                }
            }
        }

        transaction.commit().await
            .context("–ù–µ —É–¥–∞–ª–æ—Å—å commit batch transaction")?;

        self.increment_stat(StatType::Batch);
        info!("‚úÖ Batch –æ–ø–µ—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {}/{} records —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ", successful, records.len());
        
        Ok(successful)
    }

    async fn update(&self, record: &Record) -> Result<()> {
        debug!("üîÑ –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ record {} –≤ —Å–ª–æ–µ {:?}", record.id, record.layer);

        let layer_str = Self::layer_to_string(record.layer);
        let metadata_json = Self::serialize_metadata(&record.metadata)?;
        let embedding_blob = bincode::serialize(&record.embedding)
            .context("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–µ—Ä–∏–∞–ª–∏–∑–æ–≤–∞—Ç—å embedding")?;

        let result = sqlx::query(r#"
            UPDATE records 
            SET content = ?, embedding = ?, metadata = ?, updated_at = datetime('now')
            WHERE id = ? AND layer = ?
        "#)
        .bind(&record.content)
        .bind(&embedding_blob)
        .bind(&metadata_json)
        .bind(record.id.to_string())
        .bind(layer_str)
        .execute(&self.pool)
        .await;

        match result {
            Ok(result) => {
                if result.rows_affected() == 0 {
                    warn!("‚ö†Ô∏è Record {} –Ω–µ –Ω–∞–π–¥–µ–Ω –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –≤ —Å–ª–æ–µ {:?}", record.id, record.layer);
                    return Err(anyhow::anyhow!("Record –Ω–µ –Ω–∞–π–¥–µ–Ω –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è"));
                }
                self.increment_stat(StatType::Write);
                debug!("‚úÖ Record {} —É—Å–ø–µ—à–Ω–æ –æ–±–Ω–æ–≤–ª–µ–Ω", record.id);
                Ok(())
            }
            Err(e) => {
                error!("‚ùå –û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è record {}: {}", record.id, e);
                Err(anyhow::anyhow!("Update error: {}", e))
            }
        }
    }

    async fn delete(&self, id: &Uuid, layer: Layer) -> Result<()> {
        debug!("üóëÔ∏è –£–¥–∞–ª–µ–Ω–∏–µ record {} –∏–∑ —Å–ª–æ—è {:?}", id, layer);

        let layer_str = Self::layer_to_string(layer);

        let result = sqlx::query("DELETE FROM records WHERE id = ? AND layer = ?")
            .bind(id.to_string())
            .bind(layer_str)
            .execute(&self.pool)
            .await;

        match result {
            Ok(result) => {
                if result.rows_affected() == 0 {
                    warn!("‚ö†Ô∏è Record {} –Ω–µ –Ω–∞–π–¥–µ–Ω –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è –≤ —Å–ª–æ–µ {:?}", id, layer);
                    return Err(anyhow::anyhow!("Record –Ω–µ –Ω–∞–π–¥–µ–Ω –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è"));
                }
                self.increment_stat(StatType::Delete);
                debug!("‚úÖ Record {} —É—Å–ø–µ—à–Ω–æ —É–¥–∞–ª–µ–Ω", id);
                Ok(())
            }
            Err(e) => {
                error!("‚ùå –û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è record {}: {}", id, e);
                Err(anyhow::anyhow!("Delete error: {}", e))
            }
        }
    }

    async fn get(&self, id: &Uuid, layer: Layer) -> Result<Option<Record>> {
        self.increment_stat(StatType::Read);
        
        let layer_str = Self::layer_to_string(layer);

        let row = sqlx::query(r#"
            SELECT id, layer, content, embedding, metadata, created_at, updated_at
            FROM records 
            WHERE id = ? AND layer = ?
        "#)
        .bind(id.to_string())
        .bind(layer_str)
        .fetch_optional(&self.pool)
        .await
        .context("–û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö")?;

        match row {
            Some(row) => {
                let id_str: String = row.get("id");
                let layer_str: String = row.get("layer");
                let content: String = row.get("content");
                let embedding_blob: Vec<u8> = row.get("embedding");
                let metadata_json: String = row.get("metadata");

                let id = Uuid::parse_str(&id_str)
                    .context("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–∞—Ä—Å–∏—Ç—å UUID")?;
                let layer = Self::string_to_layer(&layer_str)?;
                let embedding = bincode::deserialize(&embedding_blob)
                    .context("–ù–µ —É–¥–∞–ª–æ—Å—å –¥–µ—Å–µ—Ä–∏–∞–ª–∏–∑–æ–≤–∞—Ç—å embedding")?;
                let metadata = Self::deserialize_metadata(&metadata_json)?;

                Ok(Some(Record {
                    id,
                    layer,
                    content,
                    embedding,
                    metadata,
                }))
            }
            None => Ok(None),
        }
    }

    async fn list(&self, layer: Layer, limit: Option<usize>) -> Result<Vec<Record>> {
        self.increment_stat(StatType::Read);
        
        let layer_str = Self::layer_to_string(layer);
        let limit = limit.unwrap_or(1000).min(10000); // –ó–∞—â–∏—Ç–∞ –æ—Ç —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤

        debug!("üìã –ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ records –∏–∑ —Å–ª–æ—è {:?}, –ª–∏–º–∏—Ç: {}", layer, limit);

        let rows = sqlx::query(r#"
            SELECT id, layer, content, embedding, metadata, created_at, updated_at
            FROM records 
            WHERE layer = ?
            ORDER BY created_at DESC
            LIMIT ?
        "#)
        .bind(layer_str)
        .bind(limit as i64)
        .fetch_all(&self.pool)
        .await
        .context("–û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ —Å–ø–∏—Å–∫–∞ records")?;

        let mut records = Vec::new();
        for row in rows {
            let id_str: String = row.get("id");
            let layer_str: String = row.get("layer");
            let content: String = row.get("content");
            let embedding_blob: Vec<u8> = row.get("embedding");
            let metadata_json: String = row.get("metadata");

            let id = Uuid::parse_str(&id_str).context("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–∞—Ä—Å–∏—Ç—å UUID")?;
            let layer = Self::string_to_layer(&layer_str)?;
            let embedding = bincode::deserialize(&embedding_blob)
                .context("–ù–µ —É–¥–∞–ª–æ—Å—å –¥–µ—Å–µ—Ä–∏–∞–ª–∏–∑–æ–≤–∞—Ç—å embedding")?;
            let metadata = Self::deserialize_metadata(&metadata_json)?;

            records.push(Record {
                id,
                layer,
                content,
                embedding,
                metadata,
            });
        }

        debug!("üìã –ù–∞–π–¥–µ–Ω–æ {} records –≤ —Å–ª–æ–µ {:?}", records.len(), layer);
        Ok(records)
    }

    async fn filter_by_metadata(&self, filters: &HashMap<String, String>, layer: Layer) -> Result<Vec<Record>> {
        self.increment_stat(StatType::Read);

        if filters.is_empty() {
            return self.list(layer, None).await;
        }

        let layer_str = Self::layer_to_string(layer);
        debug!("üîç –ü–æ–∏—Å–∫ –ø–æ metadata –≤ —Å–ª–æ–µ {:?}: {:?}", layer, filters);

        // –°—Ç—Ä–æ–∏–º WHERE —É—Å–ª–æ–≤–∏–µ –¥–ª—è JSON —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
        let mut where_conditions = vec!["layer = ?".to_string()];
        let mut bind_values = vec![layer_str.to_string()];

        for (key, value) in filters {
            where_conditions.push(format!("JSON_EXTRACT(metadata, '$.{}') = ?", key));
            bind_values.push(value.clone());
        }

        let where_clause = where_conditions.join(" AND ");
        let query_sql = format!(r#"
            SELECT id, layer, content, embedding, metadata, created_at, updated_at
            FROM records 
            WHERE {}
            ORDER BY created_at DESC
            LIMIT 1000
        "#, where_clause);

        let mut query = sqlx::query(&query_sql);
        for value in bind_values {
            query = query.bind(value);
        }

        let rows = query.fetch_all(&self.pool).await
            .context("–û—à–∏–±–∫–∞ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –ø–æ metadata")?;

        let mut records = Vec::new();
        for row in rows {
            let id_str: String = row.get("id");
            let layer_str: String = row.get("layer");
            let content: String = row.get("content");
            let embedding_blob: Vec<u8> = row.get("embedding");
            let metadata_json: String = row.get("metadata");

            let id = Uuid::parse_str(&id_str).context("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–∞—Ä—Å–∏—Ç—å UUID")?;
            let layer = Self::string_to_layer(&layer_str)?;
            let embedding = bincode::deserialize(&embedding_blob)
                .context("–ù–µ —É–¥–∞–ª–æ—Å—å –¥–µ—Å–µ—Ä–∏–∞–ª–∏–∑–æ–≤–∞—Ç—å embedding")?;
            let metadata = Self::deserialize_metadata(&metadata_json)?;

            records.push(Record {
                id,
                layer,
                content,
                embedding,
                metadata,
            });
        }

        debug!("üîç –ù–∞–π–¥–µ–Ω–æ {} records –ø–æ metadata —Ñ–∏–ª—å—Ç—Ä–∞–º", records.len());
        Ok(records)
    }

    async fn backup(&self, path: &str) -> Result<BackupMetadata> {
        info!("üíæ –°–æ–∑–¥–∞–Ω–∏–µ backup –≤ {}", path);

        if let Some(ref backup_manager) = self.backup_manager {
            // –°–æ–∑–¥–∞–µ–º backup —á–µ—Ä–µ–∑ BackupManager (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω)
            let backup_path = backup_manager.create_backup(
                Arc::new(crate::storage::VectorStore::new(
                    self.config.db_path.clone(),
                    Default::default(),
                ).await?),
                Some(path.to_string()),
            ).await?;

            // –°–æ–∑–¥–∞–µ–º metadata
            let mut layer_info = Vec::new();
            for layer in [Layer::Interact, Layer::Insights, Layer::Assets] {
                let count = self.count_records_in_layer(layer).await?;
                layer_info.push(LayerInfo {
                    layer: layer.clone(),
                    record_count: count,
                    size_bytes: 0, // TODO: –≤—ã—á–∏—Å–ª–∏—Ç—å —Ä–µ–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä
                });
            }

            Ok(BackupMetadata {
                version: 1,
                created_at: Utc::now(),
                magray_version: env!("CARGO_PKG_VERSION").to_string(),
                layers: layer_info,
                total_records: layer_info.iter().map(|l| l.record_count).sum(),
                index_config: Default::default(),
                checksum: None,
                layer_checksums: None,
            })
        } else {
            Err(anyhow::anyhow!("Backup manager –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω"))
        }
    }

    async fn restore(&self, path: &str) -> Result<BackupMetadata> {
        info!("üîÑ –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –∏–∑ backup {}", path);
        
        if !Path::new(path).exists() {
            return Err(anyhow::anyhow!("Backup —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {}", path));
        }

        // –ü—Ä–æ—Å—Ç–µ–π—à–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è restore - –≤ —Ä–µ–∞–ª—å–Ω–æ–º –ø—Ä–æ–µ–∫—Ç–µ –Ω—É–∂–Ω–∞ –±–æ–ª–µ–µ —Å–ª–æ–∂–Ω–∞—è –ª–æ–≥–∏–∫–∞
        info!("‚ö†Ô∏è Restore —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å –≤ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ");
        
        Ok(BackupMetadata {
            version: 1,
            created_at: Utc::now(),
            magray_version: env!("CARGO_PKG_VERSION").to_string(),
            layers: vec![],
            total_records: 0,
            index_config: Default::default(),
            checksum: None,
            layer_checksums: None,
        })
    }

    async fn init_layer(&self, layer: Layer) -> Result<()> {
        debug!("üîß –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–ª–æ—è {:?}", layer);
        
        // –î–ª—è SQLite –Ω–µ—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–π –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ —Å–ª–æ–µ–≤
        // –í—Å–µ –¥–∞–Ω–Ω—ã–µ —Ö—Ä–∞–Ω—è—Ç—Å—è –≤ –æ–¥–Ω–æ–π —Ç–∞–±–ª–∏—Ü–µ —Å —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ–º –ø–æ layer column
        
        debug!("‚úÖ –°–ª–æ–π {:?} –≥–æ—Ç–æ–≤", layer);
        Ok(())
    }

    async fn storage_stats(&self) -> Result<StorageStats> {
        let stats = self.stats.read().await;
        
        // –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ —Å–ª–æ—è–º
        let mut records_per_layer = HashMap::new();
        let mut total_records = 0;

        for layer in [Layer::Interact, Layer::Insights, Layer::Assets] {
            let count = self.count_records_in_layer(layer).await?;
            records_per_layer.insert(layer, count);
            total_records += count;
        }

        // –ü–æ–ª—É—á–∞–µ–º —Ä–∞–∑–º–µ—Ä –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
        let total_size_bytes = self.get_database_size().await?;

        Ok(StorageStats {
            total_records,
            records_per_layer,
            total_size_bytes,
            fragmentation_ratio: 0.0, // TODO: –≤—ã—á–∏—Å–ª–∏—Ç—å fragmentation
            last_optimized: stats.last_optimization,
        })
    }

    async fn optimize(&self) -> Result<()> {
        info!("üîß –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è SQLite storage...");

        // VACUUM –¥–ª—è –¥–µ—Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞—Ü–∏–∏
        sqlx::query("VACUUM;")
            .execute(&self.pool)
            .await
            .context("–û—à–∏–±–∫–∞ VACUUM –æ–ø–µ—Ä–∞—Ü–∏–∏")?;

        // ANALYZE –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        sqlx::query("ANALYZE;")
            .execute(&self.pool)
            .await
            .context("–û—à–∏–±–∫–∞ ANALYZE –æ–ø–µ—Ä–∞—Ü–∏–∏")?;

        // –û–±–Ω–æ–≤–ª—è–µ–º –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        {
            let mut stats = self.stats.write().await;
            stats.last_optimization = Some(Utc::now());
            stats.fragmentation_checks += 1;
        }

        info!("‚úÖ SQLite storage –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω");
        Ok(())
    }
}

impl SqliteStorageLayer {
    /// –ü–æ–¥—Å—á–∏—Ç–∞—Ç—å records –≤ —Å–ª–æ–µ (helper –º–µ—Ç–æ–¥)
    async fn count_records_in_layer(&self, layer: Layer) -> Result<u64> {
        let layer_str = Self::layer_to_string(layer);
        
        let row = sqlx::query("SELECT COUNT(*) as count FROM records WHERE layer = ?")
            .bind(layer_str)
            .fetch_one(&self.pool)
            .await
            .context("–û—à–∏–±–∫–∞ –ø–æ–¥—Å—á–µ—Ç–∞ records –≤ —Å–ª–æ–µ")?;
            
        let count: i64 = row.get("count");
        Ok(count as u64)
    }

    /// –ü–æ–ª—É—á–∏—Ç—å —Ä–∞–∑–º–µ—Ä –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö (helper –º–µ—Ç–æ–¥)
    async fn get_database_size(&self) -> Result<u64> {
        match tokio::fs::metadata(&self.config.db_path).await {
            Ok(metadata) => Ok(metadata.len()),
            Err(_) => Ok(0),
        }
    }
}

#[async_trait]
impl LayerHealth for SqliteStorageLayer {
    async fn health_check(&self) -> Result<LayerHealthStatus> {
        let start = std::time::Instant::now();
        
        // –ü—Ä–æ—Å—Ç–æ–π health check - –≤—ã–ø–æ–ª–Ω—è–µ–º SELECT 1
        let result = sqlx::query("SELECT 1 as health")
            .fetch_one(&self.pool)
            .await;

        let response_time_ms = start.elapsed().as_millis() as f32;
        
        match result {
            Ok(_) => Ok(LayerHealthStatus {
                layer_name: "SqliteStorageLayer".to_string(),
                healthy: true,
                response_time_ms,
                error_rate: 0.0,
                last_check: Utc::now(),
                details: {
                    let mut details = HashMap::new();
                    details.insert("database_path".to_string(), self.config.db_path.display().to_string());
                    details.insert("pool_size".to_string(), self.pool.size().to_string());
                    details
                },
            }),
            Err(e) => Ok(LayerHealthStatus {
                layer_name: "SqliteStorageLayer".to_string(),
                healthy: false,
                response_time_ms,
                error_rate: 1.0,
                last_check: Utc::now(),
                details: {
                    let mut details = HashMap::new();
                    details.insert("error".to_string(), e.to_string());
                    details
                },
            }),
        }
    }

    async fn ready_check(&self) -> Result<bool> {
        // –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ pool –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ
        match sqlx::query("SELECT 1").fetch_one(&self.pool).await {
            Ok(_) => Ok(true),
            Err(_) => Ok(false),
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use tempfile::tempdir;

    async fn create_test_storage() -> Result<Arc<SqliteStorageLayer>> {
        let temp_dir = tempdir()?;
        let config = StorageConfig {
            db_path: temp_dir.path().join("test.db"),
            backup_path: temp_dir.path().join("backups"),
            use_rocksdb: false,
            write_batch_size: 100,
        };
        SqliteStorageLayer::new(config).await
    }

    fn create_test_record() -> Record {
        Record {
            id: Uuid::new_v4(),
            layer: Layer::Interact,
            content: "Test content".to_string(),
            embedding: vec![0.1, 0.2, 0.3],
            metadata: RecordMetadata::default(),
        }
    }

    #[tokio::test]
    async fn test_storage_creation() -> Result<()> {
        let storage = create_test_storage().await?;
        assert!(storage.ready_check().await?);
        Ok(())
    }

    #[tokio::test]
    async fn test_crud_operations() -> Result<()> {
        let storage = create_test_storage().await?;
        let record = create_test_record();

        // Test store
        storage.store(&record).await?;

        // Test get
        let retrieved = storage.get(&record.id, record.layer).await?;
        assert!(retrieved.is_some());
        let retrieved_record = retrieved.unwrap();
        assert_eq!(retrieved_record.id, record.id);
        assert_eq!(retrieved_record.content, record.content);

        // Test update
        let mut updated_record = record.clone();
        updated_record.content = "Updated content".to_string();
        storage.update(&updated_record).await?;

        let retrieved_updated = storage.get(&record.id, record.layer).await?;
        assert_eq!(retrieved_updated.unwrap().content, "Updated content");

        // Test delete
        storage.delete(&record.id, record.layer).await?;
        let deleted = storage.get(&record.id, record.layer).await?;
        assert!(deleted.is_none());

        Ok(())
    }

    #[tokio::test]
    async fn test_batch_operations() -> Result<()> {
        let storage = create_test_storage().await?;
        
        let records: Vec<Record> = (0..10)
            .map(|i| Record {
                id: Uuid::new_v4(),
                layer: Layer::Interact,
                content: format!("Test content {}", i),
                embedding: vec![i as f32, (i + 1) as f32],
                metadata: RecordMetadata::default(),
            })
            .collect();

        let record_refs: Vec<&Record> = records.iter().collect();
        let stored_count = storage.store_batch(&record_refs).await?;
        assert_eq!(stored_count, 10);

        let list = storage.list(Layer::Interact, Some(20)).await?;
        assert_eq!(list.len(), 10);

        Ok(())
    }

    #[tokio::test]
    async fn test_health_check() -> Result<()> {
        let storage = create_test_storage().await?;
        let health = storage.health_check().await?;
        assert!(health.healthy);
        assert!(health.response_time_ms >= 0.0);
        Ok(())
    }

    #[tokio::test]
    async fn test_storage_stats() -> Result<()> {
        let storage = create_test_storage().await?;
        let record = create_test_record();
        
        storage.store(&record).await?;
        let stats = storage.storage_stats().await?;
        
        assert_eq!(stats.total_records, 1);
        assert_eq!(*stats.records_per_layer.get(&Layer::Interact).unwrap(), 1);
        Ok(())
    }
}