use anyhow::Result;
use std::sync::Arc;
use tracing::{info, debug, warn};

#[allow(unused_imports)]
use crate::{
    di_container::{DIContainer, DIContainerBuilder},
    EmbeddingCache,
    CacheConfig,
    cache_interface::EmbeddingCacheInterface,
    health::{HealthMonitor, HealthMonitorConfig as HealthConfig},
    metrics::MetricsCollector,
    notifications::NotificationManager,
    promotion::PromotionEngine,
    ml_promotion::{MLPromotionEngine, MLPromotionConfig},
    storage::VectorStore,
    types::PromotionConfig,
    gpu_accelerated::{GpuBatchProcessor, BatchProcessorConfig},
    backup::BackupManager,
    resource_manager::{ResourceManager, ResourceConfig},
    batch_manager::{BatchOperationManager, BatchConfig},
    CacheConfigType, MemoryConfig,
    orchestration::{
        EmbeddingCoordinator,
        SearchCoordinator, 
        HealthManager,
        PromotionCoordinator,
        ResourceController,
        BackupCoordinator,
        MemoryOrchestrator,
    },
};
use ai::{AiConfig, EmbeddingConfig, ModelLoader};

/// –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ç–æ—Ä DI –¥–ª—è memory —Å–∏—Å—Ç–µ–º—ã
pub struct MemoryDIConfigurator;

impl MemoryDIConfigurator {
    /// –ù–∞—Å—Ç—Ä–æ–∏—Ç—å –ø–æ–ª–Ω—ã–π DI –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä –¥–ª—è memory —Å–∏—Å—Ç–µ–º—ã
    pub async fn configure_full(config: MemoryConfig) -> Result<DIContainer> {
        info!("üîß –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–æ–ª–Ω–æ–≥–æ DI –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞ –¥–ª—è memory —Å–∏—Å—Ç–µ–º—ã");

        let builder = DIContainerBuilder::new();

        let container = builder
            .configure_core_dependencies(&config).await?
            .configure_storage_layer(&config).await?
            .configure_cache_layer(&config).await?
            .configure_monitoring_layer(&config).await?  // –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –¥–æ processing layer
            .configure_processing_layer(&config).await?
            .configure_backup_layer(&config).await?
            .configure_orchestration_layer(&config).await?  // –ö–æ–æ—Ä–¥–∏–Ω–∞—Ç–æ—Ä—ã –ø–æ—Å–ª–µ –≤—Å–µ—Ö dependencies
            .build()?;

        // –°–æ–∑–¥–∞–µ–º async –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –ø–æ—Å–ª–µ –±–∞–∑–æ–≤–æ–≥–æ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞
        Self::configure_async_components(&container, &config).await?;

        info!("‚úÖ DI –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä –Ω–∞—Å—Ç—Ä–æ–µ–Ω —Å {} –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—è–º–∏", 
              container.stats().total_types);

        Ok(container)
    }

    /// –ù–∞—Å—Ç—Ä–æ–∏—Ç—å –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä –¥–ª—è —Ç–µ—Å—Ç–æ–≤
    pub async fn configure_minimal(config: MemoryConfig) -> Result<DIContainer> {
        info!("üîß –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–≥–æ DI –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞");

        let builder = DIContainerBuilder::new()
            .configure_core_dependencies(&config).await?
            .configure_storage_layer(&config).await?
            .configure_cache_layer(&config).await?
            .configure_monitoring_layer(&config).await?  // –ù—É–∂–Ω–æ –¥–ª—è –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–æ—Ä–æ–≤
            .configure_backup_layer(&config).await?;  // –ù—É–∂–Ω–æ –¥–ª—è BackupCoordinator

        // –°–æ–∑–¥–∞–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä –ë–ï–ó orchestration layer –ø–æ–∫–∞
        let container = builder.build()?;

        // –°–æ–∑–¥–∞–µ–º async –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã —Å–Ω–∞—á–∞–ª–∞ (PromotionEngine, MLPromotionEngine)
        Self::configure_async_components(&container, &config).await?;
        
        // –¢–µ–ø–µ—Ä—å –º–æ–∂–µ–º –¥–æ–±–∞–≤–∏—Ç—å orchestration –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–æ—Ä—ã –≤—Ä—É—á–Ω—É—é
        Self::register_orchestration_coordinators(&container).await?;

        info!("‚úÖ –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π DI –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä –Ω–∞—Å—Ç—Ä–æ–µ–Ω —Å {} –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—è–º–∏", 
              container.stats().total_types);
        Ok(container)
    }

    /// –ù–∞—Å—Ç—Ä–æ–∏—Ç—å —Ç–æ–ª—å–∫–æ CPU –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ (–±–µ–∑ GPU)
    pub async fn configure_cpu_only(config: MemoryConfig) -> Result<DIContainer> {
        info!("üîß –ù–∞—Å—Ç—Ä–æ–π–∫–∞ CPU-only DI –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞");

        let mut cpu_config = config;
        cpu_config.ai_config.embedding.use_gpu = false;
        cpu_config.ai_config.reranking.use_gpu = false;

        let container = DIContainerBuilder::new()
            .configure_core_dependencies(&cpu_config).await?
            .configure_storage_layer(&cpu_config).await?
            .configure_cache_layer(&cpu_config).await?
            .configure_monitoring_layer(&cpu_config).await?
            .build()?;

        info!("‚úÖ CPU-only DI –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä –Ω–∞—Å—Ç—Ä–æ–µ–Ω");
        Ok(container)
    }

    /// –ù–∞—Å—Ç—Ä–æ–∏—Ç—å async –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –ø–æ—Å–ª–µ –±–∞–∑–æ–≤–æ–≥–æ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞
    pub async fn configure_async_components(container: &DIContainer, config: &MemoryConfig) -> Result<()> {
        info!("üîß –ù–∞—Å—Ç—Ä–æ–π–∫–∞ async –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤");
        
        // –°–æ–∑–¥–∞–µ–º PromotionEngine
        let store = container.resolve::<VectorStore>()
            .map_err(|e| anyhow::anyhow!("Failed to resolve VectorStore for PromotionEngine: {}", e))?;
        let promotion_config = PromotionConfig::default();
        // PromotionEngine —Ç—Ä–µ–±—É–µ—Ç db: Arc<Db>, —Å–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –±–∞–∑—É –¥–ª—è —Ç–µ—Å—Ç–æ–≤
        let temp_db = Arc::new(sled::open(std::env::temp_dir().join("promotion_db"))
            .map_err(|e| anyhow::anyhow!("Failed to create temp db: {}", e))?);
        
        info!("–°–æ–∑–¥–∞–Ω–∏–µ PromotionEngine");
        let promotion_engine = PromotionEngine::new(store, promotion_config, temp_db).await
            .map_err(|e| anyhow::anyhow!("Failed to create PromotionEngine: {}", e))?;
        
        container.register_instance(promotion_engine)?;

        // –°–æ–∑–¥–∞–µ–º MLPromotionEngine
        let ml_config = MLPromotionConfig::default();
        let store_for_ml = container.resolve::<VectorStore>()
            .map_err(|e| anyhow::anyhow!("Failed to resolve VectorStore for MLPromotionEngine: {}", e))?;
        
        info!("–°–æ–∑–¥–∞–Ω–∏–µ MLPromotionEngine");
        let ml_engine = MLPromotionEngine::new(store_for_ml, ml_config).await
            .map_err(|e| anyhow::anyhow!("Failed to create MLPromotionEngine: {}", e))?;
        
        container.register_instance(ml_engine)?;

        // GPU Processor (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        if config.ai_config.embedding.use_gpu {
            let gpu_config = BatchProcessorConfig::default();
            let embedding_config = container.resolve::<EmbeddingConfig>()
                .map_err(|e| anyhow::anyhow!("Failed to resolve EmbeddingConfig: {}", e))?;
            let cache = container.resolve::<Arc<dyn EmbeddingCacheInterface>>()
                .map_err(|e| anyhow::anyhow!("Failed to resolve cache for GPU: {}", e))?;
            
            info!("–°–æ–∑–¥–∞–Ω–∏–µ GpuBatchProcessor");
            let processor = GpuBatchProcessor::new(gpu_config, (*embedding_config).clone(), (*cache).clone()).await
                .map_err(|e| anyhow::anyhow!("Failed to create GpuBatchProcessor: {}", e))?;
            
            container.register_instance(processor)?;
        }

        info!("‚úÖ Async –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –Ω–∞—Å—Ç—Ä–æ–µ–Ω—ã");
        Ok(())
    }
    
    /// –†–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞—Ç—å orchestration –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–æ—Ä—ã –ü–û–°–õ–ï async –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
    async fn register_orchestration_coordinators(container: &DIContainer) -> Result<()> {
        info!("üîß –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è orchestration –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–æ—Ä–æ–≤");
        
        // EmbeddingCoordinator
        let cache = container.resolve::<Arc<dyn EmbeddingCacheInterface>>()?;
        let embedding_coordinator = if let Some(gpu_processor) = container.try_resolve::<GpuBatchProcessor>() {
            EmbeddingCoordinator::new(gpu_processor, (*cache).clone())
        } else {
            // Fallback - —Å–æ–∑–¥–∞–µ–º CPU processor
            warn!("GPU processor –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, —Å–æ–∑–¥–∞–µ–º CPU fallback –¥–ª—è EmbeddingCoordinator");
            let embedding_config = container.resolve::<ai::EmbeddingConfig>()?;
            let mut cpu_config = (*embedding_config).clone();
            cpu_config.use_gpu = false;
            
            let gpu_config = BatchProcessorConfig::default();
            let gpu_processor = GpuBatchProcessor::new(gpu_config, cpu_config, (*cache).clone()).await?;
            EmbeddingCoordinator::new(Arc::new(gpu_processor), (*cache).clone())
        };
        container.register_instance(embedding_coordinator)?;
        
        // SearchCoordinator
        let store = container.resolve::<VectorStore>()?;
        let embedding_coord = container.resolve::<EmbeddingCoordinator>()?;
        let search_coordinator = SearchCoordinator::new(store, embedding_coord);
        container.register_instance(search_coordinator)?;
        
        // HealthManager
        let health_monitor = container.resolve::<HealthMonitor>()?;
        let health_manager = HealthManager::new(health_monitor);
        container.register_instance(health_manager)?;
        
        // PromotionCoordinator
        let promotion_engine = container.resolve::<PromotionEngine>()?;
        let ml_promotion = container.try_resolve::<parking_lot::RwLock<MLPromotionEngine>>();
        let promotion_coordinator = PromotionCoordinator::new(promotion_engine, ml_promotion);
        container.register_instance(promotion_coordinator)?;
        
        // ResourceController
        let resource_config = ResourceConfig::default();
        let resource_manager = ResourceManager::new(resource_config)?;
        let wrapped_manager = Arc::new(parking_lot::RwLock::new(resource_manager));
        let resource_controller = ResourceController::new(wrapped_manager);
        container.register_instance(resource_controller)?;
        
        // BackupCoordinator
        let backup_manager = container.resolve::<BackupManager>()?;
        let store = container.resolve::<VectorStore>()?;
        let backup_coordinator = BackupCoordinator::new(backup_manager, store);
        container.register_instance(backup_coordinator)?;
        
        // MemoryOrchestrator (–≥–ª–∞–≤–Ω—ã–π)
        let memory_orchestrator = MemoryOrchestrator::from_container(container)?;
        container.register_instance(memory_orchestrator)?;
        
        info!("‚úÖ Orchestration –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–æ—Ä—ã –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω—ã");
        Ok(())
    }
}

/// Extension trait –¥–ª—è —É–¥–æ–±–Ω–æ–π –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
trait MemoryDIExtensions {
    async fn configure_core_dependencies(self, config: &MemoryConfig) -> Result<Self>
    where 
        Self: Sized;
    
    async fn configure_storage_layer(self, config: &MemoryConfig) -> Result<Self>
    where 
        Self: Sized;
    
    async fn configure_cache_layer(self, config: &MemoryConfig) -> Result<Self>
    where 
        Self: Sized;
    
    async fn configure_processing_layer(self, config: &MemoryConfig) -> Result<Self>
    where 
        Self: Sized;
    
    async fn configure_monitoring_layer(self, config: &MemoryConfig) -> Result<Self>
    where 
        Self: Sized;
    
    async fn configure_backup_layer(self, config: &MemoryConfig) -> Result<Self>
    where 
        Self: Sized;
    
    async fn configure_orchestration_layer(self, config: &MemoryConfig) -> Result<Self>
    where 
        Self: Sized;
}

impl MemoryDIExtensions for DIContainerBuilder {
    /// –û—Å–Ω–æ–≤–Ω—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ (–∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è, AI —Å–µ—Ä–≤–∏—Å—ã)
    async fn configure_core_dependencies(self, config: &MemoryConfig) -> Result<Self> {
        debug!("–ù–∞—Å—Ç—Ä–æ–π–∫–∞ core dependencies");

        let config_clone = (*config).clone();
        let self_with_config = self
            .register_instance(config_clone)?;

        // AI –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
        let ai_config = config.ai_config.clone();
        let self_with_ai = self_with_config
            .register_instance(ai_config)?;

        // Embedding –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∏–∑ AI config  
        let embedding_config = EmbeddingConfig {
            model_name: config.ai_config.embedding.model_name.clone(),
            batch_size: 32,
            max_length: 512,
            use_gpu: config.ai_config.embedding.use_gpu,
            gpu_config: None,
            embedding_dim: Some(1024), // Qwen3 standard dimension
        };

        let self_with_embedding = self_with_ai
            .register_instance(embedding_config)?;

        // Model Loader (singleton –¥–ª—è –ø–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è)
        let final_self = self_with_embedding
            .register_singleton(|container| {
                let ai_config = container.resolve::<AiConfig>()?;
                Ok(Arc::new(ModelLoader::new(&ai_config.models_dir)))
            })?;

        debug!("‚úì Core dependencies –Ω–∞—Å—Ç—Ä–æ–µ–Ω—ã");
        Ok(final_self)
    }

    /// –°–ª–æ–π —Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö (VectorStore)
    async fn configure_storage_layer(self, config: &MemoryConfig) -> Result<Self> {
        debug!("–ù–∞—Å—Ç—Ä–æ–π–∫–∞ storage layer");

        let db_path = config.db_path.clone();
        
        // –°–æ–∑–¥–∞–µ–º VectorStore –∑–∞—Ä–∞–Ω–µ–µ –≤ async –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ
        info!("–°–æ–∑–¥–∞–Ω–∏–µ VectorStore –ø–æ –ø—É—Ç–∏: {:?}", db_path);
        let store = VectorStore::new(&db_path).await
            .map_err(|e| anyhow::anyhow!("Failed to create VectorStore: {}", e))?;
        
        let final_self = self
            .register_instance(store)?;

        debug!("‚úì Storage layer –Ω–∞—Å—Ç—Ä–æ–µ–Ω");
        Ok(final_self)
    }

    /// –°–ª–æ–π –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è (EmbeddingCache)
    async fn configure_cache_layer(self, config: &MemoryConfig) -> Result<Self> {
        debug!("–ù–∞—Å—Ç—Ä–æ–π–∫–∞ cache layer");

        let cache_config_clone = config.cache_config.clone();
        let cache_path = config.cache_path.clone();
        
        let final_self = self.register_singleton(move |_container| {
            info!("–ù–∞—Å—Ç—Ä–æ–π–∫–∞ cache layer");
            // –¢–æ–ª—å–∫–æ LRU cache (—É–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–æ)
            info!("–°–æ–∑–¥–∞–Ω–∏–µ LRU cache: max_entries={}, ttl={}s", 
                  cache_config_clone.max_entries, 
                  cache_config_clone.ttl_seconds.unwrap_or(3600));
            let cache_interface: Arc<dyn EmbeddingCacheInterface> = Arc::new(
                EmbeddingCache::new(&cache_path, cache_config_clone.clone())?
            );
            Ok(cache_interface)
        })?;

        debug!("‚úì Cache layer –Ω–∞—Å—Ç—Ä–æ–µ–Ω");
        Ok(final_self)
    }

    /// –°–ª–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ (GPU, Batch, Promotion)
    async fn configure_processing_layer(self, config: &MemoryConfig) -> Result<Self> {
        debug!("–ù–∞—Å—Ç—Ä–æ–π–∫–∞ processing layer");

        let mut builder = self;

        // Batch Manager
        builder = builder
            .register_singleton(|container| {
                info!("–°–æ–∑–¥–∞–Ω–∏–µ BatchOperationManager");
                let store = container.resolve::<VectorStore>()?;
                let batch_config = BatchConfig::default();
                let metrics = container.try_resolve::<Arc<MetricsCollector>>()
                    .map(|arc_arc| arc_arc.as_ref().clone());
                let manager = BatchOperationManager::new(store, batch_config, metrics);
                Ok(Arc::new(manager))
            })?;

        // GPU Processor –≤—Ä–µ–º–µ–Ω–Ω–æ –æ—Ç–∫–ª—é—á–µ–Ω - —Ç—Ä–µ–±—É–µ—Ç complex async setup
        if config.ai_config.embedding.use_gpu {
            debug!("GPU processor –≤—Ä–µ–º–µ–Ω–Ω–æ –æ—Ç–∫–ª—é—á–µ–Ω –¥–ª—è —É–ø—Ä–æ—â–µ–Ω–∏—è");
        }

        debug!("‚úì Processing layer –Ω–∞—Å—Ç—Ä–æ–µ–Ω");
        Ok(builder)
    }

    /// –°–ª–æ–π –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ (HealthMonitor, Metrics)
    async fn configure_monitoring_layer(self, _config: &MemoryConfig) -> Result<Self> {
        debug!("–ù–∞—Å—Ç—Ä–æ–π–∫–∞ monitoring layer");

        let mut builder = self;

        // Health Monitor
        builder = builder
            .register_singleton(|_container| {
                info!("–°–æ–∑–¥–∞–Ω–∏–µ HealthMonitor");
                let health_config = HealthConfig::default();
                let monitor = HealthMonitor::new(health_config);
                Ok(Arc::new(monitor))
            })?;

        // Metrics Collector
        builder = builder
            .register_singleton(|_container| {
                info!("–°–æ–∑–¥–∞–Ω–∏–µ MetricsCollector");
                let collector = MetricsCollector::new();
                Ok(Arc::new(collector))
            })?;

        // Notification Manager
        builder = builder
            .register_singleton(|_container| {
                info!("–°–æ–∑–¥–∞–Ω–∏–µ NotificationManager");
                let notification_config = crate::notifications::NotificationConfig::default();
                let manager = NotificationManager::new(notification_config)?;
                Ok(Arc::new(manager))
            })?;

        debug!("‚úì Monitoring layer –Ω–∞—Å—Ç—Ä–æ–µ–Ω");
        Ok(builder)
    }

    /// –°–ª–æ–π —Ä–µ–∑–µ—Ä–≤–Ω–æ–≥–æ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è
    async fn configure_backup_layer(self, _config: &MemoryConfig) -> Result<Self> {
        debug!("–ù–∞—Å—Ç—Ä–æ–π–∫–∞ backup layer");

        let final_self = self
            .register_singleton(|_container| {
                info!("–°–æ–∑–¥–∞–Ω–∏–µ BackupManager");
                let manager = BackupManager::new(std::path::Path::new("./backups"));
                Ok(Arc::new(manager))
            })?;

        debug!("‚úì Backup layer –Ω–∞—Å—Ç—Ä–æ–µ–Ω");
        Ok(final_self)
    }
    
    /// –°–ª–æ–π orchestration –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–æ—Ä–æ–≤
    async fn configure_orchestration_layer(self, _config: &MemoryConfig) -> Result<Self> {
        debug!("–ù–∞—Å—Ç—Ä–æ–π–∫–∞ orchestration layer");
        
        let mut builder = self;
        
        // EmbeddingCoordinator
        builder = builder
            .register_singleton(|container| {
                info!("–°–æ–∑–¥–∞–Ω–∏–µ EmbeddingCoordinator");
                let cache = container.resolve::<Arc<dyn EmbeddingCacheInterface>>()?;
                
                // –ü—ã—Ç–∞–µ–º—Å—è –ø–æ–ª—É—á–∏—Ç—å GPU processor, –µ—Å–ª–∏ –Ω–µ—Ç - —Å–æ–∑–¥–∞–µ–º fallback
                if let Some(gpu_processor) = container.try_resolve::<GpuBatchProcessor>() {
                    Ok(Arc::new(EmbeddingCoordinator::new(gpu_processor, (*cache).clone())))
                } else {
                    // Fallback –Ω–∞ —Å–æ–∑–¥–∞–Ω–∏–µ CPU-only embedding coordinator –±–µ–∑ GPU processor
                    warn!("GPU processor –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω –≤ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏");
                    
                    // –ü—ã—Ç–∞–µ–º—Å—è —Å–æ–∑–¥–∞—Ç—å GPU processor —Å CPU fallback
                    let embedding_config = container.resolve::<ai::EmbeddingConfig>()?;
                    let mut cpu_config = (*embedding_config).clone();
                    cpu_config.use_gpu = false; // –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ CPU —Ä–µ–∂–∏–º
                    
                    let gpu_config = BatchProcessorConfig::default();
                    
                    // –°–æ–∑–¥–∞–µ–º –≤ async –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ
                    let gpu_processor_result = tokio::task::block_in_place(|| {
                        tokio::runtime::Handle::current().block_on(async {
                            GpuBatchProcessor::new(gpu_config, cpu_config, (*cache).clone()).await
                        })
                    });
                    
                    match gpu_processor_result {
                        Ok(processor) => Ok(Arc::new(EmbeddingCoordinator::new(Arc::new(processor), (*cache).clone()))),
                        Err(e) => Err(anyhow::anyhow!("Failed to create fallback EmbeddingCoordinator: {}", e))
                    }
                }
            })?;
        
        // SearchCoordinator
        builder = builder
            .register_singleton(|container| {
                info!("–°–æ–∑–¥–∞–Ω–∏–µ SearchCoordinator");
                let store = container.resolve::<VectorStore>()?;
                let embedding_coordinator = container.resolve::<EmbeddingCoordinator>()?;
                Ok(Arc::new(SearchCoordinator::new(store, embedding_coordinator)))
            })?;
        
        // HealthManager
        builder = builder
            .register_singleton(|container| {
                info!("–°–æ–∑–¥–∞–Ω–∏–µ HealthManager");
                let health_monitor = container.resolve::<HealthMonitor>()?;
                Ok(Arc::new(HealthManager::new(health_monitor)))
            })?;
        
        // PromotionCoordinator
        builder = builder
            .register_singleton(|container| {
                info!("–°–æ–∑–¥–∞–Ω–∏–µ PromotionCoordinator");
                let promotion_engine = container.resolve::<PromotionEngine>()?;
                let ml_promotion = container.try_resolve::<parking_lot::RwLock<MLPromotionEngine>>();
                Ok(Arc::new(PromotionCoordinator::new(promotion_engine, ml_promotion)))
            })?;
        
        // ResourceController
        builder = builder
            .register_singleton(|_container| {
                info!("–°–æ–∑–¥–∞–Ω–∏–µ ResourceController");
                let resource_config = ResourceConfig::default();
                let resource_manager = ResourceManager::new(resource_config)?;
                let wrapped_manager = Arc::new(parking_lot::RwLock::new(resource_manager));
                Ok(Arc::new(ResourceController::new(wrapped_manager)))
            })?;
        
        // BackupCoordinator
        builder = builder
            .register_singleton(|container| {
                info!("–°–æ–∑–¥–∞–Ω–∏–µ BackupCoordinator");
                let backup_manager = container.resolve::<BackupManager>()?;
                let store = container.resolve::<VectorStore>()?;
                Ok(Arc::new(BackupCoordinator::new(backup_manager, store)))
            })?;
        
        // MemoryOrchestrator (—Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω—ã–π –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–æ—Ä)
        builder = builder
            .register_singleton(|container| {
                info!("–°–æ–∑–¥–∞–Ω–∏–µ MemoryOrchestrator");
                Ok(Arc::new(MemoryOrchestrator::from_container(container)?))
            })?;
        
        debug!("‚úì Orchestration layer –Ω–∞—Å—Ç—Ä–æ–µ–Ω");
        Ok(builder)
    }
}

/// Test helpers –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π
#[cfg(test)]
pub mod test_helpers {
    use super::*;
    use ai::{AiConfig, EmbeddingConfig as AiEmbeddingConfig, RerankingConfig};

    pub fn create_test_config() -> Result<MemoryConfig> {
        let temp_dir = std::env::temp_dir();
        let db_path = temp_dir.join("test_magray_db");
        let cache_path = temp_dir.join("test_cache");
        
        // –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É—é—Ç
        std::fs::create_dir_all(&db_path)?;
        std::fs::create_dir_all(&cache_path)?;
        
        let ai_config = AiConfig {
            models_dir: temp_dir.join("models"),
            embedding: AiEmbeddingConfig {
                model_name: "test-model".to_string(),
                batch_size: 32,
                max_length: 512,
                embedding_dim: Some(1024),
                use_gpu: false,
                gpu_config: None,
            },
            reranking: RerankingConfig {
                model_name: "test-reranker".to_string(),
                batch_size: 16,
                max_length: 512,
                use_gpu: false,
                gpu_config: None,
            },
        };
        
        let cache_config = CacheConfig::default();
        
        Ok(MemoryConfig {
            db_path,
            cache_path,
            promotion: PromotionConfig::default(),
            ml_promotion: None,
            streaming_config: None,
            ai_config,
            cache_config,
            health_enabled: true,
            health_config: HealthConfig::default(),
            resource_config: ResourceConfig::default(),
            notification_config: crate::notifications::NotificationConfig::default(),
            batch_config: BatchConfig::default(),
        })
    }
}
