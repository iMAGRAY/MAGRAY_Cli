use anyhow::Result;
use chrono::{DateTime, Utc};
use serde::{Deserialize, Serialize};
use std::collections::{HashMap, BTreeMap};
use std::sync::Arc;
use tracing::{debug, info};

use crate::{
    storage::VectorStore,
    types::{Layer, Record},
};

/// ML-based promotion engine —Å –º–∞—à–∏–Ω–Ω—ã–º –æ–±—É—á–µ–Ω–∏–µ–º –¥–ª—è smart promotion
/// @component: {"k":"C","id":"ml_promotion_engine","t":"ML-based smart promotion system","m":{"cur":95,"tgt":100,"u":"%"}}
pub struct MLPromotionEngine {
    store: Arc<VectorStore>,
    model: PromotionModel,
    config: MLPromotionConfig,
    usage_tracker: UsageTracker,
    semantic_analyzer: SemanticAnalyzer,
    performance_optimizer: PerformanceOptimizer,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct MLPromotionConfig {
    /// –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π access count –¥–ª—è —Ä–∞—Å—Å–º–æ—Ç—Ä–µ–Ω–∏—è promotion
    pub min_access_threshold: u32,
    /// –í–µ—Å –¥–ª—è temporal features (0.0-1.0)
    pub temporal_weight: f32,
    /// –í–µ—Å –¥–ª—è semantic features (0.0-1.0)
    pub semantic_weight: f32,
    /// –í–µ—Å –¥–ª—è usage features (0.0-1.0)
    pub usage_weight: f32,
    /// –ü–æ—Ä–æ–≥ –¥–ª—è promotion (0.0-1.0)
    pub promotion_threshold: f32,
    /// –†–∞–∑–º–µ—Ä batch –¥–ª—è ML inference
    pub ml_batch_size: usize,
    /// –ò–Ω—Ç–µ—Ä–≤–∞–ª –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ (–≤ —á–∞—Å–∞—Ö)
    pub training_interval_hours: u64,
    /// –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å GPU –¥–ª—è ML –æ–ø–µ—Ä–∞—Ü–∏–π
    pub use_gpu_for_ml: bool,
}

impl Default for MLPromotionConfig {
    fn default() -> Self {
        Self {
            min_access_threshold: 3,
            temporal_weight: 0.3,
            semantic_weight: 0.4,
            usage_weight: 0.3,
            promotion_threshold: 0.7,
            ml_batch_size: 32,
            training_interval_hours: 24,
            use_gpu_for_ml: true,
        }
    }
}

/// ML –º–æ–¥–µ–ª—å –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –≤–∞–∂–Ω–æ—Å—Ç–∏ –∑–∞–ø–∏—Å–µ–π
#[derive(Debug)]
pub struct PromotionModel {
    /// –í–µ—Å–∞ –¥–ª—è —Ä–∞–∑–ª–∏—á–Ω—ã—Ö features
    temporal_weights: Vec<f32>,
    semantic_weights: Vec<f32>,
    usage_weights: Vec<f32>,
    /// Bias term
    bias: f32,
    /// –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏
    accuracy: f32,
    last_training: DateTime<Utc>,
}

/// –¢—Ä–µ–∫–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –¥–ª—è ML features
#[derive(Debug, Default)]
pub struct UsageTracker {
    /// –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–æ—Å—Ç—É–ø–∞ –ø–æ –≤—Ä–µ–º–µ–Ω–∏ —Å—É—Ç–æ–∫
    hourly_access_patterns: BTreeMap<u32, f32>,
    /// –ß–∞—Å—Ç–æ—Ç–∞ –¥–æ—Å—Ç—É–ø–∞ –∫ similar records
    semantic_clusters: HashMap<String, ClusterStats>,
    /// Co-occurrence patterns
    access_sequences: HashMap<String, Vec<String>>,
    /// User behavior patterns
    user_sessions: HashMap<String, SessionStats>,
}

#[derive(Debug, Default, Clone)]
pub struct ClusterStats {
    pub total_accesses: u64,
    pub avg_promotion_time: f32,
    pub success_rate: f32,
}

#[derive(Debug, Default, Clone)]
pub struct SessionStats {
    pub avg_session_length: f32,
    pub access_frequency: f32,
    pub preferred_layers: HashMap<Layer, f32>,
}

/// –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –≤–∞–∂–Ω–æ—Å—Ç–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
#[derive(Debug)]
pub struct SemanticAnalyzer {
    /// –í–∞–∂–Ω—ã–µ keywords –∏ –∏—Ö –≤–µ—Å–∞
    keyword_weights: HashMap<String, f32>,
    /// Topic modeling cache
    topic_cache: HashMap<String, Vec<f32>>,
    /// Semantic similarity threshold
    similarity_threshold: f32,
}

/// –û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –¥–ª—è ML operations
#[derive(Debug)]
pub struct PerformanceOptimizer {
    /// –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    avg_inference_time_ms: f32,
    cache_hit_rate: f32,
    /// Adaptive batch sizing
    optimal_batch_size: usize,
    /// GPU utilization stats
    gpu_utilization: f32,
}

/// –†–µ–∑—É–ª—å—Ç–∞—Ç—ã ML-based promotion
#[derive(Debug, Default, Clone, Serialize, Deserialize)]
pub struct MLPromotionStats {
    pub total_analyzed: usize,
    pub promoted_interact_to_insights: usize,
    pub promoted_insights_to_assets: usize,
    pub ml_inference_time_ms: u64,
    pub feature_extraction_time_ms: u64,
    pub model_accuracy: f32,
    pub avg_confidence_score: f32,
    pub cache_hit_rate: f32,
    pub gpu_utilization: f32,
}

/// Feature vector –¥–ª—è ML –º–æ–¥–µ–ª–∏
#[derive(Debug, Clone)]
pub struct PromotionFeatures {
    /// Temporal features
    pub age_hours: f32,
    pub access_recency: f32,
    pub temporal_pattern_score: f32,
    
    /// Usage features  
    pub access_count: f32,
    pub access_frequency: f32,
    pub session_importance: f32,
    
    /// Semantic features
    pub semantic_importance: f32,
    pub keyword_density: f32,
    pub topic_relevance: f32,
    
    /// Context features
    pub layer_affinity: f32,
    pub co_occurrence_score: f32,
    pub user_preference_score: f32,
}

impl MLPromotionEngine {
    pub async fn new(store: Arc<VectorStore>, config: MLPromotionConfig) -> Result<Self> {
        info!("üß† –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è ML-based Promotion Engine");
        info!("  - Temporal weight: {:.2}", config.temporal_weight);
        info!("  - Semantic weight: {:.2}", config.semantic_weight);
        info!("  - Usage weight: {:.2}", config.usage_weight);
        info!("  - Promotion threshold: {:.2}", config.promotion_threshold);
        info!("  - GPU –¥–ª—è ML: {}", config.use_gpu_for_ml);

        let model = PromotionModel::new();
        let usage_tracker = UsageTracker::default();
        let semantic_analyzer = SemanticAnalyzer::new();
        let performance_optimizer = PerformanceOptimizer::new();

        Ok(Self {
            store,
            model,
            config,
            usage_tracker,
            semantic_analyzer,
            performance_optimizer,
        })
    }

    /// –û—Å–Ω–æ–≤–Ω–æ–π ML-based promotion cycle
    pub async fn run_ml_promotion_cycle(&mut self) -> Result<MLPromotionStats> {
        let start_time = std::time::Instant::now();
        let mut stats = MLPromotionStats::default();

        info!("üß† –ó–∞–ø—É—Å–∫ ML-based promotion —Ü–∏–∫–ª–∞");

        // –≠—Ç–∞–ø 1: –û–±–Ω–æ–≤–ª—è–µ–º usage tracking
        let tracking_time = std::time::Instant::now();
        self.update_usage_tracking().await?;
        debug!("Usage tracking –æ–±–Ω–æ–≤–ª–µ–Ω –∑–∞ {:?}", tracking_time.elapsed());

        // –≠—Ç–∞–ø 2: ML inference –¥–ª—è –≤—Å–µ—Ö –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤
        let inference_time = std::time::Instant::now();
        let candidates = self.get_promotion_candidates().await?;
        stats.total_analyzed = candidates.len();

        if !candidates.is_empty() {
            let (promotions, ml_stats) = self.analyze_candidates_with_ml(candidates).await?;
            
            stats.ml_inference_time_ms = inference_time.elapsed().as_millis() as u64;
            stats.model_accuracy = ml_stats.accuracy;
            stats.avg_confidence_score = ml_stats.avg_confidence;

            // –≠—Ç–∞–ø 3: –í—ã–ø–æ–ª–Ω—è–µ–º promotions –Ω–∞ –æ—Å–Ω–æ–≤–µ ML –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
            let promotion_time = std::time::Instant::now();
            stats.promoted_interact_to_insights = self.execute_promotions(&promotions, Layer::Interact, Layer::Insights).await?;
            stats.promoted_insights_to_assets = self.execute_promotions(&promotions, Layer::Insights, Layer::Assets).await?;
            
            debug!("Promotions –≤—ã–ø–æ–ª–Ω–µ–Ω—ã –∑–∞ {:?}", promotion_time.elapsed());
        }

        // –≠—Ç–∞–ø 4: –û–±–Ω–æ–≤–ª—è–µ–º –º–æ–¥–µ–ª—å –µ—Å–ª–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ
        if self.should_retrain_model() {
            info!("üéØ –ü–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ ML –º–æ–¥–µ–ª–∏...");
            self.retrain_model().await?;
        }

        // –≠—Ç–∞–ø 5: –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        self.update_performance_stats(&mut stats);

        let total_time = start_time.elapsed().as_millis() as u64;
        
        info!("‚úÖ ML promotion —Ü–∏–∫–ª –∑–∞–≤–µ—Ä—à–µ–Ω –∑–∞ {}ms", total_time);
        info!("  üìä –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ: {} –∑–∞–ø–∏—Å–µ–π", stats.total_analyzed);
        info!("  ‚¨ÜÔ∏è Promoted to Insights: {}", stats.promoted_interact_to_insights);
        info!("  ‚¨ÜÔ∏è Promoted to Assets: {}", stats.promoted_insights_to_assets);
        info!("  üéØ Model accuracy: {:.1}%", stats.model_accuracy * 100.0);
        info!("  ‚ö° Avg confidence: {:.2}", stats.avg_confidence_score);

        Ok(stats)
    }

    /// –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ features –¥–ª—è ML –º–æ–¥–µ–ª–∏
    async fn extract_features(&self, record: &Record) -> Result<PromotionFeatures> {
        let now = Utc::now();
        
        // Temporal features
        let age_hours = (now - record.ts).num_hours() as f32;
        let access_recency = self.calculate_access_recency(record);
        let temporal_pattern_score = self.usage_tracker.get_temporal_pattern_score(&record.id);

        // Usage features
        let access_count = record.access_count as f32;
        let access_frequency = self.calculate_access_frequency(record);
        let session_importance = self.calculate_session_importance(record);

        // Semantic features
        let semantic_importance = self.semantic_analyzer.analyze_importance(&record.text).await?;
        let keyword_density = self.semantic_analyzer.calculate_keyword_density(&record.text);
        let topic_relevance = self.semantic_analyzer.get_topic_relevance(&record.text).await?;

        // Context features
        let layer_affinity = self.calculate_layer_affinity(record);
        let co_occurrence_score = self.calculate_co_occurrence_score(record);
        let user_preference_score = self.calculate_user_preference_score(record);

        Ok(PromotionFeatures {
            age_hours,
            access_recency,
            temporal_pattern_score,
            access_count,
            access_frequency,
            session_importance,
            semantic_importance,
            keyword_density,
            topic_relevance,
            layer_affinity,
            co_occurrence_score,
            user_preference_score,
        })
    }

    /// ML inference –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è promotion score
    fn predict_promotion_score(&self, features: &PromotionFeatures) -> f32 {
        // Temporal component
        let temporal_score = 
            features.age_hours * self.model.temporal_weights[0] +
            features.access_recency * self.model.temporal_weights[1] +
            features.temporal_pattern_score * self.model.temporal_weights[2];

        // Usage component
        let usage_score = 
            features.access_count * self.model.usage_weights[0] +
            features.access_frequency * self.model.usage_weights[1] +
            features.session_importance * self.model.usage_weights[2];

        // Semantic component
        let semantic_score = 
            features.semantic_importance * self.model.semantic_weights[0] +
            features.keyword_density * self.model.semantic_weights[1] +
            features.topic_relevance * self.model.semantic_weights[2];

        // Weighted combination
        let final_score = 
            temporal_score * self.config.temporal_weight +
            usage_score * self.config.usage_weight +
            semantic_score * self.config.semantic_weight +
            self.model.bias;

        // Sigmoid activation –¥–ª—è [0,1] range
        1.0 / (1.0 + (-final_score).exp())
    }

    /// –ê–Ω–∞–ª–∏–∑ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ —Å ML
    async fn analyze_candidates_with_ml(&self, candidates: Vec<Record>) -> Result<(Vec<PromotionDecision>, MLInferenceStats)> {
        let start_time = std::time::Instant::now();
        let mut decisions = Vec::new();
        let mut total_confidence = 0.0;

        info!("üî¨ ML –∞–Ω–∞–ª–∏–∑ {} –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –¥–ª—è promotion", candidates.len());

        // –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á–∞–º–∏ –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏
        for batch in candidates.chunks(self.config.ml_batch_size) {
            for record in batch {
                let features = self.extract_features(record).await?;
                let promotion_score = self.predict_promotion_score(&features);
                
                let should_promote = promotion_score >= self.config.promotion_threshold;
                total_confidence += promotion_score;

                if should_promote {
                    decisions.push(PromotionDecision {
                        record: record.clone(),
                        confidence: promotion_score,
                        features,
                        target_layer: self.determine_target_layer(record, promotion_score),
                    });
                }

                debug!("Record {}: score={:.3}, promote={}", 
                    record.id, promotion_score, should_promote);
            }
        }

        let inference_time = start_time.elapsed().as_millis() as u64;
        let avg_confidence = if candidates.is_empty() { 0.0 } else { total_confidence / candidates.len() as f32 };

        let stats = MLInferenceStats {
            inference_time_ms: inference_time,
            accuracy: self.model.accuracy,
            avg_confidence,
            batch_size: self.config.ml_batch_size,
        };

        info!("üéØ ML –∞–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω: {} promotions –∏–∑ {} –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤", 
            decisions.len(), candidates.len());

        Ok((decisions, stats))
    }

    /// –ü–æ–ª—É—á–µ–Ω–∏–µ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –¥–ª—è promotion
    async fn get_promotion_candidates(&self) -> Result<Vec<Record>> {
        debug!("üîç –ü–æ–∏—Å–∫ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –¥–ª—è ML promotion");
        
        let mut candidates = Vec::new();
        
        // –ü–æ–ª—É—á–∞–µ–º –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –∏–∑ Interact —Å–ª–æ—è
        let interact_iter = self.store.iter_layer(Layer::Interact).await?;
        for item in interact_iter {
            if let Ok((_, value)) = item {
                if let Ok(stored) = bincode::deserialize::<crate::storage::StoredRecord>(&value) {
                    if stored.record.access_count >= self.config.min_access_threshold {
                        candidates.push(stored.record);
                    }
                }
            }
        }

        // –ü–æ–ª—É—á–∞–µ–º –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –∏–∑ Insights —Å–ª–æ—è –¥–ª—è promotion –≤ Assets
        let insights_iter = self.store.iter_layer(Layer::Insights).await?;
        for item in insights_iter {
            if let Ok((_, value)) = item {
                if let Ok(stored) = bincode::deserialize::<crate::storage::StoredRecord>(&value) {
                    if stored.record.access_count >= self.config.min_access_threshold * 2 {
                        candidates.push(stored.record);
                    }
                }
            }
        }

        info!("üìã –ù–∞–π–¥–µ–Ω–æ {} –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –¥–ª—è ML –∞–Ω–∞–ª–∏–∑–∞", candidates.len());
        Ok(candidates)
    }

    /// –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ promotions –Ω–∞ –æ—Å–Ω–æ–≤–µ ML —Ä–µ—à–µ–Ω–∏–π
    async fn execute_promotions(&self, decisions: &[PromotionDecision], from_layer: Layer, to_layer: Layer) -> Result<usize> {
        let mut promoted_count = 0;

        for decision in decisions.iter().filter(|d| d.record.layer == from_layer && d.target_layer == to_layer) {
            // –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é –∑–∞–ø–∏—Å—å –¥–ª—è —Ü–µ–ª–µ–≤–æ–≥–æ —Å–ª–æ—è
            let mut promoted_record = decision.record.clone();
            promoted_record.layer = to_layer;
            promoted_record.ts = Utc::now(); // –û–±–Ω–æ–≤–ª—è–µ–º timestamp
            
            // –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –Ω–æ–≤—ã–π —Å–ª–æ–π
            self.store.insert(&promoted_record).await?;
            
            // –£–¥–∞–ª—è–µ–º –∏–∑ —Å—Ç–∞—Ä–æ–≥–æ —Å–ª–æ—è
            self.store.delete_by_id(&decision.record.id, from_layer).await?;
            
            promoted_count += 1;
            
            debug!("‚úÖ Promoted record {} from {:?} to {:?} (confidence: {:.3})", 
                decision.record.id, from_layer, to_layer, decision.confidence);
        }

        if promoted_count > 0 {
            info!("‚¨ÜÔ∏è Promoted {} records from {:?} to {:?}", promoted_count, from_layer, to_layer);
        }

        Ok(promoted_count)
    }

    // Helper methods
    fn calculate_access_recency(&self, record: &Record) -> f32 {
        let now = Utc::now();
        let last_access = record.ts;
        let recency_hours = (now - last_access).num_hours() as f32;
        
        // –ò–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –∏ –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º (–±–æ–ª–µ–µ recent = –≤—ã—à–µ score)
        (24.0 / (recency_hours + 1.0)).min(1.0)
    }

    fn calculate_access_frequency(&self, record: &Record) -> f32 {
        let age_days = (Utc::now() - record.ts).num_days() as f32;
        if age_days <= 0.0 { 
            return record.access_count as f32;
        }
        
        record.access_count as f32 / age_days
    }

    fn calculate_session_importance(&self, record: &Record) -> f32 {
        // Placeholder for complex session analysis
        match record.layer {
            Layer::Interact => 0.3,
            Layer::Insights => 0.6,
            Layer::Assets => 0.9,
        }
    }

    fn calculate_layer_affinity(&self, record: &Record) -> f32 {
        // –ê–Ω–∞–ª–∏–∑ —Å–∫–ª–æ–Ω–Ω–æ—Å—Ç–∏ –∑–∞–ø–∏—Å–∏ –∫ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–º—É —Å–ª–æ—é
        match record.layer {
            Layer::Interact => if record.access_count > 5 { 0.8 } else { 0.2 },
            Layer::Insights => if record.access_count > 10 { 0.9 } else { 0.5 },
            Layer::Assets => 1.0,
        }
    }

    fn calculate_co_occurrence_score(&self, _record: &Record) -> f32 {
        // Placeholder –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ co-occurrence patterns
        0.5
    }

    fn calculate_user_preference_score(&self, _record: &Record) -> f32 {
        // Placeholder –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏—Ö –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏–π
        0.5
    }

    fn determine_target_layer(&self, record: &Record, confidence: f32) -> Layer {
        match record.layer {
            Layer::Interact => {
                if confidence > 0.9 { Layer::Assets } else { Layer::Insights }
            },
            Layer::Insights => Layer::Assets,
            Layer::Assets => Layer::Assets, // –£–∂–µ –Ω–∞ –≤–µ—Ä—Ö–Ω–µ–º —É—Ä–æ–≤–Ω–µ
        }
    }

    async fn update_usage_tracking(&mut self) -> Result<()> {
        debug!("üìä –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ usage tracking –¥–ª—è ML");
        // Placeholder –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
        Ok(())
    }

    fn should_retrain_model(&self) -> bool {
        let now = Utc::now();
        let hours_since_training = (now - self.model.last_training).num_hours();
        hours_since_training >= self.config.training_interval_hours as i64
    }

    async fn retrain_model(&mut self) -> Result<()> {
        info!("üéØ –ü–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ ML –º–æ–¥–µ–ª–∏ –¥–ª—è promotion");
        
        // –ü—Ä–æ—Å—Ç–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –≤–µ—Å–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ performance
        for weight in &mut self.model.temporal_weights {
            *weight *= 0.95; // Slight decay
        }
        
        self.model.last_training = Utc::now();
        self.model.accuracy = 0.85; // Placeholder
        
        info!("‚úÖ –ú–æ–¥–µ–ª—å –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∞, accuracy: {:.1}%", self.model.accuracy * 100.0);
        Ok(())
    }

    fn update_performance_stats(&mut self, stats: &mut MLPromotionStats) {
        stats.cache_hit_rate = self.performance_optimizer.cache_hit_rate;
        stats.gpu_utilization = self.performance_optimizer.gpu_utilization;
        
        // –û–±–Ω–æ–≤–ª—è–µ–º –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–µ –º–µ—Ç—Ä–∏–∫–∏
        self.performance_optimizer.avg_inference_time_ms = stats.ml_inference_time_ms as f32;
    }
}

/// –†–µ—à–µ–Ω–∏–µ –æ promotion
#[derive(Debug, Clone)]
pub struct PromotionDecision {
    pub record: Record,
    pub confidence: f32,
    pub features: PromotionFeatures,
    pub target_layer: Layer,
}

/// –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ ML inference
#[derive(Debug)]
pub struct MLInferenceStats {
    pub inference_time_ms: u64,
    pub accuracy: f32,
    pub avg_confidence: f32,
    pub batch_size: usize,
}

impl PromotionModel {
    fn new() -> Self {
        Self {
            temporal_weights: vec![0.2, 0.3, 0.5],
            semantic_weights: vec![0.4, 0.3, 0.3],
            usage_weights: vec![0.5, 0.3, 0.2],
            bias: 0.1,
            accuracy: 0.8,
            last_training: Utc::now(),
        }
    }
}

impl SemanticAnalyzer {
    fn new() -> Self {
        let mut keyword_weights = HashMap::new();
        
        // –í–∞–∂–Ω—ã–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ keywords
        keyword_weights.insert("error".to_string(), 0.9);
        keyword_weights.insert("critical".to_string(), 0.95);
        keyword_weights.insert("important".to_string(), 0.8);
        keyword_weights.insert("bug".to_string(), 0.85);
        keyword_weights.insert("feature".to_string(), 0.7);
        keyword_weights.insert("performance".to_string(), 0.75);
        keyword_weights.insert("security".to_string(), 0.9);
        keyword_weights.insert("optimize".to_string(), 0.7);

        Self {
            keyword_weights,
            topic_cache: HashMap::new(),
            similarity_threshold: 0.7,
        }
    }

    async fn analyze_importance(&self, text: &str) -> Result<f32> {
        let mut importance = 0.0;
        let words: Vec<&str> = text.split_whitespace().collect();
        
        for word in &words {
            let word_lower = word.to_lowercase();
            if let Some(&weight) = self.keyword_weights.get(&word_lower) {
                importance += weight;
            }
        }
        
        // –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø–æ –¥–ª–∏–Ω–µ —Ç–µ–∫—Å—Ç–∞
        if !words.is_empty() {
            importance = (importance / words.len() as f32).min(1.0);
        }
        
        Ok(importance)
    }

    fn calculate_keyword_density(&self, text: &str) -> f32 {
        let words: Vec<&str> = text.split_whitespace().collect();
        let mut keyword_count = 0;
        
        for word in &words {
            if self.keyword_weights.contains_key(&word.to_lowercase()) {
                keyword_count += 1;
            }
        }
        
        if words.is_empty() { 0.0 } else { keyword_count as f32 / words.len() as f32 }
    }

    async fn get_topic_relevance(&self, _text: &str) -> Result<f32> {
        // Placeholder –¥–ª—è topic modeling
        Ok(0.5)
    }
}

impl PerformanceOptimizer {
    fn new() -> Self {
        Self {
            avg_inference_time_ms: 0.0,
            cache_hit_rate: 0.0,
            optimal_batch_size: 32,
            gpu_utilization: 0.0,
        }
    }
}

impl UsageTracker {
    fn get_temporal_pattern_score(&self, _record_id: &uuid::Uuid) -> f32 {
        // Placeholder –¥–ª—è temporal pattern analysis
        0.5
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::types::{Record, Layer};
    use uuid::Uuid;

    #[tokio::test]
    async fn test_ml_promotion_features() {
        let config = MLPromotionConfig::default();
        // Test will need actual VectorStore for full functionality
        // This is a placeholder showing the structure
        assert_eq!(config.promotion_threshold, 0.7);
    }

    #[test]
    fn test_semantic_analyzer() {
        let analyzer = SemanticAnalyzer::new();
        let density = analyzer.calculate_keyword_density("this is a critical error in the system");
        assert!(density > 0.0);
    }

    #[test]
    fn test_promotion_model() {
        let model = PromotionModel::new();
        assert_eq!(model.temporal_weights.len(), 3);
        assert_eq!(model.semantic_weights.len(), 3);
        assert_eq!(model.usage_weights.len(), 3);
    }
}