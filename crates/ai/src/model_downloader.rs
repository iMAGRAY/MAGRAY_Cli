use anyhow::{Context, Result};
#[cfg(feature = "openai")]
use futures_util::StreamExt;
use reqwest;
use std::path::{Path, PathBuf};
use std::sync::atomic::{AtomicU64, Ordering};
use std::sync::Arc;
use tokio::fs;
use tokio::io::AsyncWriteExt;
use tracing::{info, warn};

pub struct ModelDownloader {
    base_path: PathBuf,
    client: reqwest::Client,
}

/// –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏
#[derive(Debug, Clone)]
pub struct ModelInfo {
    pub name: String,
    pub files: Vec<ModelFile>,
    pub total_size: u64,
}

#[derive(Debug, Clone)]
pub struct ModelFile {
    pub filename: String,
    pub url: String,
    pub size: u64,
    pub sha256: Option<String>,
}

// –ü–µ—Ä–µ–Ω–µ—Å–µ–Ω–æ –≤—ã—à–µ —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –º–æ–¥—É–ª—è, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å clippy::items_after_test_module
async fn verify_sha256(path: &Path, expected_hex: &str) -> Result<bool> {
    use sha2::{Digest, Sha256};
    use tokio::io::AsyncReadExt;
    let mut file = tokio::fs::File::open(path).await?;
    let mut hasher = Sha256::new();
    let mut buf = vec![0u8; 1024 * 1024];
    loop {
        let n = file.read(&mut buf).await?;
        if n == 0 {
            break;
        }
        hasher.update(&buf[..n]);
    }
    let result = hasher.finalize();
    let hex = format!("{result:x}");
    Ok(hex.eq_ignore_ascii_case(expected_hex))
}

impl ModelDownloader {
    /// –°–æ–∑–¥–∞—Ç—å –Ω–æ–≤—ã–π –∑–∞–≥—Ä—É–∑—á–∏–∫ –º–æ–¥–µ–ª–µ–π
    pub fn new(base_path: impl AsRef<Path>) -> Result<Self> {
        let mut headers = reqwest::header::HeaderMap::new();
        if let Ok(token) = std::env::var("HF_TOKEN") {
            if !token.is_empty() {
                if let Ok(value) =
                    reqwest::header::HeaderValue::from_str(&format!("Bearer {token}"))
                {
                    headers.insert(reqwest::header::AUTHORIZATION, value);
                }
            }
        }

        let client = reqwest::Client::builder()
            .user_agent("MAGRAY-CLI/1.0")
            .timeout(std::time::Duration::from_secs(300))
            .default_headers(headers)
            .build()?;

        Ok(Self {
            base_path: base_path.as_ref().to_path_buf(),
            client,
        })
    }

    /// –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∏ –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å –µ—Å–ª–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ
    pub async fn ensure_model(&self, model_name: &str) -> Result<PathBuf> {
        let model_path = self.base_path.join(model_name);

        // –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏
        if self.is_model_complete(&model_path).await? {
            info!("‚úÖ –ú–æ–¥–µ–ª—å {} —É–∂–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞", model_name);
            return Ok(model_path);
        }

        // –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –º–æ–¥–µ–ª–∏
        let model_info = self.get_model_info(model_name)?;

        info!(
            "üì• –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ {} ({:.1} MB)",
            model_name,
            model_info.total_size as f64 / 1024.0 / 1024.0
        );

        // –°–æ–∑–¥–∞—ë–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
        fs::create_dir_all(&model_path).await?;

        // –ó–∞–≥—Ä—É–∂–∞–µ–º —Ñ–∞–π–ª—ã
        for file in &model_info.files {
            self.download_file(file, &model_path).await?;
        }

        info!("‚úÖ –ú–æ–¥–µ–ª—å {} —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞", model_name);
        Ok(model_path)
    }

    /// –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —á—Ç–æ –º–æ–¥–µ–ª—å –ø–æ–ª–Ω–æ—Å—Ç—å—é –∑–∞–≥—Ä—É–∂–µ–Ω–∞
    async fn is_model_complete(&self, model_path: &Path) -> Result<bool> {
        if !model_path.exists() {
            return Ok(false);
        }

        // –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –º–æ–¥–µ–ª–∏
        let model_exists = model_path.join("model.onnx").exists();

        if !model_exists {
            return Ok(false);
        }

        // –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –æ—Å—Ç–∞–ª—å–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
        let required_files = vec!["tokenizer.json", "config.json"];

        for file in required_files {
            let file_path = model_path.join(file);
            if !file_path.exists() {
                return Ok(false);
            }

            // –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —Ñ–∞–π–ª –Ω–µ –ø—É—Å—Ç–æ–π
            let metadata = fs::metadata(&file_path).await?;
            if metadata.len() == 0 {
                warn!("‚ö†Ô∏è –§–∞–π–ª {} –ø—É—Å—Ç–æ–π", file);
                return Ok(false);
            }
        }

        // –ï—Å–ª–∏ –µ—Å—Ç—å –∏–∑–≤–µ—Å—Ç–Ω—ã–µ –∫–æ–Ω—Ç—Ä–æ–ª—å–Ω—ã–µ —Å—É–º–º—ã, –ø—Ä–æ–≤–µ—Ä–∏–º
        // (–°–µ–π—á–∞—Å –Ω–µ—Ç —Ä–µ–µ—Å—Ç—Ä–∞ checksum'–æ–≤ –∑–¥–µ—Å—å; –ø–æ–ª–µ sha256 –Ω–∞ –∫–∞–∂–¥–æ–º —Ñ–∞–π–ª–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –∑–∞–¥–∞–Ω–æ –∏–∑ get_model_info)
        let info = self.get_model_info(
            model_path
                .file_name()
                .and_then(|s| s.to_str())
                .unwrap_or(""),
        );
        if let Ok(info) = info {
            for f in &info.files {
                if let Some(sum) = &f.sha256 {
                    let p = model_path.join(&f.filename);
                    if p.exists() {
                        if let Ok(valid) = verify_sha256(&p, sum).await {
                            if !valid {
                                warn!("Checksum mismatch for {}", p.display());
                                return Ok(false);
                            }
                        }
                    }
                }
            }
        }

        Ok(true)
    }

    /// –ü–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –º–æ–¥–µ–ª–∏
    fn get_model_info(&self, model_name: &str) -> Result<ModelInfo> {
        match model_name {
            // Qwen3 Embedding 0.6B: –±—É–¥–µ–º –ø—ã—Ç–∞—Ç—å—Å—è –≤—ã—Ç—è–Ω—É—Ç—å tokenizer/config —Å HF, –∞ model.onnx ‚Äî –∏–∑ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –∫–∞–Ω–¥–∏–¥–∞—Ç–Ω—ã—Ö –ø—É—Ç–µ–π
            "qwen3emb" => Ok(ModelInfo {
                name: "qwen3emb".to_string(),
                files: vec![
                    ModelFile {
                        filename: "model.onnx".to_string(),
                        url: "AUTO".to_string(),
                        size: 0,
                        sha256: None,
                    },
                    ModelFile {
                        filename: "tokenizer.json".to_string(),
                        url: "AUTO".to_string(),
                        size: 0,
                        sha256: None,
                    },
                    ModelFile {
                        filename: "config.json".to_string(),
                        url: "AUTO".to_string(),
                        size: 0,
                        sha256: None,
                    },
                ],
                total_size: 0,
            }),

            // Qwen3 Reranker 0.6B
            "qwen3_reranker" => Ok(ModelInfo {
                name: "qwen3_reranker".to_string(),
                files: vec![
                    ModelFile {
                        filename: "model.onnx".to_string(),
                        url: "AUTO".to_string(),
                        size: 0,
                        sha256: None,
                    },
                    ModelFile {
                        filename: "tokenizer.json".to_string(),
                        url: "AUTO".to_string(),
                        size: 0,
                        sha256: None,
                    },
                    ModelFile {
                        filename: "config.json".to_string(),
                        url: "AUTO".to_string(),
                        size: 0,
                        sha256: None,
                    },
                ],
                total_size: 0,
            }),

            _ => Err(anyhow::anyhow!("–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –º–æ–¥–µ–ª—å: {}", model_name)),
        }
    }

    /// –í–µ—Ä–Ω—É—Ç—å —Å–ø–∏—Å–æ–∫ –∫–∞–Ω–¥–∏–¥–∞—Ç–Ω—ã—Ö URL –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ –º–æ–¥–µ–ª–∏
    fn candidate_urls(&self, model_name: &str, filename: &str) -> Vec<String> {
        let mut out = Vec::new();
        match (model_name, filename) {
            ("qwen3emb", "tokenizer.json") => {
                out.push(
                    "https://huggingface.co/Qwen/Qwen3-Embedding-0.6B/resolve/main/tokenizer.json"
                        .to_string(),
                );
            }
            ("qwen3emb", "config.json") => {
                out.push(
                    "https://huggingface.co/Qwen/Qwen3-Embedding-0.6B/resolve/main/config.json"
                        .to_string(),
                );
            }
            ("qwen3emb", "model.onnx") => {
                out.push(
                    "https://huggingface.co/Qwen/Qwen3-Embedding-0.6B/resolve/main/model.onnx"
                        .to_string(),
                );
                out.push(
                    "https://huggingface.co/Qwen/Qwen3-Embedding-0.6B/resolve/main/onnx/model.onnx"
                        .to_string(),
                );
                out.push("https://huggingface.co/Qwen/Qwen3-Embedding-0.6B/resolve/main/onnx/encoder_model.onnx".to_string());
                out.push(
                    "https://huggingface.co/Qwen/Qwen3-Embedding-0.6B/resolve/main/model_fp16.onnx"
                        .to_string(),
                );
            }
            ("qwen3_reranker", "tokenizer.json") => {
                out.push(
                    "https://huggingface.co/Qwen/Qwen3-Reranker-0.6B/resolve/main/tokenizer.json"
                        .to_string(),
                );
            }
            ("qwen3_reranker", "config.json") => {
                out.push(
                    "https://huggingface.co/Qwen/Qwen3-Reranker-0.6B/resolve/main/config.json"
                        .to_string(),
                );
            }
            ("qwen3_reranker", "model.onnx") => {
                out.push(
                    "https://huggingface.co/Qwen/Qwen3-Reranker-0.6B/resolve/main/model.onnx"
                        .to_string(),
                );
                out.push(
                    "https://huggingface.co/Qwen/Qwen3-Reranker-0.6B/resolve/main/onnx/model.onnx"
                        .to_string(),
                );
                out.push("https://huggingface.co/Qwen/Qwen3-Reranker-0.6B/resolve/main/onnx/encoder_model.onnx".to_string());
                out.push(
                    "https://huggingface.co/Qwen/Qwen3-Reranker-0.6B/resolve/main/model_fp16.onnx"
                        .to_string(),
                );
            }
            _ => {}
        }
        out
    }

    /// –ó–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª —Å –ø—Ä–æ–≥—Ä–µ—Å—Å–æ–º
    async fn download_file(&self, file: &ModelFile, dest_dir: &Path) -> Result<()> {
        let dest_path = dest_dir.join(&file.filename);

        // –ï—Å–ª–∏ —ç—Ç–æ –ª–æ–∫–∞–ª—å–Ω—ã–π —Ñ–∞–π–ª, –ø—Ä–æ—Å—Ç–æ –ø—Ä–æ–≤–µ—Ä—è–µ–º –µ–≥–æ –Ω–∞–ª–∏—á–∏–µ
        if file.url == "LOCAL_FILE" {
            if dest_path.exists() {
                info!("‚úÖ –õ–æ–∫–∞–ª—å–Ω—ã–π —Ñ–∞–π–ª {} –Ω–∞–π–¥–µ–Ω", file.filename);
                return Ok(());
            } else {
                return Err(anyhow::anyhow!(
                    "–õ–æ–∫–∞–ª—å–Ω—ã–π —Ñ–∞–π–ª {} –Ω–µ –Ω–∞–π–¥–µ–Ω",
                    file.filename
                ));
            }
        }

        // –ï—Å–ª–∏ AUTO ‚Äî –ø–æ–ø—Ä–æ–±—É–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ –∫–∞–Ω–¥–∏–¥–∞—Ç–Ω—ã—Ö URL
        if file.url == "AUTO" {
            let model_name = dest_dir
                .file_name()
                .and_then(|s| s.to_str())
                .unwrap_or("")
                .to_string();
            let candidates = self.candidate_urls(&model_name, &file.filename);
            if candidates.is_empty() {
                warn!("–ù–µ—Ç –∫–∞–Ω–¥–∏–¥–∞—Ç–Ω—ã—Ö URL –¥–ª—è {}/{}", model_name, file.filename);
                // –ü—ã—Ç–∞–µ–º—Å—è –ø—Ä–æ–¥–æ–ª–∂–∏—Ç—å –¥–∞–ª—å—à–µ ‚Äî —Ñ–∞–π–ª –º–æ–∂–µ—Ç –±—ã—Ç—å –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω —Å–∫—Ä–∏–ø—Ç–æ–º –æ—Ç–¥–µ–ª—å–Ω–æ
                return Ok(());
            }

            let mut last_err: Option<anyhow::Error> = None;
            for (idx, url) in candidates.iter().enumerate() {
                match self.try_download_once(url, file, &dest_path).await {
                    Ok(()) => {
                        info!("‚úÖ {} –∑–∞–≥—Ä—É–∂–µ–Ω –∏–∑ {}", file.filename, url);
                        return Ok(());
                    }
                    Err(e) => {
                        warn!(
                            "–ü–æ–ø—ã—Ç–∫–∞ {}/{}: –Ω–µ —É–¥–∞–ª–æ—Å—å —Å–∫–∞—á–∞—Ç—å {} –∏–∑ {}: {}",
                            idx + 1,
                            candidates.len(),
                            file.filename,
                            url,
                            e
                        );
                        last_err = Some(e);
                        // –Ω–µ–±–æ–ª—å—à–æ–π backoff
                        tokio::time::sleep(std::time::Duration::from_millis(250)).await;
                        continue;
                    }
                }
            }
            // –ï—Å–ª–∏ –Ω–∏ –æ–¥–∏–Ω URL –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é –æ—à–∏–±–∫—É
            if let Some(e) = last_err {
                return Err(e);
            }
            return Err(anyhow::anyhow!("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–∫–∞—á–∞—Ç—å {}", file.filename));
        }

        // –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π —Ñ–∞–π–ª
        if dest_path.exists() {
            let metadata = fs::metadata(&dest_path).await?;
            if metadata.len() == file.size {
                // –ï—Å–ª–∏ —É–∫–∞–∑–∞–Ω sha256 ‚Äî –ø—Ä–æ–≤–∞–ª–∏–¥–∏—Ä—É–µ–º
                if let Some(sum) = &file.sha256 {
                    if verify_sha256(&dest_path, sum).await? {
                        info!("‚úÖ –§–∞–π–ª {} —É–∂–µ –∑–∞–≥—Ä—É–∂–µ–Ω (checksum ok)", file.filename);
                        return Ok(());
                    }
                    warn!(
                        "Checksum mismatch for existing {}, re-downloading",
                        file.filename
                    );
                } else {
                    info!("‚úÖ –§–∞–π–ª {} —É–∂–µ –∑–∞–≥—Ä—É–∂–µ–Ω", file.filename);
                    return Ok(());
                }
            } else {
                warn!(
                    "‚ö†Ô∏è –†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ {} –Ω–µ —Å–æ–≤–ø–∞–¥–∞–µ—Ç, –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∂–∞–µ–º",
                    file.filename
                );
            }
        }

        info!(
            "üì• –ó–∞–≥—Ä—É–∑–∫–∞ {} ({:.1} MB)...",
            file.filename,
            file.size as f64 / 1024.0 / 1024.0
        );

        // –ü–æ–ø—ã—Ç–∫–∞ —Å–∫–∞—á–∞—Ç—å –Ω–∞–ø—Ä—è–º—É—é –∏–∑ —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ URL
        self.try_download_once(&file.url, file, &dest_path).await
    }

    async fn try_download_once(&self, url: &str, file: &ModelFile, dest_path: &Path) -> Result<()> {
        // –°–æ–∑–¥–∞—ë–º –∑–∞–ø—Ä–æ—Å
        let response = self
            .client
            .get(url)
            .send()
            .await
            .context("–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ —Ñ–∞–π–ª–∞")?;

        if !response.status().is_success() {
            return Err(anyhow::anyhow!(
                "–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ {}: HTTP {}",
                file.filename,
                response.status()
            ));
        }

        // –ü–æ–ª—É—á–∞–µ–º —Ä–∞–∑–º–µ—Ä
        let total_size = response.content_length().unwrap_or(file.size);

        // –°–æ–∑–¥–∞—ë–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
        let temp_path = dest_path.with_extension("tmp");
        let mut temp_file = tokio::fs::File::create(&temp_path).await?;

        // –ó–∞–≥—Ä—É–∂–∞–µ–º —Å –ø—Ä–æ–≥—Ä–µ—Å—Å–æ–º
        let downloaded = Arc::new(AtomicU64::new(0));
        let downloaded_clone = downloaded.clone();

        // Spawn –∑–∞–¥–∞—á—É –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
        let progress_task = tokio::spawn(async move {
            let mut last_report = std::time::Instant::now();
            loop {
                tokio::time::sleep(tokio::time::Duration::from_secs(1)).await;

                let bytes = downloaded_clone.load(Ordering::Relaxed);
                if total_size > 0 {
                    let progress = (bytes as f64 / total_size as f64) * 100.0;
                    if last_report.elapsed().as_secs() >= 2 {
                        info!(
                            "   üìä –ü—Ä–æ–≥—Ä–µ—Å—Å: {:.1}% ({:.1} MB / {:.1} MB)",
                            progress,
                            bytes as f64 / 1024.0 / 1024.0,
                            total_size as f64 / 1024.0 / 1024.0
                        );
                        last_report = std::time::Instant::now();
                    }
                }

                if total_size > 0 && bytes >= total_size {
                    break;
                }
            }
        });

        // –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        #[cfg(feature = "openai")]
        {
            let mut stream = response.bytes_stream();
            while let Some(chunk) = stream.next().await {
                let chunk = chunk?;
                temp_file.write_all(&chunk).await?;
                downloaded.fetch_add(chunk.len() as u64, Ordering::Relaxed);
            }
        }
        #[cfg(not(feature = "openai"))]
        {
            let bytes = response.bytes().await?;
            temp_file.write_all(&bytes).await?;
            downloaded.fetch_add(bytes.len() as u64, Ordering::Relaxed);
        }

        temp_file.flush().await?;
        drop(temp_file);

        // –ñ–¥—ë–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
        progress_task.abort();

        // –í–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏—è checksum –µ—Å–ª–∏ –∑–∞–¥–∞–Ω–∞
        if let Some(sum) = &file.sha256 {
            if !verify_sha256(&temp_path, sum).await? {
                return Err(anyhow::anyhow!(
                    "Checksum verification failed for {}",
                    file.filename
                ));
            }
        }

        // –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤—ã–≤–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
        fs::rename(&temp_path, &dest_path).await?;

        info!("‚úÖ {} –∑–∞–≥—Ä—É–∂–µ–Ω —É—Å–ø–µ—à–Ω–æ", file.filename);
        Ok(())
    }

    /// –û—á–∏—Å—Ç–∏—Ç—å –∫—ç—à –º–æ–¥–µ–ª–µ–π
    pub async fn clear_cache(&self) -> Result<()> {
        if self.base_path.exists() {
            fs::remove_dir_all(&self.base_path).await?;
            info!("üßπ –ö—ç—à –º–æ–¥–µ–ª–µ–π –æ—á–∏—â–µ–Ω");
        }
        Ok(())
    }

    /// –ü–æ–ª—É—á–∏—Ç—å —Ä–∞–∑–º–µ—Ä –∫—ç—à–∞
    pub async fn get_cache_size(&self) -> Result<u64> {
        if !self.base_path.exists() {
            return Ok(0);
        }

        let mut total_size = 0u64;
        let mut entries = fs::read_dir(&self.base_path).await?;

        while let Some(entry) = entries.next_entry().await? {
            if let Ok(metadata) = entry.metadata().await {
                if metadata.is_file() {
                    total_size += metadata.len();
                }
            }
        }

        Ok(total_size)
    }
}

lazy_static::lazy_static! {
    /// –ì–ª–æ–±–∞–ª—å–Ω—ã–π –∑–∞–≥—Ä—É–∑—á–∏–∫ –º–æ–¥–µ–ª–µ–π
    pub static ref MODEL_DOWNLOADER: ModelDownloader = {
        let models_dir = PathBuf::from("models");
        ModelDownloader::new(models_dir)
            .expect("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –∑–∞–≥—Ä—É–∑—á–∏–∫ –º–æ–¥–µ–ª–µ–π")
    };
}

/// –£–±–µ–¥–∏—Ç—å—Å—è —á—Ç–æ –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞
pub async fn ensure_model(model_name: &str) -> Result<PathBuf> {
    MODEL_DOWNLOADER.ensure_model(model_name).await
}

#[cfg(test)]
mod tests {
    use super::*;
    use tempfile::TempDir;

    #[tokio::test]
    async fn test_model_info() {
        let temp_dir = TempDir::new().expect("Operation should succeed");
        let downloader = ModelDownloader::new(temp_dir.path()).expect("Operation should succeed");

        let info = downloader
            .get_model_info("qwen3emb")
            .expect("Operation should succeed");
        assert_eq!(info.name, "qwen3emb");
        assert!(!info.files.is_empty());
        assert!(info.total_size == 0);
    }

    #[tokio::test]
    async fn test_model_detection() {
        let temp_dir = TempDir::new().expect("Operation should succeed");
        let downloader = ModelDownloader::new(temp_dir.path()).expect("Operation should succeed");

        let model_path = temp_dir.path().join("qwen3emb");
        let is_complete = downloader
            .is_model_complete(&model_path)
            .await
            .expect("Operation should succeed");
        assert!(!is_complete);

        // –°–æ–∑–¥–∞—ë–º —Ñ–µ–π–∫–æ–≤—ã–µ —Ñ–∞–π–ª—ã
        fs::create_dir_all(&model_path)
            .await
            .expect("Operation should succeed");
        fs::write(model_path.join("model.onnx"), b"fake")
            .await
            .expect("Operation should succeed");
        fs::write(model_path.join("tokenizer.json"), b"fake")
            .await
            .expect("Operation should succeed");
        fs::write(model_path.join("config.json"), b"fake")
            .await
            .expect("Operation should succeed");

        let is_complete = downloader
            .is_model_complete(&model_path)
            .await
            .expect("Operation should succeed");
        assert!(is_complete);
    }
}
