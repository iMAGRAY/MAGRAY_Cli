use anyhow::Result;
use tracing::info;

#[cfg(feature = "gpu")]
use tracing::warn;

#[cfg(feature = "gpu")]
use ort::execution_providers::{CUDAExecutionProvider, TensorRTExecutionProvider, ExecutionProviderDispatch};

use crate::gpu_detector::{GpuDetector, GpuOptimalParams};

/// GPU –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è ONNX Runtime
/// @component: {"k":"C","id":"gpu_config","t":"GPU configuration for ONNX","m":{"cur":100,"tgt":100,"u":"%"}}
#[derive(Debug, Clone)]
pub struct GpuConfig {
    /// ID —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞ CUDA (–æ–±—ã—á–Ω–æ 0)
    pub device_id: i32,
    /// –†–∞–∑–º–µ—Ä GPU –ø–∞–º—è—Ç–∏ –¥–ª—è –∞—Ä–µ–Ω—ã (–≤ –±–∞–π—Ç–∞—Ö)
    pub gpu_mem_limit: usize,
    /// –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å TensorRT –¥–ª—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
    pub use_tensorrt: bool,
    /// –†–∞–∑–º–µ—Ä –ø–∞–º—è—Ç–∏ –¥–ª—è TensorRT –∫—ç—à–∞
    pub tensorrt_cache_size: usize,
    /// –í–∫–ª—é—á–∏—Ç—å FP16 –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è
    pub enable_fp16: bool,
    /// –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
    pub auto_optimize: bool,
}

impl Default for GpuConfig {
    fn default() -> Self {
        Self {
            device_id: 0,
            gpu_mem_limit: 2 * 1024 * 1024 * 1024, // 2GB
            use_tensorrt: false,
            tensorrt_cache_size: 1024 * 1024 * 1024, // 1GB
            enable_fp16: true,
            auto_optimize: true,
        }
    }
}

impl GpuConfig {
    /// –°–æ–∑–¥–∞—Ç—å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π
    pub fn auto_optimized() -> Self {
        let mut config = Self::default();
        
        // –û–ø—Ä–µ–¥–µ–ª—è–µ–º GPU
        let detector = GpuDetector::detect();
        
        if let Some(best_device) = detector.select_best_device() {
            config.device_id = best_device as i32;
            
            // –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –≤—ã–±—Ä–∞–Ω–Ω–æ–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–µ
            if let Some(device) = detector.devices.iter().find(|d| d.index == best_device) {
                // –ò—Å–ø–æ–ª—å–∑—É–µ–º 80% –¥–æ—Å—Ç—É–ø–Ω–æ–π –ø–∞–º—è—Ç–∏
                config.gpu_mem_limit = (device.free_memory_mb as usize * 1024 * 1024 * 8) / 10;
                
                // –í–∫–ª—é—á–∞–µ–º TensorRT –¥–ª—è –º–æ—â–Ω—ã—Ö GPU (8GB+)
                config.use_tensorrt = device.total_memory_mb >= 8000;
                
                // –í–∫–ª—é—á–∞–µ–º FP16 –¥–ª—è –≤—Å–µ—Ö —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö GPU (—É—Å–∫–æ—Ä–µ–Ω–∏–µ –≤ 2x –±–µ–∑ –ø–æ—Ç–µ—Ä–∏ –∫–∞—á–µ—Å—Ç–≤–∞)
                config.enable_fp16 = true;
                
                info!("üéØ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∞ GPU –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è:");
                info!("  - –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: GPU {} ({})", device.index, device.name);
                info!("  - –ü–∞–º—è—Ç—å: {} MB –∏–∑ {} MB", 
                    config.gpu_mem_limit / 1024 / 1024, 
                    device.free_memory_mb
                );
                info!("  - TensorRT: {}", if config.use_tensorrt { "–≤–∫–ª—é—á–µ–Ω" } else { "–≤—ã–∫–ª—é—á–µ–Ω" });
                info!("  - FP16: {}", if config.enable_fp16 { "–≤–∫–ª—é—á–µ–Ω" } else { "–≤—ã–∫–ª—é—á–µ–Ω" });
            }
        }
        
        config
    }
    
    /// –°–æ–∑–¥–∞—Ç—å execution providers –¥–ª—è GPU (–Ω–æ–≤—ã–π API)
    #[cfg(feature = "gpu")]
    pub fn create_providers(&self) -> Result<Vec<ExecutionProviderDispatch>> {
        let mut providers = Vec::new();
        
        // –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∞–ª—å–Ω—É—é –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å GPU
        let detector = GpuDetector::detect();
        if !detector.available {
            warn!("‚ö†Ô∏è GPU –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω, providers –Ω–µ –±—É–¥—É—Ç —Å–æ–∑–¥–∞–Ω—ã");
            return Ok(providers);
        }
        
        // TensorRT provider (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω –∏ –¥–æ—Å—Ç—É–ø–µ–Ω)
        if self.use_tensorrt {
            match self.create_tensorrt_provider() {
                Ok(provider) => {
                    info!("‚úÖ TensorRT provider –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –¥–ª—è GPU {}", self.device_id);
                    providers.push(provider);
                }
                Err(e) => {
                    warn!("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å TensorRT provider: {}", e);
                }
            }
        }
        
        // CUDA provider (–æ—Å–Ω–æ–≤–Ω–æ–π)
        match self.create_cuda_provider() {
            Ok(provider) => {
                info!("‚úÖ CUDA provider –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –¥–ª—è GPU {}", self.device_id);
                info!("  üìä GPU memory limit: {} MB", self.gpu_mem_limit / 1024 / 1024);
                providers.push(provider);
            }
            Err(e) => {
                warn!("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å CUDA provider: {}", e);
                warn!("  –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —É—Å—Ç–∞–Ω–æ–≤–∫—É CUDA –∏ cuDNN");
            }
        }
        
        if providers.is_empty() {
            warn!("‚ö†Ô∏è –ù–∏ –æ–¥–∏–Ω GPU provider –Ω–µ –±—ã–ª —Å–æ–∑–¥–∞–Ω");
        }
        
        Ok(providers)
    }
    
    /// –°–æ–∑–¥–∞—Ç—å CUDA provider —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫
    #[cfg(feature = "gpu")]
    fn create_cuda_provider(&self) -> Result<ExecutionProviderDispatch> {
        let provider = CUDAExecutionProvider::default()
            .with_device_id(self.device_id)
            .with_memory_limit(self.gpu_mem_limit)
            .build();
            
        Ok(provider)
    }
    
    /// –°–æ–∑–¥–∞—Ç—å TensorRT provider —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫
    #[cfg(feature = "gpu")]
    fn create_tensorrt_provider(&self) -> Result<ExecutionProviderDispatch> {
        let provider = TensorRTExecutionProvider::default()
            .with_device_id(self.device_id)
            .with_max_workspace_size(self.tensorrt_cache_size)
            .with_fp16(self.enable_fp16)
            .with_engine_cache(true)
            .with_engine_cache_path("./tensorrt_cache")
            .with_timing_cache(true)
            .with_force_sequential_engine_build(false) // –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è —Å–±–æ—Ä–∫–∞
            .build();
            
        Ok(provider)
    }
    
    /// –°–æ–∑–¥–∞—Ç—å execution providers –¥–ª—è GPU (stub –¥–ª—è non-GPU builds)
    #[cfg(not(feature = "gpu"))]
    pub fn create_providers(&self) -> Result<Vec<()>> {
        info!("‚ÑπÔ∏è GPU –ø–æ–¥–¥–µ—Ä–∂–∫–∞ –Ω–µ –≤–∫–ª—é—á–µ–Ω–∞. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ --features gpu –ø—Ä–∏ —Å–±–æ—Ä–∫–µ");
        Ok(Vec::new())
    }
    
    /// –ü–æ–ª—É—á–∏—Ç—å –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ GPU
    pub fn get_optimal_params(&self, model_size_mb: u64) -> GpuOptimalParams {
        let detector = GpuDetector::detect();
        
        if let Some(device) = detector.devices.iter().find(|d| d.index == self.device_id as u32) {
            GpuOptimalParams::calculate(device.free_memory_mb, model_size_mb)
        } else {
            // –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –µ—Å–ª–∏ GPU –Ω–µ –Ω–∞–π–¥–µ–Ω
            GpuOptimalParams {
                batch_size: 32,
                max_sequence_length: 256,
                use_fp16: self.enable_fp16,
                memory_fraction: 0.8,
            }
        }
    }
}

/// –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö GPU (legacy compatibility)
#[derive(Debug, Clone)]
pub struct GpuInfo {
    pub available: bool,
    pub device_count: usize,
    pub device_name: String,
    pub total_memory: usize,
    pub cuda_version: String,
}

impl GpuInfo {
    /// –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å GPU
    pub fn detect() -> Self {
        let detector = GpuDetector::detect();
        
        Self {
            available: detector.available,
            device_count: detector.devices.len(),
            device_name: detector.devices.first()
                .map(|d| d.name.clone())
                .unwrap_or_else(|| "N/A".to_string()),
            total_memory: detector.devices.first()
                .map(|d| (d.total_memory_mb * 1024 * 1024) as usize)
                .unwrap_or(0),
            cuda_version: detector.cuda_version,
        }
    }
    
    /// –í—ã–≤–µ—Å—Ç–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ GPU
    pub fn print_info(&self) {
        let detector = GpuDetector::detect();
        detector.print_detailed_info();
    }
}