use anyhow::Result;
use tracing::info;

#[cfg(feature = "gpu")]
use tracing::warn;

#[cfg(feature = "gpu")]
use ort::execution_providers::{
    CUDAExecutionProvider, ExecutionProviderDispatch, TensorRTExecutionProvider,
};

#[cfg(all(feature = "gpu", windows))]
use ort::execution_providers::DirectMLExecutionProvider;

#[cfg(feature = "gpu")]
use ort::execution_providers::OpenVINOExecutionProvider;

use crate::gpu_detector::{GpuDetector, GpuOptimalParams};

/// GPU –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è ONNX Runtime
#[derive(Debug, Clone)]
pub struct GpuConfig {
    /// ID —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞ CUDA (–æ–±—ã—á–Ω–æ 0)
    pub device_id: i32,
    /// –†–∞–∑–º–µ—Ä GPU –ø–∞–º—è—Ç–∏ –¥–ª—è –∞—Ä–µ–Ω—ã (–≤ –±–∞–π—Ç–∞—Ö)
    pub gpu_mem_limit: usize,
    /// –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å TensorRT –¥–ª—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
    pub use_tensorrt: bool,
    /// –†–∞–∑–º–µ—Ä –ø–∞–º—è—Ç–∏ –¥–ª—è TensorRT –∫—ç—à–∞
    pub tensorrt_cache_size: usize,
    /// –í–∫–ª—é—á–∏—Ç—å FP16 –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è
    pub enable_fp16: bool,
    /// –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
    pub auto_optimize: bool,
    /// –ü—Ä–µ–¥–ø–æ—á–∏—Ç–∞–µ–º—ã–π —Ç–∏–ø –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞
    pub preferred_provider: GpuProviderType,
    /// –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å DirectML –Ω–∞ Windows
    pub use_directml: bool,
    /// –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å OpenVINO –¥–ª—è Intel GPU/CPU
    pub use_openvino: bool,
}

#[derive(Debug, Clone, PartialEq)]
pub enum GpuProviderType {
    CUDA,
    DirectML,
    OpenVINO,
    Auto,
}

impl Default for GpuConfig {
    fn default() -> Self {
        Self {
            device_id: 0,
            gpu_mem_limit: 2 * 1024 * 1024 * 1024, // 2GB
            use_tensorrt: false,
            tensorrt_cache_size: 1024 * 1024 * 1024, // 1GB
            enable_fp16: true,
            auto_optimize: true,
            preferred_provider: GpuProviderType::Auto,
            use_directml: cfg!(windows),
            use_openvino: true,
        }
    }
}

impl GpuConfig {
    /// –°–æ–∑–¥–∞—Ç—å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π
    pub fn auto_optimized() -> Self {
        let mut config = Self::default();

        // –û–ø—Ä–µ–¥–µ–ª—è–µ–º GPU
        let detector = GpuDetector::detect();

        if let Some(best_device) = detector.select_best_device() {
            config.device_id = best_device as i32;

            // –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –≤—ã–±—Ä–∞–Ω–Ω–æ–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–µ
            if let Some(device) = detector.devices.iter().find(|d| d.index == best_device) {
                // –ò—Å–ø–æ–ª—å–∑—É–µ–º 80% –¥–æ—Å—Ç—É–ø–Ω–æ–π –ø–∞–º—è—Ç–∏
                config.gpu_mem_limit = (device.free_memory_mb as usize * 1024 * 1024 * 8) / 10;

                // –í–∫–ª—é—á–∞–µ–º TensorRT –¥–ª—è –º–æ—â–Ω—ã—Ö GPU (8GB+)
                config.use_tensorrt = device.total_memory_mb >= 8000;

                // –í–∫–ª—é—á–∞–µ–º FP16 –¥–ª—è –≤—Å–µ—Ö —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö GPU (—É—Å–∫–æ—Ä–µ–Ω–∏–µ –≤ 2x –±–µ–∑ –ø–æ—Ç–µ—Ä–∏ –∫–∞—á–µ—Å—Ç–≤–∞)
                config.enable_fp16 = true;

                info!("üéØ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∞ GPU –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è:");
                info!("  - –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: GPU {} ({})", device.index, device.name);
                info!(
                    "  - –ü–∞–º—è—Ç—å: {} MB –∏–∑ {} MB",
                    config.gpu_mem_limit / 1024 / 1024,
                    device.free_memory_mb
                );
                info!(
                    "  - TensorRT: {}",
                    if config.use_tensorrt {
                        "–≤–∫–ª—é—á–µ–Ω"
                    } else {
                        "–≤—ã–∫–ª—é—á–µ–Ω"
                    }
                );
                info!(
                    "  - FP16: {}",
                    if config.enable_fp16 {
                        "–≤–∫–ª—é—á–µ–Ω"
                    } else {
                        "–≤—ã–∫–ª—é—á–µ–Ω"
                    }
                );
            }
        }

        config
    }

    /// –°–æ–∑–¥–∞—Ç—å execution providers –¥–ª—è GPU —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º –≤—ã–±–æ—Ä–æ–º –ª—É—á—à–µ–≥–æ
    #[cfg(feature = "gpu")]
    pub fn create_providers(&self) -> Result<Vec<ExecutionProviderDispatch>> {
        let mut providers = Vec::new();

        // –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–∞–∫–∏–µ –ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å
        let provider_attempts = match self.preferred_provider {
            GpuProviderType::CUDA => vec![GpuProviderType::CUDA],
            GpuProviderType::DirectML => vec![GpuProviderType::DirectML],
            GpuProviderType::OpenVINO => vec![GpuProviderType::OpenVINO],
            GpuProviderType::Auto => {
                // –ü–æ—Ä—è–¥–æ–∫ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞: CUDA -> DirectML (Windows) -> OpenVINO -> CPU fallback
                let mut attempts = vec![GpuProviderType::CUDA];
                if cfg!(windows) && self.use_directml {
                    attempts.push(GpuProviderType::DirectML);
                }
                if self.use_openvino {
                    attempts.push(GpuProviderType::OpenVINO);
                }
                attempts
            }
        };

        info!("üîç –ü–æ–ø—ã—Ç–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è GPU providers: {:?}", provider_attempts);

        // –ü—Ä–æ–±—É–µ–º —Å–æ–∑–¥–∞—Ç—å TensorRT provider –µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω (—Ç–æ–ª—å–∫–æ –¥–ª—è CUDA)
        if self.use_tensorrt && provider_attempts.contains(&GpuProviderType::CUDA) {
            match self.create_tensorrt_provider() {
                Ok(provider) => {
                    info!(
                        "‚úÖ TensorRT provider –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –¥–ª—è GPU {}",
                        self.device_id
                    );
                    providers.push(provider);
                }
                Err(e) => {
                    warn!("‚ö†Ô∏è TensorRT provider –Ω–µ—É–¥–∞—á–µ–Ω: {}", e);
                }
            }
        }

        // –ü—Ä–æ–±—É–µ–º —Å–æ–∑–¥–∞—Ç—å –æ—Å–Ω–æ–≤–Ω—ã–µ GPU providers
        for provider_type in provider_attempts {
            match provider_type {
                GpuProviderType::CUDA => {
                    match self.create_cuda_provider() {
                        Ok(provider) => {
                            info!(
                                "‚úÖ CUDA provider –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –¥–ª—è GPU {}",
                                self.device_id
                            );
                            info!(
                                "  üìä GPU memory limit: {} MB",
                                self.gpu_mem_limit / 1024 / 1024
                            );
                            providers.push(provider);
                            break; // –£—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–ª–∏, –ø—Ä–µ–∫—Ä–∞—â–∞–µ–º –ø–æ–ø—ã—Ç–∫–∏
                        }
                        Err(e) => {
                            warn!("‚ö†Ô∏è CUDA provider failed: {}. Trying next...", e);
                        }
                    }
                }
                GpuProviderType::DirectML => {
                    #[cfg(windows)]
                    match self.create_directml_provider() {
                        Ok(provider) => {
                            info!("‚úÖ DirectML provider –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω");
                            providers.push(provider);
                            break;
                        }
                        Err(e) => {
                            warn!("‚ö†Ô∏è DirectML provider failed: {}. Trying next...", e);
                        }
                    }

                    #[cfg(not(windows))]
                    warn!("‚ö†Ô∏è DirectML –¥–æ—Å—Ç—É–ø–µ–Ω —Ç–æ–ª—å–∫–æ –Ω–∞ Windows");
                }
                GpuProviderType::OpenVINO => match self.create_openvino_provider() {
                    Ok(provider) => {
                        info!("‚úÖ OpenVINO provider –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω");
                        providers.push(provider);
                        break;
                    }
                    Err(e) => {
                        warn!("‚ö†Ô∏è OpenVINO provider failed: {}. Trying next...", e);
                    }
                },
                GpuProviderType::Auto => unreachable!("Auto should be resolved earlier"),
            }
        }

        if providers.is_empty() {
            warn!("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –Ω–∏ –æ–¥–Ω–æ–≥–æ GPU provider. Fallback –Ω–∞ CPU.");
        }

        Ok(providers)
    }

    /// –°–æ–∑–¥–∞—Ç—å CUDA provider —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫
    #[cfg(feature = "gpu")]
    fn create_cuda_provider(&self) -> Result<ExecutionProviderDispatch> {
        let provider = CUDAExecutionProvider::default()
            .with_device_id(self.device_id)
            .with_memory_limit(self.gpu_mem_limit)
            .build();

        Ok(provider)
    }

    /// –°–æ–∑–¥–∞—Ç—å TensorRT provider —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫
    #[cfg(feature = "gpu")]
    fn create_tensorrt_provider(&self) -> Result<ExecutionProviderDispatch> {
        let provider = TensorRTExecutionProvider::default()
            .with_device_id(self.device_id)
            .with_max_workspace_size(self.tensorrt_cache_size)
            .with_fp16(self.enable_fp16)
            .with_engine_cache(true)
            .with_engine_cache_path("./tensorrt_cache")
            .with_timing_cache(true)
            .with_force_sequential_engine_build(false) // –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è —Å–±–æ—Ä–∫–∞
            .build();

        Ok(provider)
    }

    /// –°–æ–∑–¥–∞—Ç—å DirectML provider (Windows —Ç–æ–ª—å–∫–æ)
    #[cfg(all(feature = "gpu", windows))]
    fn create_directml_provider(&self) -> Result<ExecutionProviderDispatch> {
        let provider = DirectMLExecutionProvider::default()
            .with_device_id(self.device_id)
            .build();
        Ok(provider)
    }

    /// DirectML provider stub –¥–ª—è non-Windows
    #[cfg(all(feature = "gpu", not(windows)))]
    fn create_directml_provider(&self) -> Result<ExecutionProviderDispatch> {
        Err(anyhow::anyhow!("DirectML –¥–æ—Å—Ç—É–ø–µ–Ω —Ç–æ–ª—å–∫–æ –Ω–∞ Windows"))
    }

    /// –°–æ–∑–¥–∞—Ç—å OpenVINO provider
    #[cfg(feature = "gpu")]
    fn create_openvino_provider(&self) -> Result<ExecutionProviderDispatch> {
        let provider = OpenVINOExecutionProvider::default()
            .with_device_type("GPU") // –ò—Å–ø–æ–ª—å–∑—É–µ–º GPU, fallback –Ω–∞ CPU –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π
            .with_cache_dir("./openvino_cache")
            .with_num_threads(num_cpus::get())
            .build();
        Ok(provider)
    }

    /// –°–æ–∑–¥–∞—Ç—å execution providers –¥–ª—è GPU (stub –¥–ª—è non-GPU builds)
    #[cfg(not(feature = "gpu"))]
    pub fn create_providers(&self) -> Result<Vec<()>> {
        info!("‚ÑπÔ∏è GPU –ø–æ–¥–¥–µ—Ä–∂–∫–∞ –Ω–µ –≤–∫–ª—é—á–µ–Ω–∞. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ --features gpu –ø—Ä–∏ —Å–±–æ—Ä–∫–µ");
        Ok(Vec::new())
    }

    /// –ü–æ–ª—É—á–∏—Ç—å –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ GPU
    pub fn get_optimal_params(&self, model_size_mb: u64) -> GpuOptimalParams {
        let detector = GpuDetector::detect();

        if let Some(device) = detector
            .devices
            .iter()
            .find(|d| d.index == self.device_id as u32)
        {
            GpuOptimalParams::calculate(device.free_memory_mb, model_size_mb)
        } else {
            // –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –µ—Å–ª–∏ GPU –Ω–µ –Ω–∞–π–¥–µ–Ω
            GpuOptimalParams {
                batch_size: 32,
                max_sequence_length: 256,
                use_fp16: self.enable_fp16,
                memory_fraction: 0.8,
            }
        }
    }
}

/// –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö GPU (legacy compatibility)
#[derive(Debug, Clone)]
pub struct GpuInfo {
    pub available: bool,
    pub device_count: usize,
    pub device_name: String,
    pub total_memory: usize,
    pub cuda_version: String,
}

impl GpuInfo {
    /// –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å GPU
    pub fn detect() -> Self {
        let detector = GpuDetector::detect();

        Self {
            available: detector.available,
            device_count: detector.devices.len(),
            device_name: detector
                .devices
                .first()
                .map(|d| d.name.clone())
                .unwrap_or_else(|| "N/A".to_string()),
            total_memory: detector
                .devices
                .first()
                .map(|d| (d.total_memory_mb * 1024 * 1024) as usize)
                .unwrap_or(0),
            cuda_version: detector.cuda_version,
        }
    }

    /// –í—ã–≤–µ—Å—Ç–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ GPU
    pub fn print_info(&self) {
        let detector = GpuDetector::detect();
        detector.print_detailed_info();
    }
}
