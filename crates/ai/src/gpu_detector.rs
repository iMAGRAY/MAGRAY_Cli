use std::process::Command;
use std::str;
use serde::{Deserialize, Serialize};
use tracing::{info, debug};

/// @component: {"k":"C","id":"gpu_detector","t":"GPU detection and info","m":{"cur":95,"tgt":100,"u":"%"}}
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct GpuDetector {
    pub available: bool,
    pub devices: Vec<GpuDevice>,
    pub cuda_version: String,
    pub driver_version: String,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct GpuDevice {
    pub index: u32,
    pub name: String,
    pub compute_capability: String,
    pub total_memory_mb: u64,
    pub free_memory_mb: u64,
    pub temperature_c: Option<u32>,
    pub utilization_percent: Option<u32>,
    pub power_draw_w: Option<f32>,
}

impl GpuDetector {
    /// –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å –¥–æ—Å—Ç—É–ø–Ω—ã–µ GPU —á–µ—Ä–µ–∑ nvidia-smi
    pub fn detect() -> Self {
        // –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ nvidia-smi
        let nvidia_smi_check = Command::new("nvidia-smi")
            .arg("--query")
            .output();
            
        match nvidia_smi_check {
            Ok(output) if output.status.success() => {
                info!("‚úÖ nvidia-smi –¥–æ—Å—Ç—É–ø–µ–Ω, –æ–ø—Ä–µ–¥–µ–ª—è–µ–º GPU...");
                Self::detect_nvidia_gpus()
            }
            _ => {
                debug!("nvidia-smi –Ω–µ –Ω–∞–π–¥–µ–Ω –∏–ª–∏ –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç");
                Self::not_available()
            }
        }
    }
    
    /// –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å NVIDIA GPU —á–µ—Ä–µ–∑ nvidia-smi
    fn detect_nvidia_gpus() -> Self {
        let mut detector = Self {
            available: false,
            devices: Vec::new(),
            cuda_version: String::from("N/A"),
            driver_version: String::from("N/A"),
        };
        
        // –ü–æ–ª—É—á–∞–µ–º –≤–µ—Ä—Å–∏—é –¥—Ä–∞–π–≤–µ—Ä–∞
        if let Ok(output) = Command::new("nvidia-smi")
            .args(&["--query-gpu=driver_version", "--format=csv,noheader,nounits"])
            .output()
        {
            if let Ok(driver) = str::from_utf8(&output.stdout) {
                detector.driver_version = driver.trim().to_string();
            }
        }
        
        // –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ GPU
        let gpu_query = Command::new("nvidia-smi")
            .args(&[
                "--query-gpu=index,name,compute_cap,memory.total,memory.free,temperature.gpu,utilization.gpu,power.draw",
                "--format=csv,noheader,nounits"
            ])
            .output();
            
        if let Ok(output) = gpu_query {
            if output.status.success() {
                if let Ok(gpu_info) = str::from_utf8(&output.stdout) {
                    for line in gpu_info.lines() {
                        if let Some(device) = Self::parse_gpu_line(line) {
                            detector.devices.push(device);
                        }
                    }
                }
            }
        }
        
        // –ü–æ–ª—É—á–∞–µ–º –≤–µ—Ä—Å–∏—é CUDA
        if let Ok(output) = Command::new("nvcc")
            .arg("--version")
            .output()
        {
            if let Ok(version_str) = str::from_utf8(&output.stdout) {
                if let Some(cuda_line) = version_str.lines()
                    .find(|line| line.contains("release"))
                {
                    if let Some(version) = cuda_line.split("release").nth(1) {
                        detector.cuda_version = version.split(',').next()
                            .unwrap_or("N/A")
                            .trim()
                            .to_string();
                    }
                }
            }
        }
        
        detector.available = !detector.devices.is_empty();
        
        if detector.available {
            info!("üéÆ –ù–∞–π–¥–µ–Ω–æ {} GPU —É—Å—Ç—Ä–æ–π—Å—Ç–≤", detector.devices.len());
            info!("üîß –î—Ä–∞–π–≤–µ—Ä: {}, CUDA: {}", detector.driver_version, detector.cuda_version);
        }
        
        detector
    }
    
    /// –ü–∞—Ä—Å–∏—Ç—å —Å—Ç—Ä–æ–∫—É —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ GPU
    fn parse_gpu_line(line: &str) -> Option<GpuDevice> {
        let parts: Vec<&str> = line.split(',').map(|s| s.trim()).collect();
        
        if parts.len() >= 8 {
            Some(GpuDevice {
                index: parts[0].parse().unwrap_or(0),
                name: parts[1].to_string(),
                compute_capability: parts[2].to_string(),
                total_memory_mb: parts[3].parse().unwrap_or(0),
                free_memory_mb: parts[4].parse().unwrap_or(0),
                temperature_c: parts[5].parse().ok(),
                utilization_percent: parts[6].parse().ok(),
                power_draw_w: parts[7].parse().ok(),
            })
        } else {
            None
        }
    }
    
    /// –°–æ–∑–¥–∞—Ç—å –∑–∞–≥–ª—É—à–∫—É –∫–æ–≥–¥–∞ GPU –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω
    fn not_available() -> Self {
        Self {
            available: false,
            devices: Vec::new(),
            cuda_version: String::from("N/A"),
            driver_version: String::from("N/A"),
        }
    }
    
    /// –í—ã–±—Ä–∞—Ç—å –ª—É—á—à–∏–π GPU –ø–æ —Å–≤–æ–±–æ–¥–Ω–æ–π –ø–∞–º—è—Ç–∏
    pub fn select_best_device(&self) -> Option<u32> {
        self.devices
            .iter()
            .max_by_key(|d| d.free_memory_mb)
            .map(|d| d.index)
    }
    
    /// –ü–æ–ª—É—á–∏—Ç—å –æ–±—â—É—é —Å–≤–æ–±–æ–¥–Ω—É—é –ø–∞–º—è—Ç—å –Ω–∞ –≤—Å–µ—Ö GPU
    pub fn total_free_memory_mb(&self) -> u64 {
        self.devices.iter().map(|d| d.free_memory_mb).sum()
    }
    
    /// –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ª–∏ –ø–∞–º—è—Ç–∏ –¥–ª—è –º–æ–¥–µ–ª–∏
    pub fn has_sufficient_memory(&self, required_mb: u64) -> bool {
        self.devices.iter().any(|d| d.free_memory_mb >= required_mb)
    }
    
    /// –í—ã–≤–µ—Å—Ç–∏ –ø–æ–¥—Ä–æ–±–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ GPU
    pub fn print_detailed_info(&self) {
        if !self.available {
            info!("‚ùå GPU –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω –∏–ª–∏ –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω");
            return;
        }
        
        info!("üéÆ GPU –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è:");
        info!("  üîß –î—Ä–∞–π–≤–µ—Ä: {}", self.driver_version);
        info!("  üîß CUDA: {}", self.cuda_version);
        
        for device in &self.devices {
            info!("  üìä GPU {}: {}", device.index, device.name);
            info!("    - Compute capability: {}", device.compute_capability);
            info!("    - –ü–∞–º—è—Ç—å: {}/{} MB", device.free_memory_mb, device.total_memory_mb);
            
            if let Some(temp) = device.temperature_c {
                info!("    - –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞: {}¬∞C", temp);
            }
            if let Some(util) = device.utilization_percent {
                info!("    - –ó–∞–≥—Ä—É–∑–∫–∞: {}%", util);
            }
            if let Some(power) = device.power_draw_w {
                info!("    - –ü–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–µ: {:.1}W", power);
            }
        }
    }
}

/// –û–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è GPU
#[derive(Debug, Clone)]
pub struct GpuOptimalParams {
    pub batch_size: usize,
    pub max_sequence_length: usize,
    pub use_fp16: bool,
    pub memory_fraction: f32,
}

impl GpuOptimalParams {
    /// –†–∞—Å—Å—á–∏—Ç–∞—Ç—å –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–æ—Å—Ç—É–ø–Ω–æ–π –ø–∞–º—è—Ç–∏
    pub fn calculate(available_memory_mb: u64, model_size_mb: u64) -> Self {
        // –û—Å—Ç–∞–≤–ª—è–µ–º 20% –ø–∞–º—è—Ç–∏ –¥–ª—è —Å–∏—Å—Ç–µ–º—ã
        let usable_memory_mb = (available_memory_mb as f64 * 0.8) as u64;
        
        // –†–∞–∑–º–µ—Ä –æ–¥–Ω–æ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞ –≤ –±–∞—Ç—á–µ (–ø—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–æ)
        let item_size_mb = 10; // 10MB –Ω–∞ –æ–¥–∏–Ω —ç–ª–µ–º–µ–Ω—Ç (embeddings + –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ —Ç–µ–Ω–∑–æ—Ä—ã)
        
        // –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞
        let max_batch_size = ((usable_memory_mb - model_size_mb) / item_size_mb).max(1) as usize;
        
        // –û–ø—Ç–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ (—Å—Ç–µ–ø–µ–Ω—å –¥–≤–æ–π–∫–∏ –¥–ª—è –ª—É—á—à–µ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏)
        let optimal_batch_size = (1..=10)
            .map(|i| 1 << i) // 2, 4, 8, 16, 32, 64, 128, 256, 512, 1024
            .filter(|&size| size <= max_batch_size)
            .last()
            .unwrap_or(1);
            
        Self {
            batch_size: optimal_batch_size,
            max_sequence_length: if usable_memory_mb > 4000 { 512 } else { 256 },
            use_fp16: true, // –í–∫–ª—é—á–∞–µ–º FP16 –¥–ª—è –≤—Å–µ—Ö GPU (—É—Å–∫–æ—Ä–µ–Ω–∏–µ –≤ 2x –±–µ–∑ –ø–æ—Ç–µ—Ä–∏ –∫–∞—á–µ—Å—Ç–≤–∞)
            memory_fraction: 0.8,
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    
    #[test]
    fn test_gpu_detection() {
        let detector = GpuDetector::detect();
        println!("GPU available: {}", detector.available);
        detector.print_detailed_info();
    }
    
    #[test]
    fn test_optimal_params() {
        let params = GpuOptimalParams::calculate(8000, 1500);
        assert!(params.batch_size > 0);
        assert!(params.batch_size <= 512);
        println!("Optimal batch size for 8GB GPU: {}", params.batch_size);
    }
}