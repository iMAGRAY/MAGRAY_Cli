pub mod config;
pub mod embeddings_bge_m3;
pub mod embeddings_cpu;
pub mod embeddings_gpu;
pub mod errors;
pub mod memory_pool;
pub mod models;
pub mod model_registry;
pub mod reranking;
pub mod reranker_mxbai;
pub mod reranker_mxbai_optimized;
pub mod tokenizer;
pub mod tokenization;
pub mod gpu_config;
pub mod gpu_detector;
pub mod gpu_memory_pool;
pub mod auto_device_selector;
pub mod model_downloader;
pub mod tensorrt_cache;
pub mod gpu_fallback;
pub mod gpu_pipeline;
pub mod gpu_pipeline_optimized;

pub use config::{AiConfig, EmbeddingConfig, RerankingConfig};
pub use model_registry::{ModelRegistry, ModelInfo, ModelType, MODEL_REGISTRY};
pub use embeddings_bge_m3::BgeM3EmbeddingService;
pub use embeddings_cpu::{CpuEmbeddingService, OptimizedEmbeddingResult, ServiceStats};
pub use embeddings_gpu::GpuEmbeddingService;
pub use memory_pool::{MemoryPool, PoolStats, PooledBuffer, GLOBAL_MEMORY_POOL, get_input_buffer, return_input_buffer, get_pool_stats};
pub use errors::AiError;
pub use models::ModelLoader;
pub use reranking::{RerankingService, RerankResult};
pub use reranker_mxbai::{OptimizedMxbaiRerankerService, OptimizedRerankResult};
pub use tokenizer::{TokenizerService, TokenizedInput, SpecialTokens};
pub use tokenization::{OptimizedTokenizer, TokenizedInput as OptTokenizedInput, BatchTokenized};
pub use gpu_config::{GpuConfig, GpuInfo};
pub use auto_device_selector::EmbeddingServiceTrait;
pub use gpu_fallback::{GpuFallbackManager, FallbackPolicy};
pub use gpu_pipeline::{GpuPipelineManager, PipelineConfig, PipelineStats};
pub use gpu_pipeline_optimized::OptimizedGpuPipelineManager;

/// Result type for AI operations
pub type Result<T> = std::result::Result<T, AiError>;