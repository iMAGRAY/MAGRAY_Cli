# MAGRAY CLI ğŸš€

A blazing-fast, pure-Rust AI agent CLI with local-first memory, semantic search, and extensible tool system. Ship as a single binary with zero dependencies.

[![Rust](https://img.shields.io/badge/rust-%23000000.svg?style=for-the-badge&logo=rust&logoColor=white)](https://www.rust-lang.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)
[![Build Status](https://img.shields.io/github/actions/workflow/status/yourusername/MAGRAY_Cli/ci.yml?branch=main)](https://github.com/yourusername/MAGRAY_Cli/actions)

## âœ¨ Features

- ğŸƒ **Single Static Binary** - Install with `cargo install`, no Python/Node/Docker required
- ğŸ§  **Multi-Layer Memory** - Smart context management with automatic promotion/decay
- ğŸ” **HNSW Vector Search** - Sub-10ms semantic search with professional hnsw_rs implementation
- ğŸ¤– **Local AI Stack** - ONNX embeddings/reranking, optional LLM providers
- ğŸ”§ **Extensible Tools** - File operations, git integration, shell commands
- ğŸ“Š **Observable** - Built-in tracing, metrics, and event logging
- ğŸ›¡ï¸ **Memory Safe** - 100% Rust with zero unsafe blocks in core

## ğŸš€ Quick Start

```bash
# Install from crates.io (when published)
cargo install magray

# Or build from source
git clone https://github.com/yourusername/MAGRAY_Cli
cd MAGRAY_Cli
cargo build --release
cargo install --path crates/cli

# Download models manually (required)
./download_models.ps1

# Start using
magray ask "How do I implement a Redis cache?"
magray remember "Project uses PostgreSQL 15 with TimescaleDB"
magray search "database configuration"
```

## ğŸ“¦ Installation

### Prerequisites

- Rust 1.75+ (install via [rustup](https://rustup.rs/))
- 4GB RAM minimum (8GB recommended)
- 2GB disk space for models

### From Source

```bash
# Clone repository
git clone https://github.com/yourusername/MAGRAY_Cli
cd MAGRAY_Cli

# Download required ONNX models
./download_models.ps1

# Build and install
cargo build --release
cargo install --path crates/cli

# Verify installation
magray --version
```

### With Features

```bash
# Enable GPU acceleration
cargo build --release --features gpu

# Enable all features (GPU, TUI, remote LLMs)
cargo build --release --all-features
```

## ğŸ¯ Usage

### Basic Commands

```bash
# Interactive chat mode (default)
magray

# Direct chat with message
magray chat "How do I optimize this SQL query?"

# File operations
magray read file.txt
magray write output.txt "Hello World"
magray list ./src

# Tool execution with natural language
magray tool "show git status"
magray tool "create a new file with hello world"

# Smart AI planning for complex tasks
magray smart "analyze this codebase and suggest improvements"
```

### Advanced Features

```bash
# Memory system operations
magray memory search "error handling" --layer insights --top-k 20
magray memory add "API rate limit is 1000 req/min" --layer insights
magray memory stats
magray memory backup --name my-backup

# GPU acceleration management
magray gpu info
magray gpu benchmark --batch-size 100 --compare
magray gpu memory status
```

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     CLI     â”‚â”€â”€â”€â”€â–¶â”‚    Core     â”‚â”€â”€â”€â”€â–¶â”‚   Memory    â”‚
â”‚   (clap)    â”‚     â”‚  (planner)  â”‚     â”‚  (HNSW+BGE) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚                    â”‚
                            â–¼                    â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚     AI      â”‚     â”‚    Tools    â”‚
                    â”‚ (embedding) â”‚     â”‚   (WASI)    â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Memory Layers

| Layer | Purpose | Retention | Performance |
|-------|---------|-----------|-------------|
| **L1 Interact** | Current session context | 24 hours | HNSW index, <5ms |
| **L2 Insights** | Distilled knowledge | 90 days | HNSW index, <8ms |
| **L3 Assets** | Long-term storage | Unlimited | HNSW index, <10ms |

### Vector Search Performance

The system uses **hnsw_rs** by Jean-Pierre Both - a professional Rust implementation of Hierarchical Navigable Small World algorithm:

- ğŸš€ **17x faster** than linear search on 5K+ documents
- ğŸ¯ **100% recall** with optimal parameters
- âš¡ **Sub-linear scaling** O(log n) vs O(n)
- ğŸ”§ **Tunable parameters**: M=24, ef_construction=400, ef_search=100
- ğŸ§µ **Parallel operations** for batch insertions and multi-query search

**Benchmark Results:**
```
Dataset Size    HNSW Time    Linear Time    Speedup
100 docs        1.9ms        2.1ms          1.1x
500 docs        2.9ms        10.5ms         3.6x  
1000 docs       4.2ms        21.0ms         5.0x
2000 docs       3.1ms        42.3ms         13.8x
5000 docs       6.0ms        104.8ms        17.4x
```

## ğŸ¤– AI Models

MAGRAY CLI Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ ÑĞ¾Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ğµ ONNX Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ´Ğ»Ñ Ğ²ĞµĞºÑ‚Ğ¾Ñ€Ğ½Ğ¾Ğ³Ğ¾ Ğ¿Ğ¾Ğ¸ÑĞºĞ° Ğ¸ Ñ€Ğ°Ğ½Ğ¶Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ:

### Embedding Model
- **[Qwen3-Embedding-0.6B-ONNX](https://huggingface.co/onnx-community/Qwen3-Embedding-0.6B-ONNX/)**
  - Ğ Ğ°Ğ·Ğ¼ĞµÑ€Ğ½Ğ¾ÑÑ‚ÑŒ: 1024
  - ĞŸĞ¾Ğ´Ğ´ĞµÑ€Ğ¶ĞºĞ° Ğ¼Ğ½Ğ¾Ğ³Ğ¾ÑĞ·Ñ‹Ñ‡Ğ½Ğ¾ÑÑ‚Ğ¸ (Ñ€ÑƒÑÑĞºĞ¸Ğ¹, Ğ°Ğ½Ğ³Ğ»Ğ¸Ğ¹ÑĞºĞ¸Ğ¹, ĞºĞ¸Ñ‚Ğ°Ğ¹ÑĞºĞ¸Ğ¹)
  - ĞĞ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½ Ğ´Ğ»Ñ ONNX Runtime
  - Ğ Ğ°Ğ·Ğ¼ĞµÑ€ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸: ~600MB

### Reranking Model  
- **[Qwen3-Reranker-0.6B-ONNX](https://huggingface.co/zhiqing/Qwen3-Reranker-0.6B-ONNX/)**
  - Ğ¡ĞµĞ¼Ğ°Ğ½Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğµ Ğ¿ĞµÑ€ĞµÑ€Ğ°Ğ½Ğ¶Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ² Ğ¿Ğ¾Ğ¸ÑĞºĞ°
  - Ğ’Ñ‹ÑĞ¾ĞºĞ°Ñ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚ÑŒ Ğ½Ğ° Ğ¼Ğ½Ğ¾Ğ³Ğ¾ÑĞ·Ñ‹Ñ‡Ğ½Ñ‹Ñ… Ñ‚ĞµĞºÑÑ‚Ğ°Ñ…
  - INT8 ĞºĞ²Ğ°Ğ½Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ´Ğ»Ñ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸
  - Ğ Ğ°Ğ·Ğ¼ĞµÑ€ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸: ~600MB

ĞœĞ¾Ğ´ĞµĞ»Ğ¸ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸ Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶Ğ°ÑÑ‚ÑÑ Ğ¿Ñ€Ğ¸ Ğ¿ĞµÑ€Ğ²Ğ¾Ğ¼ Ğ·Ğ°Ğ¿ÑƒÑĞºĞµ Ğ¸Ğ»Ğ¸ Ñ‡ĞµÑ€ĞµĞ·:
```powershell
./download_models.ps1
```

## ğŸ”§ Configuration

Configuration file at `~/.magray/config.toml`:

```toml
[ai]
embed_model = "qwen3emb"
embed_batch_size = 32
rerank_model = "qwen3_reranker"

[ai.llm]
provider = "local"
model = "llama-3.2-3b-instruct.gguf"
max_tokens = 2048

[memory]
interact_ttl_hours = 24
insights_ttl_days = 90
promote_threshold = 0.8

[tools]
enable_network = false
plugin_dir = "~/.magray/plugins"
```

## ğŸ”§ Tool System

MAGRAY CLI includes built-in tools for common development tasks:

- **File Operations**: Read, write, and list files with syntax highlighting
- **Git Integration**: Status, commit, and repository management
- **Shell Commands**: Cross-platform command execution
- **Web Search**: Search capabilities for documentation and resources

Tools are accessed through natural language commands:
```bash
magray tool "show git status"
magray tool "create a new file called test.rs with a hello world function"
magray tool "list all .rs files in the src directory"
```

## ğŸ§ª Development

### Project Structure

```
MAGRAY_Cli/
â”œâ”€â”€ crates/
â”‚   â”œâ”€â”€ cli/        # Main binary (magray)
â”‚   â”œâ”€â”€ llm/        # LLM client abstraction
â”‚   â”œâ”€â”€ memory/     # Vector store & memory layers
â”‚   â”œâ”€â”€ ai/         # ONNX models & embeddings
â”‚   â”œâ”€â”€ tools/      # Tool system & operations
â”‚   â”œâ”€â”€ router/     # AI routing logic
â”‚   â””â”€â”€ todo/       # Task management
â”œâ”€â”€ models/         # ONNX models (git-ignored)
â”œâ”€â”€ scripts/        # Setup & utility scripts
â””â”€â”€ docs/           # Documentation
```

### Building

```bash
# Development build
cargo build

# Run tests
cargo test --workspace

# Run benchmarks
cargo bench

# Generate docs
cargo doc --open
```

### Contributing

1. Fork the repository
2. Create feature branch (`git checkout -b feature/amazing-feature`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing-feature`)
5. Open Pull Request

See [CONTRIBUTING.md](CONTRIBUTING.md) for detailed guidelines.

## ğŸ“Š Performance

Benchmarks on M1 MacBook Air:

| Operation | Time | Notes |
|-----------|------|-------|
| Embedding generation | 12ms | Batch of 32 |
| Vector search (1M docs) | 6ms | HNSW index (hnsw_rs) |
| Reranking (32 results) | 15ms | INT8 quantized |
| Memory promotion | 50ms | Async background |

## ğŸ› ï¸ Troubleshooting

### Common Issues

**"Model not found" error**
```powershell
# Re-download models
./download_models.ps1

# Verify models
dir models/
```

**High memory usage**
```powershell
# Reduce batch sizes in config
# Clear vector cache
Remove-Item -Recurse -Force ~/.magray/cache/embeddings.db
```

**Tool execution fails**
```powershell
# Check tool availability
magray tool "list available tools"

# Verify environment
echo $env:PATH
```

## ğŸ“š Documentation

- [Architecture Overview](docs/ARCHITECTURE.md)
- [API Reference](https://docs.rs/ourcli)
- [Tool System Guide](docs/TOOLS.md)
- [Memory System Deep Dive](docs/MEMORY.md)

## ğŸ¤ Community

- [Discord Server](https://discord.gg/ourcli)
- [GitHub Discussions](https://github.com/yourusername/MAGRAY_Cli/discussions)
- [Twitter](https://twitter.com/ourcli)

## ğŸ“„ License

This project is licensed under the MIT License - see [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- [hnsw_rs](https://github.com/jean-pierreBoth/hnswlib-rs) by Jean-Pierre Both for professional HNSW implementation
- [ONNX Runtime](https://onnxruntime.ai/) for fast inference
- [Tokio](https://tokio.rs/) for async runtime
- The Rust community for amazing crates

---

Built with â¤ï¸ in Rust | [Star us on GitHub!](https://github.com/yourusername/MAGRAY_Cli)